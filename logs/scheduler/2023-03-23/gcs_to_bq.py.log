[2023-03-23T11:55:33.671+0000] {processor.py:153} INFO - Started process (PID=7266) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:55:33.673+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:55:33.674+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:55:33.674+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:55:33.839+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:55:33.825+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:55:33.841+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:55:33.964+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.297 seconds
[2023-03-23T11:56:04.305+0000] {processor.py:153} INFO - Started process (PID=7327) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:56:04.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:56:04.307+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:56:04.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:56:04.339+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:56:04.338+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:56:04.343+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:56:04.383+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.083 seconds
[2023-03-23T11:56:34.482+0000] {processor.py:153} INFO - Started process (PID=7398) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:56:34.484+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:56:34.486+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:56:34.486+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:56:34.531+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:56:34.529+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:56:34.532+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:56:34.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.090 seconds
[2023-03-23T11:57:04.734+0000] {processor.py:153} INFO - Started process (PID=7468) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:57:04.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:57:04.739+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:57:04.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:57:04.781+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:57:04.779+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:57:04.782+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:57:04.810+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T11:57:35.064+0000] {processor.py:153} INFO - Started process (PID=7541) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:57:35.065+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:57:35.067+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:57:35.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:57:35.100+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:57:35.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:57:35.101+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:57:35.124+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T11:58:05.723+0000] {processor.py:153} INFO - Started process (PID=7621) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:58:05.728+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:58:05.731+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:58:05.730+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:58:05.797+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:58:05.796+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:58:05.800+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:58:05.881+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.172 seconds
[2023-03-23T11:58:36.167+0000] {processor.py:153} INFO - Started process (PID=7685) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:58:36.168+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:58:36.170+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:58:36.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:58:36.215+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:58:36.214+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:58:36.216+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:58:36.249+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.086 seconds
[2023-03-23T11:59:06.542+0000] {processor.py:153} INFO - Started process (PID=7774) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:59:06.543+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:59:06.544+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:59:06.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:59:06.580+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:59:06.579+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:59:06.581+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:59:06.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.073 seconds
[2023-03-23T11:59:36.992+0000] {processor.py:153} INFO - Started process (PID=7847) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:59:36.994+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T11:59:36.995+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:59:36.995+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:59:37.049+0000] {logging_mixin.py:137} INFO - [2023-03-23T11:59:37.048+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T11:59:37.050+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T11:59:37.073+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.087 seconds
[2023-03-23T12:00:07.930+0000] {processor.py:153} INFO - Started process (PID=7921) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:00:07.932+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:00:07.933+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:00:07.933+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:00:08.018+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:00:08.016+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:00:08.019+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:00:08.074+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.151 seconds
[2023-03-23T12:00:38.397+0000] {processor.py:153} INFO - Started process (PID=7992) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:00:38.411+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:00:38.414+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:00:38.413+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:00:38.634+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:00:38.632+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:00:38.635+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:00:38.717+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.338 seconds
[2023-03-23T12:01:09.495+0000] {processor.py:153} INFO - Started process (PID=8065) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:01:09.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:01:09.509+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:01:09.508+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:01:09.648+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:01:09.644+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:01:09.649+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:01:09.744+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.266 seconds
[2023-03-23T12:01:40.300+0000] {processor.py:153} INFO - Started process (PID=8127) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:01:40.303+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:01:40.307+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:01:40.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:01:40.354+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:01:40.352+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:01:40.355+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:01:40.398+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.104 seconds
[2023-03-23T12:02:10.512+0000] {processor.py:153} INFO - Started process (PID=8193) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:02:10.515+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:02:10.517+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:02:10.517+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:02:10.561+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:02:10.558+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:02:10.564+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:02:10.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.093 seconds
[2023-03-23T12:02:41.261+0000] {processor.py:153} INFO - Started process (PID=8266) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:02:41.272+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:02:41.276+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:02:41.276+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:02:41.359+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:02:41.357+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:02:41.360+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:02:41.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.211 seconds
[2023-03-23T12:03:12.135+0000] {processor.py:153} INFO - Started process (PID=8323) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:03:12.137+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:03:12.138+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:03:12.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:03:12.172+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:03:12.170+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:03:12.173+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:03:12.206+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.076 seconds
[2023-03-23T12:03:42.592+0000] {processor.py:153} INFO - Started process (PID=8396) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:03:42.594+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:03:42.595+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:03:42.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:03:42.631+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:03:42.629+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:03:42.632+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:03:42.679+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.092 seconds
[2023-03-23T12:04:13.314+0000] {processor.py:153} INFO - Started process (PID=8469) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:04:13.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:04:13.316+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:04:13.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:04:13.344+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:04:13.343+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:04:13.345+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:04:13.363+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.053 seconds
[2023-03-23T12:04:43.678+0000] {processor.py:153} INFO - Started process (PID=8542) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:04:43.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:04:43.680+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:04:43.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:04:43.709+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:04:43.708+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:04:43.710+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:04:43.737+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T12:05:14.146+0000] {processor.py:153} INFO - Started process (PID=8615) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:05:14.147+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:05:14.148+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:05:14.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:05:14.180+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:05:14.179+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:05:14.180+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:05:14.199+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.058 seconds
[2023-03-23T12:05:44.282+0000] {processor.py:153} INFO - Started process (PID=8697) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:05:44.283+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:05:44.284+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:05:44.284+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:05:44.320+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:05:44.318+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:05:44.321+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:05:44.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.072 seconds
[2023-03-23T12:06:15.219+0000] {processor.py:153} INFO - Started process (PID=8776) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:06:15.221+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:06:15.222+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:06:15.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:06:15.259+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:06:15.257+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:06:15.260+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:06:15.373+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.159 seconds
[2023-03-23T12:06:45.431+0000] {processor.py:153} INFO - Started process (PID=8849) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:06:45.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:06:45.434+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:06:45.434+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:06:45.473+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:06:45.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:06:45.474+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:06:45.499+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T12:07:15.704+0000] {processor.py:153} INFO - Started process (PID=8922) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:07:15.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:07:15.707+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:07:15.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:07:15.752+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:07:15.751+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:07:15.753+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:07:15.781+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.079 seconds
[2023-03-23T12:07:45.973+0000] {processor.py:153} INFO - Started process (PID=8996) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:07:45.977+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:07:45.980+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:07:45.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:07:46.013+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:07:46.011+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:07:46.013+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:07:46.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.087 seconds
[2023-03-23T12:08:16.116+0000] {processor.py:153} INFO - Started process (PID=9069) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:08:16.117+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:08:16.119+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:08:16.119+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:08:16.157+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:08:16.156+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:08:16.158+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:08:16.184+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T12:08:46.309+0000] {processor.py:153} INFO - Started process (PID=9156) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:08:46.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:08:46.311+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:08:46.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:08:46.330+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:08:46.329+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:08:46.331+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:08:46.356+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.050 seconds
[2023-03-23T12:09:16.522+0000] {processor.py:153} INFO - Started process (PID=9224) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:09:16.523+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:09:16.525+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:09:16.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:09:16.556+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:09:16.554+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:09:16.557+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:09:16.590+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.081 seconds
[2023-03-23T12:09:47.564+0000] {processor.py:153} INFO - Started process (PID=9297) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:09:47.566+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:09:47.570+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:09:47.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:09:47.661+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:09:47.659+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:09:47.662+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:09:47.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.145 seconds
[2023-03-23T12:10:17.865+0000] {processor.py:153} INFO - Started process (PID=9370) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:10:17.867+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:10:17.868+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:10:17.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:10:17.907+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:10:17.905+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:10:17.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:10:17.947+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.085 seconds
[2023-03-23T12:10:48.483+0000] {processor.py:153} INFO - Started process (PID=9443) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:10:48.484+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:10:48.485+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:10:48.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:10:48.508+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:10:48.507+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:10:48.509+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:10:48.531+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.052 seconds
[2023-03-23T12:11:19.439+0000] {processor.py:153} INFO - Started process (PID=9525) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:11:19.440+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:11:19.441+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:11:19.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:11:19.463+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:11:19.462+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:11:19.463+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:11:19.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.056 seconds
[2023-03-23T12:11:49.568+0000] {processor.py:153} INFO - Started process (PID=9605) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:11:49.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:11:49.570+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:11:49.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:11:49.596+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:11:49.595+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:11:49.597+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:11:49.622+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T12:12:20.092+0000] {processor.py:153} INFO - Started process (PID=9669) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:12:20.094+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:12:20.099+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:12:20.097+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:12:20.174+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:12:20.172+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:12:20.179+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:12:20.252+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.168 seconds
[2023-03-23T12:12:50.474+0000] {processor.py:153} INFO - Started process (PID=9733) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:12:50.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:12:50.478+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:12:50.478+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:12:50.511+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:12:50.510+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:12:50.512+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:12:50.535+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T12:13:21.479+0000] {processor.py:153} INFO - Started process (PID=9806) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:13:21.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:13:21.481+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:13:21.481+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:13:21.510+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:13:21.509+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:13:21.511+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:13:21.535+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T12:13:51.926+0000] {processor.py:153} INFO - Started process (PID=9878) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:13:51.928+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:13:51.930+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:13:51.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:13:51.964+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:13:51.962+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:13:51.965+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:13:51.993+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T12:14:22.405+0000] {processor.py:153} INFO - Started process (PID=9960) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:14:22.406+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:14:22.408+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:14:22.407+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:14:22.456+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:14:22.454+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:14:22.463+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:14:22.514+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.113 seconds
[2023-03-23T12:14:53.212+0000] {processor.py:153} INFO - Started process (PID=10040) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:14:53.214+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:14:53.215+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:14:53.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:14:53.281+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:14:53.279+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:14:53.281+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:14:53.315+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.107 seconds
[2023-03-23T12:15:24.049+0000] {processor.py:153} INFO - Started process (PID=10114) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:15:24.050+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:15:24.052+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:15:24.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:15:24.084+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:15:24.083+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:15:24.086+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:15:24.112+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T12:15:54.292+0000] {processor.py:153} INFO - Started process (PID=10187) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:15:54.293+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:15:54.295+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:15:54.294+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:15:54.330+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:15:54.328+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:15:54.331+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:15:54.360+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.073 seconds
[2023-03-23T12:16:24.728+0000] {processor.py:153} INFO - Started process (PID=10260) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:16:24.730+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:16:24.731+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:16:24.731+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:16:24.772+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:16:24.770+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:16:24.773+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:16:24.803+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.081 seconds
[2023-03-23T12:16:54.886+0000] {processor.py:153} INFO - Started process (PID=10332) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:16:54.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:16:54.889+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:16:54.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:16:54.949+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:16:54.947+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:16:54.950+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:16:54.985+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.103 seconds
[2023-03-23T12:17:25.118+0000] {processor.py:153} INFO - Started process (PID=10405) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:17:25.119+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:17:25.120+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:17:25.120+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:17:25.145+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:17:25.144+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:17:25.146+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:17:25.165+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.050 seconds
[2023-03-23T12:17:55.304+0000] {processor.py:153} INFO - Started process (PID=10478) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:17:55.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:17:55.307+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:17:55.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:17:55.327+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:17:55.326+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:17:55.327+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:17:55.350+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.049 seconds
[2023-03-23T12:18:25.877+0000] {processor.py:153} INFO - Started process (PID=10550) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:18:25.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:18:25.879+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:18:25.879+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:18:25.926+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:18:25.925+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:18:25.927+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:18:25.949+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T12:18:56.435+0000] {processor.py:153} INFO - Started process (PID=10623) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:18:56.437+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:18:56.439+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:18:56.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:18:56.477+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:18:56.475+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:18:56.478+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:18:56.509+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T12:19:26.957+0000] {processor.py:153} INFO - Started process (PID=10696) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:19:26.958+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:19:26.959+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:19:26.959+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:19:26.992+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:19:26.991+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:19:26.993+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:19:27.020+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T12:19:58.085+0000] {processor.py:153} INFO - Started process (PID=10769) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:19:58.087+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:19:58.090+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:19:58.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:19:58.145+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:19:58.143+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:19:58.147+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:19:58.180+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.103 seconds
[2023-03-23T12:20:28.440+0000] {processor.py:153} INFO - Started process (PID=10843) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:20:28.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:20:28.443+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:20:28.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:20:28.487+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:20:28.486+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:20:28.488+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:20:28.519+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.086 seconds
[2023-03-23T12:20:58.756+0000] {processor.py:153} INFO - Started process (PID=10917) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:20:58.758+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:20:58.760+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:20:58.760+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:20:58.800+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:20:58.798+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:20:58.801+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:20:58.827+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.078 seconds
[2023-03-23T12:21:28.919+0000] {processor.py:153} INFO - Started process (PID=10997) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:21:28.921+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:21:28.923+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:21:28.922+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:21:28.955+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:21:28.954+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:21:28.956+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:21:28.987+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.073 seconds
[2023-03-23T12:21:59.462+0000] {processor.py:153} INFO - Started process (PID=11072) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:21:59.465+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:21:59.467+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:21:59.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:21:59.507+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:21:59.505+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:21:59.508+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:21:59.545+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.091 seconds
[2023-03-23T12:22:30.620+0000] {processor.py:153} INFO - Started process (PID=11152) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:22:30.623+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:22:30.625+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:22:30.625+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:22:30.677+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:22:30.674+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:22:30.679+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:22:30.730+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.122 seconds
[2023-03-23T12:23:01.501+0000] {processor.py:153} INFO - Started process (PID=11225) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:23:01.504+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:23:01.507+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:23:01.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:23:01.587+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:23:01.585+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:23:01.588+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:23:01.647+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.154 seconds
[2023-03-23T12:23:31.986+0000] {processor.py:153} INFO - Started process (PID=11291) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:23:31.988+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:23:31.989+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:23:31.989+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:23:32.019+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:23:32.018+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:23:32.020+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:23:32.083+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.102 seconds
[2023-03-23T12:24:02.173+0000] {processor.py:153} INFO - Started process (PID=11364) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:24:02.174+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:24:02.176+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:24:02.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:24:02.215+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:24:02.214+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:24:02.217+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:24:02.337+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.170 seconds
[2023-03-23T12:24:33.176+0000] {processor.py:153} INFO - Started process (PID=11437) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:24:33.179+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:24:33.182+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:24:33.182+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:24:33.449+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:24:33.446+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:24:33.459+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:24:33.565+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.396 seconds
[2023-03-23T12:25:04.010+0000] {processor.py:153} INFO - Started process (PID=11517) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:25:04.011+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:25:04.014+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:25:04.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:25:04.062+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:25:04.058+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:25:04.064+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:25:04.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.102 seconds
[2023-03-23T12:25:34.513+0000] {processor.py:153} INFO - Started process (PID=11590) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:25:34.514+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:25:34.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:25:34.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:25:34.544+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:25:34.543+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:25:34.545+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:25:34.565+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.055 seconds
[2023-03-23T12:26:05.422+0000] {processor.py:153} INFO - Started process (PID=11663) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:26:05.428+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:26:05.430+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:26:05.430+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:26:05.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:26:05.511+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:26:05.516+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:26:05.562+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.146 seconds
[2023-03-23T12:26:35.851+0000] {processor.py:153} INFO - Started process (PID=11737) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:26:35.852+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:26:35.854+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:26:35.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:26:35.888+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:26:35.884+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:26:35.889+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:26:35.915+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T12:27:06.498+0000] {processor.py:153} INFO - Started process (PID=11810) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:27:06.500+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:27:06.502+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:27:06.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:27:06.536+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:27:06.534+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:27:06.537+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:27:06.576+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T12:27:36.874+0000] {processor.py:153} INFO - Started process (PID=11883) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:27:36.876+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:27:36.876+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:27:36.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:27:36.913+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:27:36.911+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:27:36.914+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:27:36.962+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.092 seconds
[2023-03-23T12:28:07.660+0000] {processor.py:153} INFO - Started process (PID=11965) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:28:07.662+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:28:07.663+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:28:07.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:28:07.705+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:28:07.701+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:28:07.707+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:28:07.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.105 seconds
[2023-03-23T12:28:38.376+0000] {processor.py:153} INFO - Started process (PID=12045) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:28:38.379+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:28:38.381+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:28:38.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:28:38.416+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:28:38.414+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:28:38.417+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:28:38.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.097 seconds
[2023-03-23T12:29:09.202+0000] {processor.py:153} INFO - Started process (PID=12118) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:29:09.207+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:29:09.209+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:29:09.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:29:09.261+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:29:09.258+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:29:09.262+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:29:09.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.229 seconds
[2023-03-23T12:29:39.819+0000] {processor.py:153} INFO - Started process (PID=12191) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:29:39.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:29:39.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:29:39.822+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:29:39.888+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:29:39.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:29:39.889+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:29:39.909+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.094 seconds
[2023-03-23T12:30:10.285+0000] {processor.py:153} INFO - Started process (PID=12280) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:30:10.287+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:30:10.288+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:30:10.287+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:30:10.316+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:30:10.315+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:30:10.317+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:30:10.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T12:30:40.918+0000] {processor.py:153} INFO - Started process (PID=12353) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:30:40.920+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:30:40.921+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:30:40.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:30:40.949+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:30:40.948+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:30:40.950+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:30:40.971+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.058 seconds
[2023-03-23T12:31:11.581+0000] {processor.py:153} INFO - Started process (PID=12442) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:31:11.582+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:31:11.584+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:31:11.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:31:11.622+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:31:11.620+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:31:11.623+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:31:11.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.078 seconds
[2023-03-23T12:31:42.105+0000] {processor.py:153} INFO - Started process (PID=12515) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:31:42.106+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:31:42.108+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:31:42.107+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:31:42.150+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:31:42.149+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:31:42.151+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:31:42.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.091 seconds
[2023-03-23T12:32:12.330+0000] {processor.py:153} INFO - Started process (PID=12588) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:32:12.332+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:32:12.333+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:32:12.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:32:12.365+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:32:12.364+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:32:12.366+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:32:12.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T12:32:43.223+0000] {processor.py:153} INFO - Started process (PID=12671) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:32:43.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:32:43.229+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:32:43.229+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:32:43.273+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:32:43.270+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:32:43.274+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:32:43.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.126 seconds
[2023-03-23T12:33:14.059+0000] {processor.py:153} INFO - Started process (PID=12751) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:33:14.063+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:33:14.064+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:33:14.064+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:33:14.104+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:33:14.103+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:33:14.105+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:33:14.152+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.099 seconds
[2023-03-23T12:33:44.873+0000] {processor.py:153} INFO - Started process (PID=12824) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:33:44.875+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:33:44.876+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:33:44.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:33:44.899+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:33:44.898+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:33:44.899+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:33:44.919+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.053 seconds
[2023-03-23T12:34:15.273+0000] {processor.py:153} INFO - Started process (PID=12913) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:34:15.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:34:15.285+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:34:15.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:34:15.367+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:34:15.364+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:34:15.369+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:34:15.441+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.174 seconds
[2023-03-23T12:34:46.209+0000] {processor.py:153} INFO - Started process (PID=12986) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:34:46.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:34:46.211+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:34:46.211+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:34:46.246+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:34:46.244+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:34:46.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:34:46.273+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.069 seconds
[2023-03-23T12:35:16.389+0000] {processor.py:153} INFO - Started process (PID=13068) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:35:16.390+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:35:16.392+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:35:16.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:35:16.422+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:35:16.420+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:35:16.423+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:35:16.452+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T12:35:46.600+0000] {processor.py:153} INFO - Started process (PID=13149) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:35:46.601+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:35:46.602+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:35:46.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:35:46.633+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:35:46.632+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:35:46.634+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:35:46.659+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T12:36:17.584+0000] {processor.py:153} INFO - Started process (PID=13222) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:36:17.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:36:17.592+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:36:17.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:36:17.646+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:36:17.644+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:36:17.647+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:36:17.715+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.137 seconds
[2023-03-23T12:36:47.858+0000] {processor.py:153} INFO - Started process (PID=13311) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:36:47.861+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:36:47.863+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:36:47.863+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:36:47.901+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:36:47.899+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:36:47.902+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:36:47.934+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.081 seconds
[2023-03-23T12:37:18.757+0000] {processor.py:153} INFO - Started process (PID=13384) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:37:18.759+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:37:18.761+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:37:18.761+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:37:18.803+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:37:18.801+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:37:18.804+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:37:18.832+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T12:37:49.477+0000] {processor.py:153} INFO - Started process (PID=13457) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:37:49.478+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:37:49.479+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:37:49.479+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:37:49.509+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:37:49.508+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:37:49.510+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:37:49.533+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.059 seconds
[2023-03-23T12:38:19.777+0000] {processor.py:153} INFO - Started process (PID=13546) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:38:19.779+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:38:19.781+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:38:19.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:38:19.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:38:19.819+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:38:19.823+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:38:19.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.104 seconds
[2023-03-23T12:38:50.738+0000] {processor.py:153} INFO - Started process (PID=13619) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:38:50.739+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:38:50.739+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:38:50.739+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:38:50.765+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:38:50.763+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:38:50.766+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:38:50.789+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T12:39:20.900+0000] {processor.py:153} INFO - Started process (PID=13708) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:39:20.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:39:20.903+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:39:20.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:39:20.942+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:39:20.940+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:39:20.943+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:39:20.986+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.092 seconds
[2023-03-23T12:39:51.979+0000] {processor.py:153} INFO - Started process (PID=13781) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:39:51.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:39:51.981+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:39:51.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:39:52.008+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:39:52.007+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:39:52.008+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:39:52.027+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.052 seconds
[2023-03-23T12:40:22.249+0000] {processor.py:153} INFO - Started process (PID=13870) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:40:22.251+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:40:22.253+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:40:22.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:40:22.294+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:40:22.292+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:40:22.295+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:40:22.345+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.101 seconds
[2023-03-23T12:40:53.381+0000] {processor.py:153} INFO - Started process (PID=13943) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:40:53.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:40:53.383+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:40:53.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:40:53.404+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:40:53.403+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:40:53.405+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:40:53.428+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.050 seconds
[2023-03-23T12:41:24.014+0000] {processor.py:153} INFO - Started process (PID=14016) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:41:24.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:41:24.019+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:41:24.019+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:41:24.070+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:41:24.067+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:41:24.071+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:41:24.115+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.106 seconds
[2023-03-23T12:41:54.986+0000] {processor.py:153} INFO - Started process (PID=14089) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:41:54.988+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:41:54.989+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:41:54.989+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:41:55.021+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:41:55.020+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:41:55.022+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:41:55.046+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T12:42:25.414+0000] {processor.py:153} INFO - Started process (PID=14178) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:42:25.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:42:25.419+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:42:25.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:42:25.465+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:42:25.463+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:42:25.467+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:42:25.499+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.090 seconds
[2023-03-23T12:42:55.750+0000] {processor.py:153} INFO - Started process (PID=14251) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:42:55.751+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:42:55.752+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:42:55.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:42:55.845+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:42:55.844+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:42:55.846+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:42:55.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.120 seconds
[2023-03-23T12:43:26.033+0000] {processor.py:153} INFO - Started process (PID=14333) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:43:26.035+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:43:26.036+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:43:26.036+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:43:26.067+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:43:26.065+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:43:26.068+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:43:26.096+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T12:43:56.682+0000] {processor.py:153} INFO - Started process (PID=14413) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:43:56.684+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:43:56.685+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:43:56.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:43:56.710+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:43:56.709+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:43:56.710+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:43:56.859+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.180 seconds
[2023-03-23T12:44:27.016+0000] {processor.py:153} INFO - Started process (PID=14486) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:44:27.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:44:27.017+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:44:27.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:44:27.035+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:44:27.034+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:44:27.035+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:44:27.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.043 seconds
[2023-03-23T12:44:57.904+0000] {processor.py:153} INFO - Started process (PID=14575) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:44:57.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:44:57.906+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:44:57.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:44:57.956+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:44:57.955+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:44:57.957+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:44:58.129+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.229 seconds
[2023-03-23T12:45:28.842+0000] {processor.py:153} INFO - Started process (PID=14648) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:45:28.844+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:45:28.846+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:45:28.846+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:45:28.884+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:45:28.882+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:45:28.886+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:45:29.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.323 seconds
[2023-03-23T12:46:00.104+0000] {processor.py:153} INFO - Started process (PID=14723) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:46:00.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:46:00.106+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:46:00.106+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:46:00.148+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:46:00.146+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:46:00.148+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:46:00.171+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T12:46:30.334+0000] {processor.py:153} INFO - Started process (PID=14809) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:46:30.336+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:46:30.337+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:46:30.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:46:30.391+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:46:30.389+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:46:30.392+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:46:30.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.120 seconds
[2023-03-23T12:47:01.315+0000] {processor.py:153} INFO - Started process (PID=14883) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:47:01.317+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:47:01.318+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:47:01.318+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:47:01.340+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:47:01.339+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:47:01.340+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:47:01.363+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.050 seconds
[2023-03-23T12:47:31.735+0000] {processor.py:153} INFO - Started process (PID=14965) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:47:31.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:47:31.739+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:47:31.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:47:31.775+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:47:31.773+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:47:31.777+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:47:31.811+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.080 seconds
[2023-03-23T12:48:01.965+0000] {processor.py:153} INFO - Started process (PID=15045) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:48:01.966+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:48:01.967+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:48:01.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:48:02.000+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:48:01.999+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:48:02.001+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:48:02.029+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T12:48:32.393+0000] {processor.py:153} INFO - Started process (PID=15118) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:48:32.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:48:32.396+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:48:32.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:48:32.430+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:48:32.429+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:48:32.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:48:32.461+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T12:49:03.424+0000] {processor.py:153} INFO - Started process (PID=15207) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:49:03.426+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:49:03.427+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:49:03.427+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:49:03.466+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:49:03.465+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:49:03.467+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:49:03.493+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.072 seconds
[2023-03-23T12:49:34.266+0000] {processor.py:153} INFO - Started process (PID=15280) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:49:34.268+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:49:34.270+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:49:34.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:49:34.308+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:49:34.306+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:49:34.310+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:49:34.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.088 seconds
[2023-03-23T12:50:04.461+0000] {processor.py:153} INFO - Started process (PID=15363) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:50:04.463+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:50:04.464+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:50:04.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:50:04.495+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:50:04.494+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:50:04.496+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:50:04.517+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.059 seconds
[2023-03-23T12:50:34.904+0000] {processor.py:153} INFO - Started process (PID=15443) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:50:34.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:50:34.906+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:50:34.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:50:34.934+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:50:34.932+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:50:34.935+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:50:34.960+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T12:51:05.634+0000] {processor.py:153} INFO - Started process (PID=15517) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:51:05.636+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:51:05.638+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:51:05.638+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:51:05.680+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:51:05.678+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:51:05.681+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:51:05.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T12:51:36.345+0000] {processor.py:153} INFO - Started process (PID=15606) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:51:36.347+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:51:36.349+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:51:36.349+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:51:36.388+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:51:36.386+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:51:36.389+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:51:36.416+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T12:52:06.601+0000] {processor.py:153} INFO - Started process (PID=15679) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:52:06.602+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:52:06.603+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:52:06.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:52:06.634+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:52:06.632+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:52:06.635+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:52:06.657+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.059 seconds
[2023-03-23T12:52:37.243+0000] {processor.py:153} INFO - Started process (PID=15762) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:52:37.244+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:52:37.245+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:52:37.245+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:52:37.279+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:52:37.277+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:52:37.280+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:52:37.308+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T12:53:07.943+0000] {processor.py:153} INFO - Started process (PID=15842) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:53:07.944+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:53:07.945+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:53:07.945+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:53:07.967+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:53:07.966+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:53:07.968+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:53:07.994+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T12:53:38.175+0000] {processor.py:153} INFO - Started process (PID=15915) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:53:38.186+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:53:38.188+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:53:38.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:53:38.245+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:53:38.243+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:53:38.247+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:53:38.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.129 seconds
[2023-03-23T12:54:09.039+0000] {processor.py:153} INFO - Started process (PID=16004) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:54:09.040+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:54:09.041+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:54:09.040+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:54:09.062+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:54:09.061+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:54:09.063+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:54:09.080+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.044 seconds
[2023-03-23T12:54:39.380+0000] {processor.py:153} INFO - Started process (PID=16077) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:54:39.381+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:54:39.384+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:54:39.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:54:39.421+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:54:39.419+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:54:39.422+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:54:39.464+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.090 seconds
[2023-03-23T12:55:09.529+0000] {processor.py:153} INFO - Started process (PID=16150) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:55:09.530+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:55:09.531+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:55:09.531+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:55:09.564+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:55:09.563+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:55:09.565+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:55:09.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.076 seconds
[2023-03-23T12:55:40.326+0000] {processor.py:153} INFO - Started process (PID=16239) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:55:40.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:55:40.329+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:55:40.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:55:40.356+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:55:40.355+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:55:40.357+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:55:40.384+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T12:56:10.480+0000] {processor.py:153} INFO - Started process (PID=16312) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:56:10.481+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:56:10.483+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:56:10.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:56:10.513+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:56:10.512+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:56:10.514+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:56:10.536+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.059 seconds
[2023-03-23T12:56:40.683+0000] {processor.py:153} INFO - Started process (PID=16383) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:56:40.684+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:56:40.685+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:56:40.685+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:56:40.716+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:56:40.715+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:56:40.717+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:56:40.741+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T12:57:10.819+0000] {processor.py:153} INFO - Started process (PID=16465) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:57:10.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:57:10.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:57:10.821+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:57:10.846+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:57:10.845+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:57:10.847+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:57:10.868+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.052 seconds
[2023-03-23T12:57:41.195+0000] {processor.py:153} INFO - Started process (PID=16538) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:57:41.196+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:57:41.197+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:57:41.197+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:57:41.227+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:57:41.226+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:57:41.228+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:57:41.251+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T12:58:11.362+0000] {processor.py:153} INFO - Started process (PID=16620) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:58:11.363+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:58:11.364+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:58:11.364+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:58:11.396+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:58:11.395+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:58:11.397+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:58:11.419+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T12:58:41.615+0000] {processor.py:153} INFO - Started process (PID=16700) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:58:41.616+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:58:41.617+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:58:41.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:58:41.638+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:58:41.637+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:58:41.639+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:58:41.660+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.048 seconds
[2023-03-23T12:59:11.739+0000] {processor.py:153} INFO - Started process (PID=16773) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:59:11.740+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:59:11.741+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:59:11.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:59:11.765+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:59:11.764+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:59:11.766+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:59:11.783+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.047 seconds
[2023-03-23T12:59:42.468+0000] {processor.py:153} INFO - Started process (PID=16862) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:59:42.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T12:59:42.470+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:59:42.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:59:42.502+0000] {logging_mixin.py:137} INFO - [2023-03-23T12:59:42.500+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T12:59:42.502+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T12:59:42.528+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:00:13.249+0000] {processor.py:153} INFO - Started process (PID=16935) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:00:13.250+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:00:13.252+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:00:13.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:00:13.278+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:00:13.277+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:00:13.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:00:13.308+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T13:00:44.189+0000] {processor.py:153} INFO - Started process (PID=17008) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:00:44.191+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:00:44.192+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:00:44.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:00:44.223+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:00:44.222+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:00:44.224+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:00:44.246+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.059 seconds
[2023-03-23T13:01:14.377+0000] {processor.py:153} INFO - Started process (PID=17098) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:01:14.378+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:01:14.380+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:01:14.380+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:01:14.413+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:01:14.411+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:01:14.414+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:01:14.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T13:01:45.249+0000] {processor.py:153} INFO - Started process (PID=17171) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:01:45.250+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:01:45.251+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:01:45.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:01:45.277+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:01:45.275+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:01:45.277+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:01:45.297+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.052 seconds
[2023-03-23T13:02:15.743+0000] {processor.py:153} INFO - Started process (PID=17253) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:02:15.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:02:15.746+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:02:15.746+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:02:15.791+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:02:15.789+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:02:15.792+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:02:15.848+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.109 seconds
[2023-03-23T13:02:45.987+0000] {processor.py:153} INFO - Started process (PID=17333) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:02:45.989+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:02:45.990+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:02:45.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:02:46.026+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:02:46.025+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:02:46.027+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:02:46.054+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T13:03:16.357+0000] {processor.py:153} INFO - Started process (PID=17406) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:03:16.359+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:03:16.360+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:03:16.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:03:16.395+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:03:16.394+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:03:16.396+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:03:16.420+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.069 seconds
[2023-03-23T13:03:47.137+0000] {processor.py:153} INFO - Started process (PID=17478) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:03:47.138+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:03:47.140+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:03:47.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:03:47.164+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:03:47.163+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:03:47.165+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:03:47.185+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.051 seconds
[2023-03-23T13:04:17.591+0000] {processor.py:153} INFO - Started process (PID=17567) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:04:17.614+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:04:17.616+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:04:17.616+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:04:17.703+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:04:17.701+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:04:17.704+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:04:17.733+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.149 seconds
[2023-03-23T13:04:48.418+0000] {processor.py:153} INFO - Started process (PID=17640) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:04:48.420+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:04:48.421+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:04:48.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:04:48.456+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:04:48.455+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:04:48.456+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:04:48.476+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T13:05:18.725+0000] {processor.py:153} INFO - Started process (PID=17721) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:05:18.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:05:18.728+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:05:18.727+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:05:18.768+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:05:18.767+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:05:18.770+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:05:18.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T13:05:49.085+0000] {processor.py:153} INFO - Started process (PID=17801) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:05:49.086+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:05:49.087+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:05:49.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:05:49.127+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:05:49.126+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:05:49.129+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:05:49.153+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.073 seconds
[2023-03-23T13:06:19.393+0000] {processor.py:153} INFO - Started process (PID=17874) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:06:19.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:06:19.395+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:06:19.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:06:19.426+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:06:19.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:06:19.427+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:06:19.449+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T13:06:49.491+0000] {processor.py:153} INFO - Started process (PID=17963) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:06:49.492+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:06:49.493+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:06:49.493+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:06:49.513+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:06:49.512+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:06:49.514+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:06:49.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.051 seconds
[2023-03-23T13:07:19.605+0000] {processor.py:153} INFO - Started process (PID=18036) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:07:19.607+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:07:19.608+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:07:19.608+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:07:19.648+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:07:19.647+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:07:19.649+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:07:19.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T13:07:50.208+0000] {processor.py:153} INFO - Started process (PID=18125) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:07:50.209+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:07:50.210+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:07:50.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:07:50.256+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:07:50.255+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:07:50.257+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:07:50.278+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T13:08:20.779+0000] {processor.py:153} INFO - Started process (PID=18198) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:08:20.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:08:20.782+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:08:20.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:08:20.816+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:08:20.815+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:08:20.817+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:08:20.864+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.088 seconds
[2023-03-23T13:08:51.326+0000] {processor.py:153} INFO - Started process (PID=18287) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:08:51.327+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:08:51.329+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:08:51.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:08:51.355+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:08:51.354+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:08:51.356+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:08:51.379+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.056 seconds
[2023-03-23T13:09:22.006+0000] {processor.py:153} INFO - Started process (PID=18360) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:09:22.028+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:09:22.030+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:09:22.030+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:09:22.056+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:09:22.054+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:09:22.056+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:09:22.092+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.090 seconds
[2023-03-23T13:09:52.458+0000] {processor.py:153} INFO - Started process (PID=18449) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:09:52.460+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:09:52.461+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:09:52.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:09:52.487+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:09:52.485+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:09:52.488+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:09:52.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.058 seconds
[2023-03-23T13:10:22.891+0000] {processor.py:153} INFO - Started process (PID=18522) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:10:22.892+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:10:22.893+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:10:22.893+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:10:22.918+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:10:22.917+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:10:22.919+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:10:22.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.053 seconds
[2023-03-23T13:10:53.603+0000] {processor.py:153} INFO - Started process (PID=18595) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:10:53.604+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:10:53.605+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:10:53.605+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:10:53.636+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:10:53.635+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:10:53.637+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:10:53.664+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T13:11:23.768+0000] {processor.py:153} INFO - Started process (PID=18684) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:11:23.769+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:11:23.770+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:11:23.770+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:11:23.813+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:11:23.812+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:11:23.814+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:11:23.832+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T13:11:54.290+0000] {processor.py:153} INFO - Started process (PID=18757) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:11:54.291+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:11:54.292+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:11:54.292+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:11:54.319+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:11:54.317+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:11:54.320+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:11:54.345+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.058 seconds
[2023-03-23T13:12:24.438+0000] {processor.py:153} INFO - Started process (PID=18846) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:12:24.440+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:12:24.442+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:12:24.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:12:24.470+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:12:24.469+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:12:24.471+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:12:24.495+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:12:55.022+0000] {processor.py:153} INFO - Started process (PID=18919) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:12:55.023+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:12:55.024+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:12:55.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:12:55.042+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:12:55.041+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:12:55.042+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:12:55.059+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.040 seconds
[2023-03-23T13:13:25.424+0000] {processor.py:153} INFO - Started process (PID=18992) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:13:25.425+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:13:25.426+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:13:25.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:13:25.447+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:13:25.446+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:13:25.448+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:13:25.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.234 seconds
[2023-03-23T13:13:56.094+0000] {processor.py:153} INFO - Started process (PID=19081) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:13:56.095+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:13:56.096+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:13:56.095+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:13:56.124+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:13:56.123+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:13:56.125+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:13:56.145+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T13:14:26.848+0000] {processor.py:153} INFO - Started process (PID=19154) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:14:26.850+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:14:26.854+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:14:26.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:14:26.900+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:14:26.897+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:14:26.901+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:14:26.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.088 seconds
[2023-03-23T13:14:57.508+0000] {processor.py:153} INFO - Started process (PID=19243) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:14:57.509+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:14:57.510+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:14:57.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:14:57.541+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:14:57.540+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:14:57.542+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:14:57.571+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T13:15:27.637+0000] {processor.py:153} INFO - Started process (PID=19316) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:15:27.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:15:27.639+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:15:27.639+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:15:27.677+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:15:27.676+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:15:27.680+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:15:27.704+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T13:15:57.796+0000] {processor.py:153} INFO - Started process (PID=19405) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:15:57.798+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:15:57.799+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:15:57.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:15:57.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:15:57.820+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:15:57.823+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:15:57.845+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T13:16:28.415+0000] {processor.py:153} INFO - Started process (PID=19478) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:16:28.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:16:28.417+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:16:28.417+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:16:28.444+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:16:28.443+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:16:28.445+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:16:28.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.216 seconds
[2023-03-23T13:16:59.305+0000] {processor.py:153} INFO - Started process (PID=19566) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:16:59.307+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:16:59.308+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:16:59.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:16:59.342+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:16:59.340+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:16:59.343+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:16:59.366+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T13:17:29.526+0000] {processor.py:153} INFO - Started process (PID=19639) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:17:29.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:17:29.529+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:17:29.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:17:29.563+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:17:29.562+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:17:29.564+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:17:29.585+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:17:59.857+0000] {processor.py:153} INFO - Started process (PID=19712) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:17:59.858+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:17:59.860+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:17:59.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:17:59.883+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:17:59.882+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:17:59.884+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:17:59.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.075 seconds
[2023-03-23T13:18:30.383+0000] {processor.py:153} INFO - Started process (PID=19801) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:18:30.398+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:18:30.399+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:18:30.399+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:18:30.457+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:18:30.455+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:18:30.458+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:18:30.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.110 seconds
[2023-03-23T13:19:00.717+0000] {processor.py:153} INFO - Started process (PID=19874) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:19:00.718+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:19:00.719+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:19:00.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:19:00.757+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:19:00.755+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:19:00.758+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:19:00.779+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T13:19:31.063+0000] {processor.py:153} INFO - Started process (PID=19947) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:19:31.064+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:19:31.065+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:19:31.065+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:19:31.092+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:19:31.091+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:19:31.093+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:19:31.113+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.053 seconds
[2023-03-23T13:20:01.283+0000] {processor.py:153} INFO - Started process (PID=20036) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:20:01.284+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:20:01.285+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:20:01.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:20:01.312+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:20:01.311+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:20:01.313+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:20:01.336+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T13:20:31.385+0000] {processor.py:153} INFO - Started process (PID=20109) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:20:31.386+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:20:31.387+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:20:31.387+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:20:31.407+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:20:31.406+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:20:31.407+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:20:31.426+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.043 seconds
[2023-03-23T13:21:01.676+0000] {processor.py:153} INFO - Started process (PID=20182) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:21:01.678+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:21:01.679+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:21:01.679+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:21:01.699+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:21:01.698+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:21:01.700+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:21:01.740+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T13:21:32.252+0000] {processor.py:153} INFO - Started process (PID=20271) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:21:32.255+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:21:32.260+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:21:32.259+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:21:32.294+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:21:32.293+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:21:32.295+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:21:32.329+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.083 seconds
[2023-03-23T13:22:02.937+0000] {processor.py:153} INFO - Started process (PID=20344) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:22:02.938+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:22:02.940+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:22:02.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:22:02.965+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:22:02.964+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:22:02.967+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:22:02.992+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T13:22:33.096+0000] {processor.py:153} INFO - Started process (PID=20433) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:22:33.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:22:33.098+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:22:33.097+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:22:33.131+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:22:33.129+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:22:33.132+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:22:33.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T13:23:03.568+0000] {processor.py:153} INFO - Started process (PID=20506) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:23:03.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:23:03.570+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:23:03.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:23:03.594+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:23:03.593+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:23:03.595+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:23:03.617+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.053 seconds
[2023-03-23T13:23:33.734+0000] {processor.py:153} INFO - Started process (PID=20595) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:23:33.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:23:33.737+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:23:33.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:23:33.770+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:23:33.769+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:23:33.771+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:23:33.791+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:24:04.150+0000] {processor.py:153} INFO - Started process (PID=20668) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:24:04.151+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:24:04.152+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:24:04.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:24:04.170+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:24:04.170+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:24:04.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:24:04.189+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.042 seconds
[2023-03-23T13:24:35.084+0000] {processor.py:153} INFO - Started process (PID=20758) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:24:35.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:24:35.086+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:24:35.086+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:24:35.122+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:24:35.120+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:24:35.124+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:24:35.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T13:25:05.392+0000] {processor.py:153} INFO - Started process (PID=20831) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:25:05.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:25:05.395+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:25:05.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:25:05.425+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:25:05.423+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:25:05.425+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:25:05.453+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T13:25:35.526+0000] {processor.py:153} INFO - Started process (PID=20904) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:25:35.527+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:25:35.529+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:25:35.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:25:35.570+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:25:35.569+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:25:35.571+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:25:35.593+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T13:26:05.858+0000] {processor.py:153} INFO - Started process (PID=20993) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:26:05.859+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:26:05.860+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:26:05.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:26:05.900+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:26:05.899+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:26:05.901+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:26:05.926+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T13:26:36.013+0000] {processor.py:153} INFO - Started process (PID=21066) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:26:36.014+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:26:36.015+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:26:36.015+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:26:36.045+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:26:36.044+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:26:36.046+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:26:36.071+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:27:06.533+0000] {processor.py:153} INFO - Started process (PID=21155) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:27:06.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:27:06.535+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:27:06.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:27:06.565+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:27:06.564+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:27:06.566+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:27:06.586+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T13:27:37.013+0000] {processor.py:153} INFO - Started process (PID=21228) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:27:37.014+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:27:37.015+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:27:37.015+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:27:37.038+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:27:37.037+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:27:37.039+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:27:37.060+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.051 seconds
[2023-03-23T13:28:07.902+0000] {processor.py:153} INFO - Started process (PID=21310) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:28:07.903+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:28:07.904+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:28:07.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:28:07.935+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:28:07.934+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:28:07.937+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:28:07.960+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:28:38.107+0000] {processor.py:153} INFO - Started process (PID=21390) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:28:38.109+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:28:38.110+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:28:38.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:28:38.153+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:28:38.152+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:28:38.154+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:28:38.190+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.086 seconds
[2023-03-23T13:29:08.613+0000] {processor.py:153} INFO - Started process (PID=21463) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:29:08.614+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:29:08.615+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:29:08.615+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:29:08.637+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:29:08.636+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:29:08.638+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:29:08.659+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.049 seconds
[2023-03-23T13:29:39.020+0000] {processor.py:153} INFO - Started process (PID=21552) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:29:39.022+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:29:39.023+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:29:39.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:29:39.056+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:29:39.054+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:29:39.057+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:29:39.082+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T13:30:09.279+0000] {processor.py:153} INFO - Started process (PID=21625) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:30:09.281+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:30:09.283+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:30:09.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:30:09.374+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:30:09.373+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:30:09.376+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:30:09.409+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.136 seconds
[2023-03-23T13:30:39.490+0000] {processor.py:153} INFO - Started process (PID=21698) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:30:39.491+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:30:39.492+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:30:39.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:30:39.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:30:39.514+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:30:39.516+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:30:39.540+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T13:31:09.879+0000] {processor.py:153} INFO - Started process (PID=21787) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:31:09.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:31:09.882+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:31:09.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:31:09.908+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:31:09.907+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:31:09.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:31:09.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.049 seconds
[2023-03-23T13:31:40.128+0000] {processor.py:153} INFO - Started process (PID=21860) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:31:40.129+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:31:40.130+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:31:40.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:31:40.155+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:31:40.154+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:31:40.156+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:31:40.179+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.055 seconds
[2023-03-23T13:32:10.714+0000] {processor.py:153} INFO - Started process (PID=21949) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:32:10.716+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:32:10.717+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:32:10.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:32:10.740+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:32:10.738+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:32:10.740+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:32:10.761+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.050 seconds
[2023-03-23T13:32:40.861+0000] {processor.py:153} INFO - Started process (PID=22022) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:32:40.863+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:32:40.864+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:32:40.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:32:40.906+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:32:40.905+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:32:40.907+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:32:40.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.075 seconds
[2023-03-23T13:33:11.102+0000] {processor.py:153} INFO - Started process (PID=22095) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:33:11.104+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:33:11.105+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:33:11.105+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:33:11.153+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:33:11.152+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:33:11.154+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:33:11.176+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T13:33:41.242+0000] {processor.py:153} INFO - Started process (PID=22184) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:33:41.243+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:33:41.244+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:33:41.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:33:41.282+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:33:41.281+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:33:41.286+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:33:41.309+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T13:34:11.726+0000] {processor.py:153} INFO - Started process (PID=22256) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:34:11.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:34:11.729+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:34:11.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:34:11.758+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:34:11.757+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:34:11.759+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:34:11.784+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:34:42.404+0000] {processor.py:153} INFO - Started process (PID=22332) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:34:42.405+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:34:42.407+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:34:42.406+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:34:42.439+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:34:42.437+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:34:42.440+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:34:42.463+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T13:35:12.551+0000] {processor.py:153} INFO - Started process (PID=22419) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:35:12.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:35:12.553+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:35:12.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:35:12.596+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:35:12.595+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:35:12.597+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:35:12.620+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.073 seconds
[2023-03-23T13:35:42.742+0000] {processor.py:153} INFO - Started process (PID=22492) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:35:42.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:35:42.745+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:35:42.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:35:42.771+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:35:42.769+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:35:42.772+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:35:42.797+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.059 seconds
[2023-03-23T13:36:13.061+0000] {processor.py:153} INFO - Started process (PID=22574) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:36:13.067+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:36:13.071+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:36:13.069+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:36:13.187+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:36:13.185+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:36:13.201+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:36:13.277+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.222 seconds
[2023-03-23T13:36:43.424+0000] {processor.py:153} INFO - Started process (PID=22654) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:36:43.426+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:36:43.427+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:36:43.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:36:43.460+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:36:43.458+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:36:43.462+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:36:43.490+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T13:37:13.724+0000] {processor.py:153} INFO - Started process (PID=22726) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:37:13.726+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:37:13.727+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:37:13.727+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:37:13.755+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:37:13.754+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:37:13.756+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:37:13.784+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T13:37:43.879+0000] {processor.py:153} INFO - Started process (PID=22815) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:37:43.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:37:43.882+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:37:43.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:37:43.905+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:37:43.904+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:37:43.906+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:37:44.085+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.211 seconds
[2023-03-23T13:38:14.212+0000] {processor.py:153} INFO - Started process (PID=22888) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:38:14.213+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:38:14.215+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:38:14.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:38:14.246+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:38:14.245+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:38:14.247+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:38:14.277+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T13:38:45.203+0000] {processor.py:153} INFO - Started process (PID=22961) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:38:45.204+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:38:45.205+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:38:45.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:38:45.233+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:38:45.232+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:38:45.234+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:38:45.369+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.169 seconds
[2023-03-23T13:39:16.077+0000] {processor.py:153} INFO - Started process (PID=23050) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:39:16.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:39:16.080+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:39:16.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:39:16.124+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:39:16.122+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:39:16.125+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:39:16.147+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T13:39:46.281+0000] {processor.py:153} INFO - Started process (PID=23123) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:39:46.282+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:39:46.283+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:39:46.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:39:46.315+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:39:46.314+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:39:46.315+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:39:46.340+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T13:40:16.580+0000] {processor.py:153} INFO - Started process (PID=23192) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:40:16.581+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:40:16.583+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:40:16.583+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:40:16.608+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:40:16.607+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:40:16.608+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:40:16.633+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T13:40:47.631+0000] {processor.py:153} INFO - Started process (PID=23274) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:40:47.632+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:40:47.634+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:40:47.633+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:40:47.663+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:40:47.662+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:40:47.664+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:40:47.691+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T13:41:18.307+0000] {processor.py:153} INFO - Started process (PID=23347) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:41:18.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:41:18.317+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:41:18.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:41:18.389+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:41:18.387+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:41:18.391+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:41:18.446+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.145 seconds
[2023-03-23T13:41:49.275+0000] {processor.py:153} INFO - Started process (PID=23429) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:41:49.276+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:41:49.277+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:41:49.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:41:49.304+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:41:49.303+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:41:49.306+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:41:49.327+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.056 seconds
[2023-03-23T13:42:20.056+0000] {processor.py:153} INFO - Started process (PID=23509) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:42:20.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:42:20.060+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:42:20.060+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:42:20.107+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:42:20.106+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:42:20.109+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:42:20.144+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.095 seconds
[2023-03-23T13:42:50.548+0000] {processor.py:153} INFO - Started process (PID=23582) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:42:50.549+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:42:50.551+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:42:50.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:42:50.578+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:42:50.577+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:42:50.579+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:42:50.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T13:43:20.772+0000] {processor.py:153} INFO - Started process (PID=23671) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:43:20.774+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:43:20.775+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:43:20.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:43:20.803+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:43:20.802+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:43:20.804+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:43:20.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T13:43:51.073+0000] {processor.py:153} INFO - Started process (PID=23744) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:43:51.074+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:43:51.076+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:43:51.076+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:43:51.121+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:43:51.119+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:43:51.122+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:43:51.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.088 seconds
[2023-03-23T13:44:21.245+0000] {processor.py:153} INFO - Started process (PID=23817) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:44:21.246+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:44:21.247+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:44:21.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:44:21.267+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:44:21.266+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:44:21.267+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:44:21.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T13:44:51.926+0000] {processor.py:153} INFO - Started process (PID=23906) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:44:51.928+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:44:51.929+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:44:51.929+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:44:51.951+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:44:51.950+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:44:51.951+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:44:51.971+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.048 seconds
[2023-03-23T13:45:22.060+0000] {processor.py:153} INFO - Started process (PID=23979) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:45:22.061+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:45:22.063+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:45:22.062+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:45:22.100+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:45:22.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:45:22.101+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:45:22.124+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T13:45:53.012+0000] {processor.py:153} INFO - Started process (PID=24052) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:45:53.013+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:45:53.014+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:45:53.014+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:45:53.039+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:45:53.037+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:45:53.040+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:45:53.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.115 seconds
[2023-03-23T13:46:23.243+0000] {processor.py:153} INFO - Started process (PID=24141) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:46:23.245+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:46:23.245+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:46:23.245+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:46:23.275+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:46:23.273+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:46:23.276+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:46:23.299+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T13:46:53.638+0000] {processor.py:153} INFO - Started process (PID=24214) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:46:53.640+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:46:53.642+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:46:53.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:46:53.679+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:46:53.677+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:46:53.680+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:46:53.710+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.079 seconds
[2023-03-23T13:47:24.046+0000] {processor.py:153} INFO - Started process (PID=24303) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:47:24.048+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:47:24.049+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:47:24.049+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:47:24.078+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:47:24.076+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:47:24.079+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:47:24.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T13:47:54.527+0000] {processor.py:153} INFO - Started process (PID=24376) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:47:54.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:47:54.529+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:47:54.529+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:47:54.549+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:47:54.548+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:47:54.549+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:47:54.572+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.051 seconds
[2023-03-23T13:48:25.221+0000] {processor.py:153} INFO - Started process (PID=24449) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:48:25.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:48:25.223+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:48:25.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:48:25.258+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:48:25.257+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:48:25.259+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:48:25.281+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T13:48:55.848+0000] {processor.py:153} INFO - Started process (PID=24538) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:48:55.849+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:48:55.850+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:48:55.850+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:48:55.879+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:48:55.877+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:48:55.881+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:48:55.935+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.090 seconds
[2023-03-23T13:49:26.061+0000] {processor.py:153} INFO - Started process (PID=24611) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:49:26.062+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:49:26.063+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:49:26.063+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:49:26.087+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:49:26.086+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:49:26.088+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:49:26.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.048 seconds
[2023-03-23T13:49:56.168+0000] {processor.py:153} INFO - Started process (PID=24692) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:49:56.169+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:49:56.170+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:49:56.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:49:56.206+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:49:56.204+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:49:56.208+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:49:56.231+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T13:50:27.177+0000] {processor.py:153} INFO - Started process (PID=24773) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:50:27.178+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:50:27.179+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:50:27.179+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:50:27.214+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:50:27.212+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:50:27.214+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:50:27.236+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T13:50:57.531+0000] {processor.py:153} INFO - Started process (PID=24846) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:50:57.532+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:50:57.534+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:50:57.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:50:57.568+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:50:57.567+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:50:57.569+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:50:57.593+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T13:51:28.152+0000] {processor.py:153} INFO - Started process (PID=24936) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:51:28.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:51:28.155+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:51:28.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:51:28.223+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:51:28.214+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:51:28.227+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:51:28.271+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.124 seconds
[2023-03-23T13:51:59.162+0000] {processor.py:153} INFO - Started process (PID=25009) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:51:59.176+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:51:59.189+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:51:59.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:51:59.291+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:51:59.289+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:51:59.293+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:51:59.354+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.199 seconds
[2023-03-23T13:52:30.171+0000] {processor.py:153} INFO - Started process (PID=25082) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:52:30.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:52:30.174+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:52:30.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:52:30.206+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:52:30.204+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:52:30.207+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:52:30.239+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.073 seconds
[2023-03-23T13:53:00.547+0000] {processor.py:153} INFO - Started process (PID=25164) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:53:00.551+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:53:00.553+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:53:00.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:53:00.591+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:53:00.589+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:53:00.593+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:53:00.648+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.107 seconds
[2023-03-23T13:53:31.106+0000] {processor.py:153} INFO - Started process (PID=25244) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:53:31.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:53:31.109+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:53:31.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:53:31.139+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:53:31.138+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:53:31.140+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:53:31.166+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.065 seconds
[2023-03-23T13:54:02.034+0000] {processor.py:153} INFO - Started process (PID=25317) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:54:02.035+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:54:02.036+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:54:02.036+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:54:02.073+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:54:02.072+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:54:02.074+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:54:02.101+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T13:54:32.428+0000] {processor.py:153} INFO - Started process (PID=25399) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:54:32.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:54:32.458+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:54:32.455+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:54:33.376+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:54:33.373+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:54:33.387+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:54:33.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.071 seconds
[2023-03-23T13:55:03.862+0000] {processor.py:153} INFO - Started process (PID=25464) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:55:03.864+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:55:03.866+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:55:03.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:55:03.961+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:55:03.959+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:55:03.962+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:55:03.997+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.141 seconds
[2023-03-23T13:55:34.551+0000] {processor.py:153} INFO - Started process (PID=25545) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:55:34.555+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:55:34.557+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:55:34.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:55:34.605+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:55:34.602+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:55:34.606+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:55:34.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.122 seconds
[2023-03-23T13:56:04.753+0000] {processor.py:153} INFO - Started process (PID=25618) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:56:04.754+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:56:04.756+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:56:04.756+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:56:04.788+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:56:04.786+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:56:04.789+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:56:04.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T13:56:35.126+0000] {processor.py:153} INFO - Started process (PID=25698) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:56:35.128+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:56:35.129+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:56:35.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:56:35.165+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:56:35.163+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:56:35.167+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:56:35.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.080 seconds
[2023-03-23T13:57:05.388+0000] {processor.py:153} INFO - Started process (PID=25771) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:57:05.389+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:57:05.391+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:57:05.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:57:05.417+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:57:05.416+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:57:05.418+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:57:05.447+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T13:57:35.508+0000] {processor.py:153} INFO - Started process (PID=25860) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:57:35.510+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:57:35.511+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:57:35.511+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:57:35.548+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:57:35.547+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:57:35.549+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:57:35.573+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T13:58:06.262+0000] {processor.py:153} INFO - Started process (PID=25933) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:58:06.263+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:58:06.265+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:58:06.264+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:58:06.294+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:58:06.293+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:58:06.296+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:58:06.323+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T13:58:36.525+0000] {processor.py:153} INFO - Started process (PID=26006) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:58:36.526+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:58:36.527+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:58:36.527+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:58:36.555+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:58:36.554+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:58:36.555+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:58:36.578+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T13:59:07.544+0000] {processor.py:153} INFO - Started process (PID=26095) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:59:07.545+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:59:07.546+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:59:07.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:59:07.565+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:59:07.564+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:59:07.565+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:59:07.585+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.045 seconds
[2023-03-23T13:59:37.831+0000] {processor.py:153} INFO - Started process (PID=26168) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:59:37.832+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T13:59:37.833+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:59:37.833+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:59:37.864+0000] {logging_mixin.py:137} INFO - [2023-03-23T13:59:37.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T13:59:37.864+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T13:59:37.887+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T14:00:08.560+0000] {processor.py:153} INFO - Started process (PID=26250) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:00:08.562+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:00:08.564+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:00:08.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:00:08.673+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:00:08.671+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:00:08.688+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:00:08.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.201 seconds
[2023-03-23T14:00:39.429+0000] {processor.py:153} INFO - Started process (PID=26330) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:00:39.430+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:00:39.431+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:00:39.431+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:00:39.474+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:00:39.471+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:00:39.476+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:00:39.504+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T14:01:10.040+0000] {processor.py:153} INFO - Started process (PID=26403) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:01:10.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:01:10.043+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:01:10.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:01:10.077+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:01:10.076+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:01:10.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:01:10.098+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T14:01:40.192+0000] {processor.py:153} INFO - Started process (PID=26476) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:01:40.194+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:01:40.196+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:01:40.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:01:40.229+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:01:40.227+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:01:40.231+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:01:40.256+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.069 seconds
[2023-03-23T14:02:10.370+0000] {processor.py:153} INFO - Started process (PID=26549) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:02:10.371+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:02:10.372+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:02:10.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:02:10.402+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:02:10.401+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:02:10.403+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:02:10.428+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T14:02:40.842+0000] {processor.py:153} INFO - Started process (PID=26638) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:02:40.844+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:02:40.844+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:02:40.844+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:02:40.871+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:02:40.870+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:02:40.872+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:02:40.991+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.153 seconds
[2023-03-23T14:03:11.574+0000] {processor.py:153} INFO - Started process (PID=26710) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:03:11.584+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:03:11.588+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:03:11.586+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:03:11.892+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:03:11.890+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:03:11.897+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:03:11.995+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.438 seconds
[2023-03-23T14:03:42.433+0000] {processor.py:153} INFO - Started process (PID=26782) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:03:42.434+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:03:42.436+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:03:42.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:03:42.469+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:03:42.467+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:03:42.469+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:03:42.499+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T14:04:12.898+0000] {processor.py:153} INFO - Started process (PID=26855) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:04:12.899+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:04:12.900+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:04:12.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:04:12.939+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:04:12.938+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:04:12.940+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:04:12.973+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.079 seconds
[2023-03-23T14:04:43.367+0000] {processor.py:153} INFO - Started process (PID=26928) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:04:43.369+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:04:43.370+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:04:43.370+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:04:43.402+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:04:43.400+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:04:43.402+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:04:43.433+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T14:05:14.117+0000] {processor.py:153} INFO - Started process (PID=27017) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:05:14.119+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:05:14.122+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:05:14.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:05:14.176+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:05:14.174+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:05:14.177+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:05:14.213+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.104 seconds
[2023-03-23T14:05:44.746+0000] {processor.py:153} INFO - Started process (PID=27090) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:05:44.748+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:05:44.749+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:05:44.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:05:44.775+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:05:44.774+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:05:44.776+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:05:44.803+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T14:06:15.294+0000] {processor.py:153} INFO - Started process (PID=27163) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:06:15.295+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:06:15.296+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:06:15.296+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:06:15.315+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:06:15.314+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:06:15.315+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:06:15.337+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.047 seconds
[2023-03-23T14:06:45.739+0000] {processor.py:153} INFO - Started process (PID=27251) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:06:45.740+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:06:45.741+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:06:45.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:06:45.763+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:06:45.762+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:06:45.764+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:06:45.784+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.048 seconds
[2023-03-23T14:07:16.074+0000] {processor.py:153} INFO - Started process (PID=27323) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:07:16.075+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:07:16.076+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:07:16.076+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:07:16.108+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:07:16.107+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:07:16.108+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:07:16.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T14:07:46.313+0000] {processor.py:153} INFO - Started process (PID=27411) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:07:46.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:07:46.316+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:07:46.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:07:46.352+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:07:46.351+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:07:46.353+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:07:46.377+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T14:08:17.328+0000] {processor.py:153} INFO - Started process (PID=27484) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:08:17.329+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:08:17.331+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:08:17.331+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:08:17.363+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:08:17.361+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:08:17.364+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:08:17.396+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T14:08:47.476+0000] {processor.py:153} INFO - Started process (PID=27565) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:08:47.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:08:47.478+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:08:47.478+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:08:47.524+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:08:47.522+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:08:47.524+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:08:47.564+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.092 seconds
[2023-03-23T14:09:18.149+0000] {processor.py:153} INFO - Started process (PID=27645) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:09:18.151+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:09:18.152+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:09:18.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:09:18.179+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:09:18.177+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:09:18.179+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:09:18.205+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T14:09:49.002+0000] {processor.py:153} INFO - Started process (PID=27718) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:09:49.006+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:09:49.009+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:09:49.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:09:49.135+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:09:49.127+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:09:49.139+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:09:49.235+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.242 seconds
[2023-03-23T14:10:19.532+0000] {processor.py:153} INFO - Started process (PID=27790) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:10:19.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:10:19.536+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:10:19.536+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:10:19.580+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:10:19.577+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:10:19.581+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:10:19.614+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.089 seconds
[2023-03-23T14:10:50.876+0000] {processor.py:153} INFO - Started process (PID=27870) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:10:50.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:10:50.896+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:10:50.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:10:51.185+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:10:51.182+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:10:51.186+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:10:51.286+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.429 seconds
[2023-03-23T14:11:22.373+0000] {processor.py:153} INFO - Started process (PID=27935) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:11:22.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:11:22.378+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:11:22.378+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:11:22.425+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:11:22.423+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:11:22.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:11:22.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.147 seconds
[2023-03-23T14:11:52.738+0000] {processor.py:153} INFO - Started process (PID=28008) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:11:52.740+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:11:52.741+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:11:52.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:11:52.768+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:11:52.767+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:11:52.769+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:11:52.795+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T14:12:23.127+0000] {processor.py:153} INFO - Started process (PID=28081) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:12:23.129+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:12:23.130+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:12:23.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:12:23.170+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:12:23.169+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:12:23.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:12:23.203+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.081 seconds
[2023-03-23T14:12:53.889+0000] {processor.py:153} INFO - Started process (PID=28154) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:12:53.891+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:12:53.892+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:12:53.892+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:12:53.922+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:12:53.920+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:12:53.923+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:12:53.950+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T14:13:24.568+0000] {processor.py:153} INFO - Started process (PID=28243) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:13:24.570+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:13:24.571+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:13:24.571+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:13:24.608+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:13:24.606+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:13:24.608+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:13:24.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.069 seconds
[2023-03-23T14:13:55.277+0000] {processor.py:153} INFO - Started process (PID=28316) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:13:55.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:13:55.279+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:13:55.279+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:13:55.308+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:13:55.307+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:13:55.309+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:13:55.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T14:14:25.834+0000] {processor.py:153} INFO - Started process (PID=28405) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:14:25.835+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:14:25.836+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:14:25.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:14:25.865+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:14:25.864+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:14:25.866+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:14:25.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.063 seconds
[2023-03-23T14:14:57.616+0000] {processor.py:153} INFO - Started process (PID=28477) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:14:57.628+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:14:57.635+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:14:57.635+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:14:58.300+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:14:58.297+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:14:58.302+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:14:58.387+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.789 seconds
[2023-03-23T14:15:29.546+0000] {processor.py:153} INFO - Started process (PID=28551) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:15:29.549+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:15:29.555+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:15:29.555+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:15:29.893+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:15:29.891+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:15:29.914+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:15:30.081+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.545 seconds
[2023-03-23T14:16:00.487+0000] {processor.py:153} INFO - Started process (PID=28624) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:16:00.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:16:00.491+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:16:00.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:16:00.525+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:16:00.523+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:16:00.526+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:16:00.556+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.072 seconds
[2023-03-23T14:16:30.917+0000] {processor.py:153} INFO - Started process (PID=28697) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:16:30.918+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:16:30.919+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:16:30.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:16:30.947+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:16:30.946+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:16:30.948+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:16:30.970+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.056 seconds
[2023-03-23T14:17:01.253+0000] {processor.py:153} INFO - Started process (PID=28778) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:17:01.254+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:17:01.255+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:17:01.255+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:17:01.287+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:17:01.285+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:17:01.288+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:17:01.310+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.062 seconds
[2023-03-23T14:17:31.363+0000] {processor.py:153} INFO - Started process (PID=28858) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:17:31.365+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:17:31.366+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:17:31.366+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:17:31.400+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:17:31.399+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:17:31.402+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:17:31.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.078 seconds
[2023-03-23T14:18:01.582+0000] {processor.py:153} INFO - Started process (PID=28930) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:18:01.583+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:18:01.584+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:18:01.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:18:01.607+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:18:01.606+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:18:01.608+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:18:01.627+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.049 seconds
[2023-03-23T14:18:31.793+0000] {processor.py:153} INFO - Started process (PID=29003) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:18:31.794+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:18:31.795+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:18:31.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:18:31.834+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:18:31.833+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:18:31.835+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:18:31.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.078 seconds
[2023-03-23T14:19:02.030+0000] {processor.py:153} INFO - Started process (PID=29076) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:19:02.031+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:19:02.033+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:19:02.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:19:02.078+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:19:02.077+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:19:02.079+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:19:02.102+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.075 seconds
[2023-03-23T14:19:32.578+0000] {processor.py:153} INFO - Started process (PID=29164) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:19:32.579+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:19:32.581+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:19:32.580+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:19:32.616+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:19:32.615+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:19:32.617+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:19:32.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T14:20:03.133+0000] {processor.py:153} INFO - Started process (PID=29237) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:20:03.135+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:20:03.147+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:20:03.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:20:03.318+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:20:03.315+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:20:03.319+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:20:03.387+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.272 seconds
[2023-03-23T14:20:33.500+0000] {processor.py:153} INFO - Started process (PID=29310) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:20:33.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:20:33.503+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:20:33.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:20:33.543+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:20:33.542+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:20:33.544+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:20:33.572+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T14:21:03.900+0000] {processor.py:153} INFO - Started process (PID=29395) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:21:03.901+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:21:03.903+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:21:03.902+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:21:03.926+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:21:03.925+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:21:03.927+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:21:03.945+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.049 seconds
[2023-03-23T14:21:34.272+0000] {processor.py:153} INFO - Started process (PID=29468) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:21:34.274+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:21:34.276+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:21:34.275+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:21:34.312+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:21:34.310+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:21:34.313+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:21:34.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.076 seconds
[2023-03-23T14:22:04.823+0000] {processor.py:153} INFO - Started process (PID=29541) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:22:04.825+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:22:04.826+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:22:04.826+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:22:04.864+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:22:04.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:22:04.865+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:22:04.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.075 seconds
[2023-03-23T14:22:35.787+0000] {processor.py:153} INFO - Started process (PID=29630) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:22:35.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:22:35.790+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:22:35.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:22:35.830+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:22:35.828+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:22:35.831+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:22:35.860+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.078 seconds
[2023-03-23T14:23:06.891+0000] {processor.py:153} INFO - Started process (PID=29703) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:23:06.893+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:23:06.894+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:23:06.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:23:06.930+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:23:06.929+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:23:06.931+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:23:06.955+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T14:23:37.225+0000] {processor.py:153} INFO - Started process (PID=29776) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:23:37.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:23:37.227+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:23:37.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:23:37.244+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:23:37.243+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:23:37.244+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:23:37.265+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.044 seconds
[2023-03-23T14:24:07.350+0000] {processor.py:153} INFO - Started process (PID=29858) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:24:07.351+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:24:07.352+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:24:07.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:24:07.392+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:24:07.390+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:24:07.399+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:24:07.427+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.080 seconds
[2023-03-23T14:24:38.084+0000] {processor.py:153} INFO - Started process (PID=29938) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:24:38.095+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:24:38.097+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:24:38.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:24:38.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:24:38.132+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:24:38.135+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:24:38.168+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.089 seconds
[2023-03-23T14:25:08.425+0000] {processor.py:153} INFO - Started process (PID=30012) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:25:08.426+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:25:08.427+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:25:08.427+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:25:08.450+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:25:08.448+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:25:08.450+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:25:08.474+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.053 seconds
[2023-03-23T14:25:39.001+0000] {processor.py:153} INFO - Started process (PID=30101) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:25:39.004+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:25:39.006+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:25:39.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:25:39.069+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:25:39.067+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:25:39.071+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:25:39.135+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.146 seconds
[2023-03-23T14:26:09.234+0000] {processor.py:153} INFO - Started process (PID=30174) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:26:09.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:26:09.236+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:26:09.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:26:09.264+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:26:09.263+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:26:09.265+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:26:09.287+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T14:26:39.931+0000] {processor.py:153} INFO - Started process (PID=30247) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:26:39.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:26:39.934+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:26:39.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:26:39.977+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:26:39.975+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:26:39.978+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:26:40.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.080 seconds
[2023-03-23T14:27:10.563+0000] {processor.py:153} INFO - Started process (PID=30336) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:27:10.565+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:27:10.567+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:27:10.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:27:10.599+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:27:10.598+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:27:10.600+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:27:10.627+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T14:27:40.768+0000] {processor.py:153} INFO - Started process (PID=30408) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:27:40.782+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:27:40.788+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:27:40.788+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:27:40.842+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:27:40.840+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:27:40.844+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:27:40.903+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.141 seconds
[2023-03-23T14:28:10.954+0000] {processor.py:153} INFO - Started process (PID=30481) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:28:10.956+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:28:10.958+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:28:10.957+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:28:10.993+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:28:10.991+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:28:10.994+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:28:11.018+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.068 seconds
[2023-03-23T14:28:41.607+0000] {processor.py:153} INFO - Started process (PID=30563) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:28:41.608+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:28:41.609+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:28:41.609+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:28:41.638+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:28:41.637+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:28:41.639+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:28:41.663+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.058 seconds
[2023-03-23T14:29:12.192+0000] {processor.py:153} INFO - Started process (PID=30643) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:29:12.194+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:29:12.195+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:29:12.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:29:12.231+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:29:12.228+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:29:12.232+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:29:12.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T14:29:42.879+0000] {processor.py:153} INFO - Started process (PID=30716) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:29:42.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:29:42.882+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:29:42.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:29:42.917+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:29:42.915+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:29:42.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:29:42.946+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T14:30:13.623+0000] {processor.py:153} INFO - Started process (PID=30789) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:30:13.626+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:30:13.627+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:30:13.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:30:13.649+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:30:13.648+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:30:13.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:30:13.666+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.047 seconds
[2023-03-23T14:30:44.237+0000] {processor.py:153} INFO - Started process (PID=30879) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:30:44.238+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:30:44.239+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:30:44.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:30:44.264+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:30:44.262+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:30:44.264+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:30:44.281+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.046 seconds
[2023-03-23T14:31:14.620+0000] {processor.py:153} INFO - Started process (PID=30952) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:31:14.621+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:31:14.622+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:31:14.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:31:14.645+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:31:14.644+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:31:14.645+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:31:14.674+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.058 seconds
[2023-03-23T14:31:44.834+0000] {processor.py:153} INFO - Started process (PID=31032) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:31:44.835+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:31:44.836+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:31:44.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:31:44.856+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:31:44.855+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:31:44.857+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:31:44.876+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.045 seconds
[2023-03-23T14:32:15.001+0000] {processor.py:153} INFO - Started process (PID=31114) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:32:15.002+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:32:15.003+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:32:15.003+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:32:15.023+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:32:15.022+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:32:15.024+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:32:15.041+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.043 seconds
[2023-03-23T14:32:45.864+0000] {processor.py:153} INFO - Started process (PID=31185) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:32:45.865+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:32:45.866+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:32:45.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:32:45.895+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:32:45.894+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:32:45.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:32:45.917+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.057 seconds
[2023-03-23T14:33:16.603+0000] {processor.py:153} INFO - Started process (PID=31274) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:33:16.612+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:33:16.614+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:33:16.614+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:33:16.888+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:33:16.886+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:33:16.890+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:33:16.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.355 seconds
[2023-03-23T14:33:47.661+0000] {processor.py:153} INFO - Started process (PID=31347) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:33:47.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:33:47.664+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:33:47.664+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:33:47.696+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:33:47.695+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:33:47.697+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:33:47.730+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T14:34:18.288+0000] {processor.py:153} INFO - Started process (PID=31420) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:34:18.289+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:34:18.290+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:34:18.290+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:34:18.321+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:34:18.320+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:34:18.322+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:34:18.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.070 seconds
[2023-03-23T14:34:48.533+0000] {processor.py:153} INFO - Started process (PID=31509) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:34:48.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:34:48.535+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:34:48.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:34:48.557+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:34:48.556+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:34:48.558+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:34:48.579+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.049 seconds
[2023-03-23T14:35:19.280+0000] {processor.py:153} INFO - Started process (PID=31582) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:35:19.281+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:35:19.282+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:35:19.282+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:35:19.313+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:35:19.312+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:35:19.314+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:35:19.338+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T14:35:49.495+0000] {processor.py:153} INFO - Started process (PID=31655) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:35:49.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:35:49.497+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:35:49.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:35:49.529+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:35:49.528+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:35:49.529+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:35:49.679+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.186 seconds
[2023-03-23T14:36:19.858+0000] {processor.py:153} INFO - Started process (PID=31744) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:36:19.860+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:36:19.864+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:36:19.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:36:19.962+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:36:19.959+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:36:19.964+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:36:20.035+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.193 seconds
[2023-03-23T14:36:50.576+0000] {processor.py:153} INFO - Started process (PID=31817) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:36:50.578+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:36:50.583+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:36:50.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:36:50.642+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:36:50.640+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:36:50.643+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:36:50.689+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.119 seconds
[2023-03-23T14:37:20.937+0000] {processor.py:153} INFO - Started process (PID=31890) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:37:20.939+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:37:20.941+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:37:20.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:37:20.988+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:37:20.987+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:37:20.990+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:37:21.018+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.090 seconds
[2023-03-23T14:37:51.485+0000] {processor.py:153} INFO - Started process (PID=31963) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:37:51.487+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:37:51.489+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:37:51.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:37:51.547+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:37:51.545+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:37:51.548+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:37:51.589+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.110 seconds
[2023-03-23T14:38:21.876+0000] {processor.py:153} INFO - Started process (PID=32036) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:21.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:38:21.880+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:21.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:21.935+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:21.933+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:38:21.937+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:21.974+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.102 seconds
[2023-03-23T14:38:28.038+0000] {processor.py:153} INFO - Started process (PID=32063) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:28.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:38:28.044+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:28.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:28.099+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:28.096+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:38:28.101+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:28.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.137 seconds
[2023-03-23T14:38:58.524+0000] {processor.py:153} INFO - Started process (PID=32136) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:58.525+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:38:58.527+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:58.527+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:58.576+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:58.573+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:38:58.577+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:58.609+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.092 seconds
[2023-03-23T14:38:59.680+0000] {processor.py:153} INFO - Started process (PID=32140) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:59.682+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T14:38:59.683+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:59.683+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:59.738+0000] {logging_mixin.py:137} INFO - [2023-03-23T14:38:59.736+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 105
    function_code = """
import base64
import json
from google.cloud import storage
from google.cloud import bigquery

def process_message(event, context):
    message = base64.b64decode(event['data']).decode('utf-8')
    data = json.loads(message)
    input_bucket_name = data['input_bucket_name']
    input_object_name = data['input_object_name']
    output_bucket_name = data['output_bucket_name']
    output_object_name = data['output_object_name']
    client = storage.Client()
    input_bucket = client.bucket(input_bucket_name)
    input_blob = input_bucket.blob(input_object_name)
    output_bucket = client.bucket(output_bucket_name)
    output_blob = output_bucket.blob(output_object_name)
    df = pd.read_csv(input_blob.download_as_string())
                       
             
           
                                
                                 

                                    
                                                             
                              
                                                 
                                                 
                                                   
                                                   
                             
                                                   
                                                     
                                                     
                                                        
                                                    ^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-03-23T14:38:59.740+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T14:38:59.786+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.112 seconds
[2023-03-23T16:58:59.822+0000] {processor.py:153} INFO - Started process (PID=3079) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:58:59.856+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T16:58:59.867+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:58:59.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:00.986+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:00.972+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T16:59:00.990+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:01.027+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.209 seconds
[2023-03-23T16:59:28.536+0000] {processor.py:153} INFO - Started process (PID=3150) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:28.538+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T16:59:28.540+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:28.540+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:28.586+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:28.584+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,
                                                            ^
SyntaxError: trailing comma not allowed without surrounding parentheses
[2023-03-23T16:59:28.587+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:28.630+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.099 seconds
[2023-03-23T16:59:29.147+0000] {processor.py:153} INFO - Started process (PID=3153) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:29.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T16:59:29.175+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:29.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:29.757+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:29.745+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T16:59:29.760+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:29.803+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.664 seconds
[2023-03-23T16:59:57.835+0000] {processor.py:153} INFO - Started process (PID=3219) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:57.836+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T16:59:57.837+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:57.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:58.103+0000] {logging_mixin.py:137} INFO - [2023-03-23T16:59:58.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T16:59:58.104+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T16:59:58.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.291 seconds
[2023-03-23T17:00:12.690+0000] {processor.py:153} INFO - Started process (PID=3256) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:00:12.691+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:00:12.692+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:00:12.692+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:00:12.959+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:00:12.953+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:00:12.962+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:00:12.992+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.306 seconds
[2023-03-23T17:00:43.643+0000] {processor.py:153} INFO - Started process (PID=3329) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:00:43.644+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:00:43.645+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:00:43.645+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:00:44.070+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:00:44.057+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:00:44.074+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:00:44.110+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.472 seconds
[2023-03-23T17:01:14.227+0000] {processor.py:153} INFO - Started process (PID=3419) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:14.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:01:14.252+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:01:14.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:14.774+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:01:14.762+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:01:14.776+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:14.811+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.599 seconds
[2023-03-23T17:01:45.462+0000] {processor.py:153} INFO - Started process (PID=3492) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:45.464+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:01:45.465+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:01:45.465+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:45.790+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:01:45.780+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:01:45.793+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:45.840+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.381 seconds
[2023-03-23T17:01:52.771+0000] {processor.py:153} INFO - Started process (PID=3515) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:52.784+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:01:52.791+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:01:52.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:53.180+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:01:53.172+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:01:53.182+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:01:53.203+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.437 seconds
[2023-03-23T17:02:09.739+0000] {processor.py:153} INFO - Started process (PID=3556) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:09.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:09.746+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:09.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:09.838+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:09.837+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 39
    bucket_name+ = 'my-bucket'
                 ^
SyntaxError: invalid syntax
[2023-03-23T17:02:09.840+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:09.897+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.164 seconds
[2023-03-23T17:02:11.738+0000] {processor.py:153} INFO - Started process (PID=3563) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:11.740+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:11.742+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:11.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:12.247+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:12.228+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:12.249+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:12.289+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.555 seconds
[2023-03-23T17:02:13.838+0000] {processor.py:153} INFO - Started process (PID=3566) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:13.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:13.842+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:13.842+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:14.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:14.502+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:14.517+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:14.568+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.735 seconds
[2023-03-23T17:02:18.735+0000] {processor.py:153} INFO - Started process (PID=3576) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:18.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:18.738+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:18.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:19.115+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:19.093+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:19.119+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:19.168+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.437 seconds
[2023-03-23T17:02:21.823+0000] {processor.py:153} INFO - Started process (PID=3593) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:21.826+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:21.828+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:21.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:23.165+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:23.143+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:23.167+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:23.204+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.387 seconds
[2023-03-23T17:02:24.129+0000] {processor.py:153} INFO - Started process (PID=3596) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:24.131+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:24.132+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:24.132+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:25.074+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:25.061+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:25.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:25.139+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.026 seconds
[2023-03-23T17:02:28.591+0000] {processor.py:153} INFO - Started process (PID=3604) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:28.606+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:28.613+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:28.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:30.249+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:30.207+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:30.253+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:30.301+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.717 seconds
[2023-03-23T17:02:38.784+0000] {processor.py:153} INFO - Started process (PID=3625) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:38.785+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:38.787+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:38.786+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:39.895+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:39.873+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:39.985+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:40.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.310 seconds
[2023-03-23T17:02:44.633+0000] {processor.py:153} INFO - Started process (PID=3645) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:44.635+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:44.636+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:44.636+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:45.145+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:45.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:45.148+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:45.191+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.565 seconds
[2023-03-23T17:02:46.311+0000] {processor.py:153} INFO - Started process (PID=3647) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:46.314+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:46.315+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:46.315+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:46.949+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:46.926+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:46.957+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:47.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.703 seconds
[2023-03-23T17:02:52.919+0000] {processor.py:153} INFO - Started process (PID=3673) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:52.920+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:52.922+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:52.921+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:53.645+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:53.606+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:53.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:53.700+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.787 seconds
[2023-03-23T17:02:58.331+0000] {processor.py:153} INFO - Started process (PID=3681) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:58.339+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:02:58.341+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:58.341+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:59.473+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:02:59.459+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:02:59.475+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:02:59.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.199 seconds
[2023-03-23T17:03:17.662+0000] {processor.py:153} INFO - Started process (PID=3723) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:17.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:17.665+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:17.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:18.200+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:18.187+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:18.204+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:18.230+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.574 seconds
[2023-03-23T17:03:22.178+0000] {processor.py:153} INFO - Started process (PID=3752) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:22.180+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:22.183+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:22.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:22.905+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:22.866+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:22.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:22.968+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.797 seconds
[2023-03-23T17:03:32.041+0000] {processor.py:153} INFO - Started process (PID=3764) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:32.042+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:32.044+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:32.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:32.383+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:32.376+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:32.386+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:32.523+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.487 seconds
[2023-03-23T17:03:34.414+0000] {processor.py:153} INFO - Started process (PID=3767) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:34.415+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:34.417+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:34.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:34.826+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:34.815+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:34.828+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:34.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.527 seconds
[2023-03-23T17:03:37.892+0000] {processor.py:153} INFO - Started process (PID=3777) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:37.920+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:37.938+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:37.938+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:39.533+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:39.481+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:39.549+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:39.609+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.725 seconds
[2023-03-23T17:03:47.389+0000] {processor.py:153} INFO - Started process (PID=3800) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:47.390+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:47.391+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:47.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:47.725+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:47.719+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:47.727+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:47.745+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.359 seconds
[2023-03-23T17:03:54.833+0000] {processor.py:153} INFO - Started process (PID=3832) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:54.834+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:03:54.836+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:54.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:55.438+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:03:55.426+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:03:55.440+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:03:55.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.657 seconds
[2023-03-23T17:04:26.250+0000] {processor.py:153} INFO - Started process (PID=3905) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:04:26.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:04:26.253+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:04:26.253+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:04:26.443+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:04:26.433+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:04:26.446+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:04:26.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.223 seconds
[2023-03-23T17:04:57.368+0000] {processor.py:153} INFO - Started process (PID=3977) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:04:57.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:04:57.371+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:04:57.371+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:04:57.568+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:04:57.560+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:04:57.571+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:04:57.596+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.231 seconds
[2023-03-23T17:05:27.785+0000] {processor.py:153} INFO - Started process (PID=4058) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:05:27.786+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:05:27.788+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:05:27.788+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:05:28.054+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:05:28.048+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:05:28.056+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:05:28.080+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.299 seconds
[2023-03-23T17:05:58.219+0000] {processor.py:153} INFO - Started process (PID=4138) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:05:58.221+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:05:58.223+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:05:58.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:05:58.596+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:05:58.586+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:05:58.598+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:05:58.643+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.438 seconds
[2023-03-23T17:06:28.857+0000] {processor.py:153} INFO - Started process (PID=4212) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:06:28.859+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:06:28.860+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:06:28.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:06:29.058+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:06:29.049+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:06:29.060+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:06:29.080+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.226 seconds
[2023-03-23T17:06:59.479+0000] {processor.py:153} INFO - Started process (PID=4284) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:06:59.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:06:59.481+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:06:59.481+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:06:59.684+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:06:59.675+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:06:59.687+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:06:59.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.233 seconds
[2023-03-23T17:07:30.761+0000] {processor.py:153} INFO - Started process (PID=4357) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:07:30.762+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:07:30.762+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:07:30.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:07:30.944+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:07:30.933+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:07:30.947+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:07:30.966+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.208 seconds
[2023-03-23T17:08:01.132+0000] {processor.py:153} INFO - Started process (PID=4447) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:08:01.134+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:08:01.135+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:08:01.135+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:08:01.438+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:08:01.429+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:08:01.440+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:08:01.473+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.346 seconds
[2023-03-23T17:08:31.691+0000] {processor.py:153} INFO - Started process (PID=4520) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:08:31.693+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:08:31.696+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:08:31.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:08:32.093+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:08:32.081+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:08:32.097+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:08:32.123+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.436 seconds
[2023-03-23T17:09:03.165+0000] {processor.py:153} INFO - Started process (PID=4593) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:03.166+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:09:03.167+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:03.167+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:03.362+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:03.347+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:09:03.364+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:03.545+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.382 seconds
[2023-03-23T17:09:29.853+0000] {processor.py:153} INFO - Started process (PID=4664) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:29.860+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:09:29.862+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:29.862+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:30.889+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:30.638+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:09:30.892+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:30.930+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.082 seconds
[2023-03-23T17:09:34.004+0000] {processor.py:153} INFO - Started process (PID=4667) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:34.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:09:34.009+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:34.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:34.185+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:34.183+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:09:34.187+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:34.310+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.315 seconds
[2023-03-23T17:09:35.245+0000] {processor.py:153} INFO - Started process (PID=4668) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:35.249+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:09:35.251+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:35.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:35.526+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:35.524+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:09:35.528+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:35.588+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.349 seconds
[2023-03-23T17:09:36.660+0000] {processor.py:153} INFO - Started process (PID=4670) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:36.662+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:09:36.663+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:36.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:36.792+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:09:36.790+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:09:36.794+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:09:36.860+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.206 seconds
[2023-03-23T17:10:06.909+0000] {processor.py:153} INFO - Started process (PID=4753) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:06.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:06.912+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:06.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:06.940+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:06.938+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:06.940+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:06.976+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.071 seconds
[2023-03-23T17:10:10.606+0000] {processor.py:153} INFO - Started process (PID=4769) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:10.617+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:10.619+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:10.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:10.914+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:10.912+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:10.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:11.057+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.469 seconds
[2023-03-23T17:10:12.357+0000] {processor.py:153} INFO - Started process (PID=4771) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:12.367+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:12.370+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:12.370+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:12.543+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:12.541+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:12.545+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:12.606+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.255 seconds
[2023-03-23T17:10:13.348+0000] {processor.py:153} INFO - Started process (PID=4772) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:13.349+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:13.351+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:13.351+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:13.553+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:13.552+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
       ^
SyntaxError: invalid syntax
[2023-03-23T17:10:13.554+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:13.586+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.245 seconds
[2023-03-23T17:10:15.412+0000] {processor.py:153} INFO - Started process (PID=4773) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:15.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:15.419+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:15.417+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:15.451+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:15.450+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
       ^
SyntaxError: invalid syntax
[2023-03-23T17:10:15.452+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:15.484+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.078 seconds
[2023-03-23T17:10:16.430+0000] {processor.py:153} INFO - Started process (PID=4774) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:16.435+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:16.436+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:16.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:16.529+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:16.527+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
       ^
SyntaxError: invalid syntax
[2023-03-23T17:10:16.531+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:16.560+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.135 seconds
[2023-03-23T17:10:19.655+0000] {processor.py:153} INFO - Started process (PID=4775) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:19.656+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:19.657+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:19.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:19.682+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:19.681+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:19.683+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:19.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.056 seconds
[2023-03-23T17:10:21.411+0000] {processor.py:153} INFO - Started process (PID=4783) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:21.412+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:21.421+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:21.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:21.451+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:21.449+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:21.452+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:21.583+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.177 seconds
[2023-03-23T17:10:31.845+0000] {processor.py:153} INFO - Started process (PID=4822) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:31.846+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:31.848+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:31.848+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:31.883+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:31.881+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:31.884+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:31.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T17:10:41.235+0000] {processor.py:153} INFO - Started process (PID=4848) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:41.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:10:41.245+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:41.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:41.277+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:10:41.275+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:10:41.278+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:10:41.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.096 seconds
[2023-03-23T17:11:11.427+0000] {processor.py:153} INFO - Started process (PID=4921) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:11.428+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:11:11.429+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:11.429+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:11.474+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:11.474+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:11:11.475+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:11.501+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.077 seconds
[2023-03-23T17:11:26.739+0000] {processor.py:153} INFO - Started process (PID=4953) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:26.740+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:11:26.741+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:26.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:26.798+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:26.796+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:11:26.800+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:26.856+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.122 seconds
[2023-03-23T17:11:29.602+0000] {processor.py:153} INFO - Started process (PID=4956) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:29.604+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:11:29.607+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:29.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:29.674+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:29.673+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:11:29.676+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:29.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.110 seconds
[2023-03-23T17:11:38.381+0000] {processor.py:153} INFO - Started process (PID=4988) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:38.382+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:11:38.384+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:38.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:38.417+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:38.416+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:11:38.418+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:38.444+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.069 seconds
[2023-03-23T17:11:40.823+0000] {processor.py:153} INFO - Started process (PID=4993) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:40.826+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:11:40.827+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:40.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:40.873+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:11:40.871+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:11:40.874+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:11:40.909+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.091 seconds
[2023-03-23T17:12:11.189+0000] {processor.py:153} INFO - Started process (PID=5082) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:11.192+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:12:11.198+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:11.198+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:11.267+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:11.264+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:12:11.268+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:11.337+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.154 seconds
[2023-03-23T17:12:13.199+0000] {processor.py:153} INFO - Started process (PID=5087) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:13.200+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:12:13.201+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:13.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:13.234+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:13.232+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:12:13.234+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:13.259+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T17:12:16.564+0000] {processor.py:153} INFO - Started process (PID=5090) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:16.565+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:12:16.566+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:16.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:16.676+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:16.674+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:12:16.676+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:16.699+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.139 seconds
[2023-03-23T17:12:36.875+0000] {processor.py:153} INFO - Started process (PID=5137) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:36.876+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:12:36.877+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:36.877+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:36.955+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:36.954+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 52
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:12:36.955+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:36.976+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.107 seconds
[2023-03-23T17:12:56.228+0000] {processor.py:153} INFO - Started process (PID=5189) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:56.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:12:56.231+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:56.230+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:56.275+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:12:56.274+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 61
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:12:56.276+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:12:56.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.114 seconds
[2023-03-23T17:13:00.015+0000] {processor.py:153} INFO - Started process (PID=5196) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:00.023+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:13:00.028+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:13:00.027+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:00.088+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:13:00.086+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 70
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-03-23T17:13:00.089+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:00.128+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.118 seconds
[2023-03-23T17:13:01.212+0000] {processor.py:153} INFO - Started process (PID=5197) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:01.213+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:13:01.214+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:13:01.214+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:01.599+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:13:01.592+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:13:01.600+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:01.623+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.415 seconds
[2023-03-23T17:13:31.680+0000] {processor.py:153} INFO - Started process (PID=5270) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:31.682+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:13:31.683+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:13:31.683+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:31.895+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:13:31.886+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:13:31.897+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:13:31.918+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.243 seconds
[2023-03-23T17:14:02.032+0000] {processor.py:153} INFO - Started process (PID=5359) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:14:02.034+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:14:02.036+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:14:02.035+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:14:02.396+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:14:02.386+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:14:02.399+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:14:02.435+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.409 seconds
[2023-03-23T17:14:32.517+0000] {processor.py:153} INFO - Started process (PID=5433) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:14:32.518+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:14:32.519+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:14:32.519+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:14:32.716+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:14:32.704+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:14:32.719+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:14:32.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.228 seconds
[2023-03-23T17:15:03.172+0000] {processor.py:153} INFO - Started process (PID=5505) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:15:03.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:15:03.174+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:15:03.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:15:03.492+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:15:03.473+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:15:03.495+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:15:03.530+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.363 seconds
[2023-03-23T17:15:34.534+0000] {processor.py:153} INFO - Started process (PID=5581) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:15:34.536+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:15:34.537+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:15:34.537+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:15:34.835+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:15:34.829+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:15:34.837+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:15:34.857+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.327 seconds
[2023-03-23T17:16:04.957+0000] {processor.py:153} INFO - Started process (PID=5670) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:04.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:04.962+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:04.962+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:05.400+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:05.390+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:16:05.402+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:05.439+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.489 seconds
[2023-03-23T17:16:30.241+0000] {processor.py:153} INFO - Started process (PID=5728) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:30.243+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:30.244+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:30.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:31.184+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:31.137+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:16:31.191+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:31.257+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.022 seconds
[2023-03-23T17:16:33.115+0000] {processor.py:153} INFO - Started process (PID=5744) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:33.118+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:33.120+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:33.120+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:33.191+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:33.190+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 30
    with
        ^
SyntaxError: invalid syntax
[2023-03-23T17:16:33.192+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:33.222+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.114 seconds
[2023-03-23T17:16:35.525+0000] {processor.py:153} INFO - Started process (PID=5746) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:35.527+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:35.538+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:35.537+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:35.862+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:35.860+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 30
    with DAG
           ^
SyntaxError: invalid syntax
[2023-03-23T17:16:35.863+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:36.023+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.506 seconds
[2023-03-23T17:16:37.602+0000] {processor.py:153} INFO - Started process (PID=5752) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:37.603+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:37.605+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:37.605+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:37.771+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:37.770+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:16:37.772+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:37.805+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.208 seconds
[2023-03-23T17:16:45.381+0000] {processor.py:153} INFO - Started process (PID=5762) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:45.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:45.384+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:45.384+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:45.526+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:45.525+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:16:45.527+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:45.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.178 seconds
[2023-03-23T17:16:49.801+0000] {processor.py:153} INFO - Started process (PID=5788) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:49.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:49.804+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:49.804+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:49.847+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:49.845+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:16:49.849+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:49.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.100 seconds
[2023-03-23T17:16:52.018+0000] {processor.py:153} INFO - Started process (PID=5790) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:52.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:52.021+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:52.021+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:52.063+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:52.061+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:16:52.063+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:52.096+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.082 seconds
[2023-03-23T17:16:55.119+0000] {processor.py:153} INFO - Started process (PID=5791) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:55.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:55.121+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:55.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:55.163+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:55.162+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:16:55.170+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:55.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.102 seconds
[2023-03-23T17:16:57.363+0000] {processor.py:153} INFO - Started process (PID=5792) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:57.364+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:16:57.365+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:57.365+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:57.401+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:16:57.400+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:16:57.403+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:16:57.462+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.106 seconds
[2023-03-23T17:17:01.928+0000] {processor.py:153} INFO - Started process (PID=5802) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:01.944+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:01.948+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:01.947+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:02.028+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:02.025+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:02.029+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:02.079+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.165 seconds
[2023-03-23T17:17:04.784+0000] {processor.py:153} INFO - Started process (PID=5825) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:04.786+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:04.787+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:04.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:04.844+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:04.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:04.845+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:04.901+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.123 seconds
[2023-03-23T17:17:10.523+0000] {processor.py:153} INFO - Started process (PID=5835) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:10.524+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:10.525+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:10.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:10.568+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:10.566+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:10.569+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:10.607+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.092 seconds
[2023-03-23T17:17:14.427+0000] {processor.py:153} INFO - Started process (PID=5842) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:14.434+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:14.440+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:14.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:14.633+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:14.631+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:14.637+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:14.672+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.252 seconds
[2023-03-23T17:17:15.797+0000] {processor.py:153} INFO - Started process (PID=5843) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:15.798+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:15.799+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:15.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:15.972+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:15.970+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:15.973+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:16.015+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.222 seconds
[2023-03-23T17:17:18.063+0000] {processor.py:153} INFO - Started process (PID=5861) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:18.065+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:18.068+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:18.068+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:18.190+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:18.187+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:18.191+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:18.231+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.172 seconds
[2023-03-23T17:17:20.449+0000] {processor.py:153} INFO - Started process (PID=5870) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:20.465+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:20.476+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:20.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:20.533+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:20.531+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:20.534+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:20.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.178 seconds
[2023-03-23T17:17:22.780+0000] {processor.py:153} INFO - Started process (PID=5872) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:22.782+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:22.785+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:22.784+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:22.844+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:22.843+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:22.846+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:22.894+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.120 seconds
[2023-03-23T17:17:25.883+0000] {processor.py:153} INFO - Started process (PID=5873) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:25.889+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:25.893+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:25.893+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:25.939+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:25.937+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:25.941+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:25.992+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.115 seconds
[2023-03-23T17:17:27.281+0000] {processor.py:153} INFO - Started process (PID=5874) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:27.289+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:27.291+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:27.291+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:27.406+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:27.404+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:27.408+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:27.486+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.213 seconds
[2023-03-23T17:17:30.638+0000] {processor.py:153} INFO - Started process (PID=5882) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:30.640+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:30.640+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:30.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:30.694+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:30.692+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:30.695+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:30.722+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.087 seconds
[2023-03-23T17:17:35.586+0000] {processor.py:153} INFO - Started process (PID=5906) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:35.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:35.590+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:35.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:35.630+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:35.629+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:35.632+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:35.696+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.116 seconds
[2023-03-23T17:17:37.092+0000] {processor.py:153} INFO - Started process (PID=5909) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:37.094+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:37.095+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:37.095+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:37.139+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:37.138+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:37.140+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:37.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.106 seconds
[2023-03-23T17:17:39.393+0000] {processor.py:153} INFO - Started process (PID=5915) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:39.412+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:39.415+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:39.415+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:39.473+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:39.471+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 32
    tags=['cloud storage,]
                         ^
SyntaxError: EOL while scanning string literal
[2023-03-23T17:17:39.475+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:39.579+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.192 seconds
[2023-03-23T17:17:43.005+0000] {processor.py:153} INFO - Started process (PID=5925) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:43.006+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:43.008+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:43.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:43.035+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:43.034+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:43.036+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:43.066+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T17:17:47.632+0000] {processor.py:153} INFO - Started process (PID=5929) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:47.633+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:47.634+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:47.634+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:47.672+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:47.670+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:47.673+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:47.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.093 seconds
[2023-03-23T17:17:49.663+0000] {processor.py:153} INFO - Started process (PID=5944) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:49.665+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:49.667+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:49.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:49.720+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:49.716+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:49.722+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:49.809+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.154 seconds
[2023-03-23T17:17:52.050+0000] {processor.py:153} INFO - Started process (PID=5953) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:52.051+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:52.053+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:52.053+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:52.111+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:52.109+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:52.112+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:52.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.140 seconds
[2023-03-23T17:17:52.771+0000] {processor.py:153} INFO - Started process (PID=5955) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:52.778+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:52.787+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:52.786+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:52.939+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:52.938+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:52.941+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:53.003+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.238 seconds
[2023-03-23T17:17:54.841+0000] {processor.py:153} INFO - Started process (PID=5956) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:54.850+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:54.851+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:54.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:54.895+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:54.893+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:54.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:54.951+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.117 seconds
[2023-03-23T17:17:56.899+0000] {processor.py:153} INFO - Started process (PID=5957) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:56.900+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:17:56.901+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:56.901+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:56.936+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:17:56.935+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:17:56.937+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:17:56.960+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.067 seconds
[2023-03-23T17:18:04.089+0000] {processor.py:153} INFO - Started process (PID=5967) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:04.090+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:04.090+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:04.090+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:04.131+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:04.129+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 33
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:04.132+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:04.169+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.084 seconds
[2023-03-23T17:18:07.390+0000] {processor.py:153} INFO - Started process (PID=5991) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:07.392+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:07.412+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:07.412+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:07.548+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:07.546+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:07.549+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:07.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.227 seconds
[2023-03-23T17:18:12.809+0000] {processor.py:153} INFO - Started process (PID=6006) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:12.814+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:12.815+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:12.815+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:12.856+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:12.855+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:12.857+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:12.931+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.128 seconds
[2023-03-23T17:18:17.097+0000] {processor.py:153} INFO - Started process (PID=6007) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:17.098+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:17.100+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:17.100+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:17.152+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:17.148+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:17.160+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:17.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.115 seconds
[2023-03-23T17:18:19.968+0000] {processor.py:153} INFO - Started process (PID=6016) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:19.970+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:19.971+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:19.971+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:20.025+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:20.024+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:20.027+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:20.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.093 seconds
[2023-03-23T17:18:22.759+0000] {processor.py:153} INFO - Started process (PID=6027) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:22.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:22.763+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:22.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:22.843+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:22.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:22.844+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:22.905+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.155 seconds
[2023-03-23T17:18:27.768+0000] {processor.py:153} INFO - Started process (PID=6036) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:27.771+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:27.773+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:27.772+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:27.811+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:27.810+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:27.815+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:27.870+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.108 seconds
[2023-03-23T17:18:28.834+0000] {processor.py:153} INFO - Started process (PID=6037) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:28.835+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:28.837+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:28.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:28.905+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:28.903+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:28.906+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:28.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.112 seconds
[2023-03-23T17:18:45.879+0000] {processor.py:153} INFO - Started process (PID=6084) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:45.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:45.881+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:45.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:45.907+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:45.906+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:45.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:45.931+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.055 seconds
[2023-03-23T17:18:47.995+0000] {processor.py:153} INFO - Started process (PID=6085) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:47.996+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:47.997+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:47.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:48.027+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:48.026+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:48.028+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:48.057+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T17:18:51.920+0000] {processor.py:153} INFO - Started process (PID=6111) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:51.922+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:51.924+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:51.923+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:52.076+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:52.074+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:52.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:52.146+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.233 seconds
[2023-03-23T17:18:55.390+0000] {processor.py:153} INFO - Started process (PID=6113) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:55.391+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:55.393+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:55.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:55.423+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:55.422+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:55.424+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:55.452+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.066 seconds
[2023-03-23T17:18:57.625+0000] {processor.py:153} INFO - Started process (PID=6114) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:57.627+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:57.629+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:57.628+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:57.706+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:57.705+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:57.708+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:57.753+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.137 seconds
[2023-03-23T17:18:58.661+0000] {processor.py:153} INFO - Started process (PID=6115) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:58.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:18:58.664+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:58.664+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:58.710+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:18:58.709+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:18:58.711+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:18:58.743+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.088 seconds
[2023-03-23T17:19:02.465+0000] {processor.py:153} INFO - Started process (PID=6123) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:02.466+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:02.467+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:02.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:02.496+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:02.494+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:02.498+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:02.524+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T17:19:03.755+0000] {processor.py:153} INFO - Started process (PID=6126) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:03.769+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:03.773+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:03.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:03.866+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:03.864+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    start_date=datetime(year=)
                             ^
SyntaxError: invalid syntax
[2023-03-23T17:19:03.868+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:03.914+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.165 seconds
[2023-03-23T17:19:06.376+0000] {processor.py:153} INFO - Started process (PID=6138) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:06.390+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:06.392+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:06.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:06.456+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:06.454+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:06.458+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:06.547+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.181 seconds
[2023-03-23T17:19:08.771+0000] {processor.py:153} INFO - Started process (PID=6142) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:08.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:08.774+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:08.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:09.105+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:09.103+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:09.107+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:09.163+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.401 seconds
[2023-03-23T17:19:10.218+0000] {processor.py:153} INFO - Started process (PID=6153) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:10.224+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:10.225+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:10.225+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:10.504+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:10.503+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    start_date=datetime(year=2023, month=)
                                         ^
SyntaxError: invalid syntax
[2023-03-23T17:19:10.506+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:10.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.418 seconds
[2023-03-23T17:19:11.871+0000] {processor.py:153} INFO - Started process (PID=6158) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:11.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:11.925+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:11.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:12.090+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:12.089+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:12.092+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:12.176+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.313 seconds
[2023-03-23T17:19:13.494+0000] {processor.py:153} INFO - Started process (PID=6162) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:13.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:13.518+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:13.517+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:13.774+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:13.772+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:13.777+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:13.862+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.374 seconds
[2023-03-23T17:19:14.927+0000] {processor.py:153} INFO - Started process (PID=6169) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:14.934+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:14.940+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:14.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:14.998+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:14.996+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:14.999+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:15.055+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.138 seconds
[2023-03-23T17:19:16.058+0000] {processor.py:153} INFO - Started process (PID=6170) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:16.060+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:16.064+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:16.064+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:16.114+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:16.112+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    start_date=datetime(year=2023, month=3,day=)
                                               ^
SyntaxError: invalid syntax
[2023-03-23T17:19:16.115+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:16.146+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.095 seconds
[2023-03-23T17:19:18.640+0000] {processor.py:153} INFO - Started process (PID=6172) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:18.642+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:18.643+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:18.643+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:18.683+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:18.681+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:18.684+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:18.726+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.094 seconds
[2023-03-23T17:19:21.209+0000] {processor.py:153} INFO - Started process (PID=6177) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:21.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:21.212+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:21.211+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:21.250+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:21.247+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 37
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:21.250+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:21.421+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.216 seconds
[2023-03-23T17:19:28.069+0000] {processor.py:153} INFO - Started process (PID=6199) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:28.071+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:28.072+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:28.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:28.117+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:28.114+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 37
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:28.119+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:28.164+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.102 seconds
[2023-03-23T17:19:32.204+0000] {processor.py:153} INFO - Started process (PID=6207) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:32.206+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:32.207+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:32.207+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:32.363+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:32.362+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 37
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:32.364+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:32.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.193 seconds
[2023-03-23T17:19:34.524+0000] {processor.py:153} INFO - Started process (PID=6210) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:34.525+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:34.526+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:34.526+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:34.557+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:34.555+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 37
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:34.557+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:34.584+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.064 seconds
[2023-03-23T17:19:36.772+0000] {processor.py:153} INFO - Started process (PID=6213) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:36.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:36.774+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:36.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:36.926+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:36.924+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    schedule_interval=@
                      ^
SyntaxError: invalid syntax
[2023-03-23T17:19:36.927+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:36.991+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.223 seconds
[2023-03-23T17:19:40.755+0000] {processor.py:153} INFO - Started process (PID=6228) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:40.758+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:40.759+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:40.759+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:40.812+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:40.811+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 36
    '@
     ^
SyntaxError: EOL while scanning string literal
[2023-03-23T17:19:40.830+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:41.116+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.369 seconds
[2023-03-23T17:19:42.121+0000] {processor.py:153} INFO - Started process (PID=6239) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:42.126+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:42.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:42.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:42.276+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:42.274+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    schedule_interval=@
                      ^
SyntaxError: invalid syntax
[2023-03-23T17:19:42.277+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:42.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.222 seconds
[2023-03-23T17:19:43.560+0000] {processor.py:153} INFO - Started process (PID=6242) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:43.562+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:43.564+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:43.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:43.601+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:43.599+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    schedule_interval='@
                       ^
SyntaxError: EOL while scanning string literal
[2023-03-23T17:19:43.602+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:43.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.094 seconds
[2023-03-23T17:19:47.230+0000] {processor.py:153} INFO - Started process (PID=6252) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:47.231+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:47.232+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:47.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:47.259+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:47.257+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    schedule_interval='@dauly
                            ^
SyntaxError: EOL while scanning string literal
[2023-03-23T17:19:47.259+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:47.288+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.060 seconds
[2023-03-23T17:19:49.342+0000] {processor.py:153} INFO - Started process (PID=6253) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:49.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:49.344+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:49.344+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:49.372+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:49.371+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    schedule_interval='@da
                         ^
SyntaxError: EOL while scanning string literal
[2023-03-23T17:19:49.373+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:49.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.054 seconds
[2023-03-23T17:19:51.211+0000] {processor.py:153} INFO - Started process (PID=6259) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:51.217+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:51.222+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:51.221+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:51.329+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:51.327+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 35
    schedule_interval='@daily
                            ^
SyntaxError: EOL while scanning string literal
[2023-03-23T17:19:51.330+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:51.366+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.160 seconds
[2023-03-23T17:19:53.170+0000] {processor.py:153} INFO - Started process (PID=6263) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:53.171+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:19:53.173+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:53.172+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:53.247+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:19:53.246+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 37
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:19:53.249+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:19:53.307+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.143 seconds
[2023-03-23T17:20:03.521+0000] {processor.py:153} INFO - Started process (PID=6289) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:03.523+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:03.524+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:03.524+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:03.600+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:03.599+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:20:03.603+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:03.651+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.136 seconds
[2023-03-23T17:20:08.206+0000] {processor.py:153} INFO - Started process (PID=6303) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:08.207+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:08.208+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:08.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:08.342+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:08.340+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:20:08.343+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:08.374+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.172 seconds
[2023-03-23T17:20:11.431+0000] {processor.py:153} INFO - Started process (PID=6316) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:11.463+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:11.478+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:11.478+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:11.577+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:11.575+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:20:11.585+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:11.641+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.224 seconds
[2023-03-23T17:20:13.913+0000] {processor.py:153} INFO - Started process (PID=6322) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:13.915+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:13.916+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:13.916+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:13.944+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:13.942+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:20:13.945+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:13.971+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T17:20:17.932+0000] {processor.py:153} INFO - Started process (PID=6332) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:17.986+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:18.021+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:18.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:18.232+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:18.230+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 37
    as
     ^
SyntaxError: invalid syntax
[2023-03-23T17:20:18.237+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:18.278+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.352 seconds
[2023-03-23T17:20:19.135+0000] {processor.py:153} INFO - Started process (PID=6333) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:19.140+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:19.142+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:19.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:19.181+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:19.179+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    )
    ^
SyntaxError: invalid syntax
[2023-03-23T17:20:19.182+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:19.224+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.094 seconds
[2023-03-23T17:20:21.588+0000] {processor.py:153} INFO - Started process (PID=6337) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:21.589+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:21.590+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:21.590+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:21.645+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:21.643+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    ) as
        ^
SyntaxError: invalid syntax
[2023-03-23T17:20:21.645+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:21.671+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.089 seconds
[2023-03-23T17:20:25.779+0000] {processor.py:153} INFO - Started process (PID=6360) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:25.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:25.783+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:25.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:25.814+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:25.812+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 34
    start_date=datetime(year=2023, month=3,day=23),
             ^
SyntaxError: invalid syntax
[2023-03-23T17:20:25.815+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:25.853+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.080 seconds
[2023-03-23T17:20:27.993+0000] {processor.py:153} INFO - Started process (PID=6362) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:28.002+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:28.006+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:28.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:28.061+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:28.060+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    ) as ga
          ^
SyntaxError: invalid syntax
[2023-03-23T17:20:28.062+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:28.088+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.103 seconds
[2023-03-23T17:20:32.266+0000] {processor.py:153} INFO - Started process (PID=6363) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:32.268+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:32.270+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:32.270+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:32.313+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:32.311+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    ) as dag
           ^
SyntaxError: invalid syntax
[2023-03-23T17:20:32.314+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:32.361+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.100 seconds
[2023-03-23T17:20:36.379+0000] {processor.py:153} INFO - Started process (PID=6373) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:36.380+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:36.382+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:36.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:36.415+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:36.413+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 41
    project_id = 'my-project-id'
             ^
SyntaxError: invalid syntax
[2023-03-23T17:20:36.416+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:36.460+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.085 seconds
[2023-03-23T17:20:41.189+0000] {processor.py:153} INFO - Started process (PID=6397) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:41.191+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:41.192+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:41.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:41.349+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:41.348+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 38
    ) as dag
           ^
SyntaxError: invalid syntax
[2023-03-23T17:20:41.351+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:41.620+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.438 seconds
[2023-03-23T17:20:42.591+0000] {processor.py:153} INFO - Started process (PID=6400) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:42.593+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:20:42.595+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:42.594+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:42.670+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:20:42.669+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 41
    project_id = 'my-project-id'
             ^
IndentationError: expected an indented block
[2023-03-23T17:20:42.672+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:20:42.738+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.151 seconds
[2023-03-23T17:21:12.920+0000] {processor.py:153} INFO - Started process (PID=6474) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:12.922+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:21:12.923+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:21:12.923+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:12.954+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:21:12.953+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 41
    project_id = 'my-project-id'
             ^
IndentationError: expected an indented block
[2023-03-23T17:21:12.954+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:12.977+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.061 seconds
[2023-03-23T17:21:32.705+0000] {processor.py:153} INFO - Started process (PID=6520) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:32.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:21:32.716+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:21:32.716+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:32.747+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:21:32.745+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 40
    project_id = 'my-project-id'
             ^
IndentationError: expected an indented block
[2023-03-23T17:21:32.747+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:32.855+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.154 seconds
[2023-03-23T17:21:51.898+0000] {processor.py:153} INFO - Started process (PID=6576) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:51.899+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:21:51.900+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:21:51.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:51.930+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:21:51.928+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 40
    project_id = 'my-project-id'
             ^
IndentationError: expected an indented block
[2023-03-23T17:21:51.931+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:21:51.998+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.106 seconds
[2023-03-23T17:22:22.640+0000] {processor.py:153} INFO - Started process (PID=6649) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:22.641+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:22:22.643+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:22:22.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:22.672+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:22:22.671+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 40
    project_id = 'my-project-id'
             ^
IndentationError: expected an indented block
[2023-03-23T17:22:22.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:22.711+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.075 seconds
[2023-03-23T17:22:53.101+0000] {processor.py:153} INFO - Started process (PID=6721) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:53.104+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:22:53.105+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:22:53.105+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:53.140+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:22:53.139+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 40
    project_id = 'my-project-id'
             ^
IndentationError: expected an indented block
[2023-03-23T17:22:53.141+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:53.170+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.074 seconds
[2023-03-23T17:22:55.854+0000] {processor.py:153} INFO - Started process (PID=6727) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:55.856+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:22:55.859+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:22:55.858+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:55.892+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:22:55.890+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 41
    create_bucket = GoogleCloudStorageCreateBucketOperator(
                ^
IndentationError: expected an indented block
[2023-03-23T17:22:55.892+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:22:55.918+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.069 seconds
[2023-03-23T17:23:00.464+0000] {processor.py:153} INFO - Started process (PID=6748) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:00.483+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:00.504+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:00.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:01.628+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:01.598+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:23:01.632+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:01.709+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.282 seconds
[2023-03-23T17:23:02.623+0000] {processor.py:153} INFO - Started process (PID=6750) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:02.625+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:02.626+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:02.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:03.050+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:03.040+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:23:03.054+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:03.093+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.475 seconds
[2023-03-23T17:23:05.249+0000] {processor.py:153} INFO - Started process (PID=6751) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:05.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:05.253+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:05.253+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:05.719+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:05.709+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:23:05.722+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:05.766+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.522 seconds
[2023-03-23T17:23:13.250+0000] {processor.py:153} INFO - Started process (PID=6779) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:13.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:13.254+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:13.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:13.401+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:13.400+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 46
    create_bucket = GoogleCloudStorageCreateBucketOperator(
    ^
IndentationError: unexpected indent
[2023-03-23T17:23:13.403+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:13.454+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.209 seconds
[2023-03-23T17:23:21.234+0000] {processor.py:153} INFO - Started process (PID=6799) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:21.236+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:21.238+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:21.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:21.286+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:21.284+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 46
    create_bucket = GoogleCloudStorageCreateBucketOperator(
    ^
IndentationError: unexpected indent
[2023-03-23T17:23:21.288+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:21.338+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.109 seconds
[2023-03-23T17:23:24.985+0000] {processor.py:153} INFO - Started process (PID=6803) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:24.986+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:24.988+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:24.988+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:25.019+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:25.017+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 46
    create_bucket = GoogleCloudStorageCreateBucketOperator(
    ^
IndentationError: unexpected indent
[2023-03-23T17:23:25.020+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:25.054+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.075 seconds
[2023-03-23T17:23:27.490+0000] {processor.py:153} INFO - Started process (PID=6808) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:27.492+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:27.495+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:27.495+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:27.531+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:27.529+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 46
    create_bucket = GoogleCloudStorageCreateBucketOperator(
    ^
IndentationError: unexpected indent
[2023-03-23T17:23:27.532+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:27.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.108 seconds
[2023-03-23T17:23:29.158+0000] {processor.py:153} INFO - Started process (PID=6820) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:29.160+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:29.171+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:29.171+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:29.254+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:29.252+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 46
    create_bucket = GoogleCloudStorageCreateBucketOperator(
    ^
IndentationError: unexpected indent
[2023-03-23T17:23:29.259+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:29.324+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.172 seconds
[2023-03-23T17:23:31.713+0000] {processor.py:153} INFO - Started process (PID=6829) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:31.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:31.716+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:31.716+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:32.241+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:32.228+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:23:32.244+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:32.287+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.580 seconds
[2023-03-23T17:23:51.350+0000] {processor.py:153} INFO - Started process (PID=6876) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:51.352+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:23:51.354+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:51.354+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:52.012+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:23:52.001+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:23:52.014+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:23:52.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.699 seconds
[2023-03-23T17:24:22.676+0000] {processor.py:153} INFO - Started process (PID=6958) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:24:22.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:24:22.680+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:24:22.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:24:22.977+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:24:22.965+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:24:22.981+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:24:23.015+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.344 seconds
[2023-03-23T17:24:53.614+0000] {processor.py:153} INFO - Started process (PID=7038) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:24:53.615+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:24:53.617+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:24:53.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:24:53.886+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:24:53.878+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:24:53.895+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:24:53.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.315 seconds
[2023-03-23T17:25:24.941+0000] {processor.py:153} INFO - Started process (PID=7112) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:25:24.942+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:25:24.944+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:25:24.943+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:25:25.163+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:25:25.154+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:25:25.165+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:25:25.190+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.252 seconds
[2023-03-23T17:25:55.797+0000] {processor.py:153} INFO - Started process (PID=7185) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:25:55.806+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:25:55.808+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:25:55.807+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:25:56.042+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:25:56.033+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:25:56.045+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:25:56.067+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.274 seconds
[2023-03-23T17:26:26.314+0000] {processor.py:153} INFO - Started process (PID=7260) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:26:26.316+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:26:26.317+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:26:26.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:26:26.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:26:26.506+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:26:26.517+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:26:26.542+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.230 seconds
[2023-03-23T17:26:57.184+0000] {processor.py:153} INFO - Started process (PID=7340) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:26:57.194+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:26:57.209+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:26:57.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:26:59.093+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:26:58.903+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:26:59.118+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:26:59.188+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.977 seconds
[2023-03-23T17:27:30.225+0000] {processor.py:153} INFO - Started process (PID=7420) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:27:30.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:27:30.228+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:27:30.228+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:27:30.720+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:27:30.711+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:27:30.723+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:27:30.758+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.540 seconds
[2023-03-23T17:28:01.362+0000] {processor.py:153} INFO - Started process (PID=7494) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:28:01.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:28:01.370+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:28:01.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:28:01.771+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:28:01.762+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:28:01.774+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:28:01.803+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.454 seconds
[2023-03-23T17:28:32.116+0000] {processor.py:153} INFO - Started process (PID=7567) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:28:32.117+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:28:32.119+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:28:32.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:28:32.326+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:28:32.318+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:28:32.329+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:28:32.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.239 seconds
[2023-03-23T17:29:02.967+0000] {processor.py:153} INFO - Started process (PID=7641) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:29:02.968+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:29:02.969+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:29:02.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:29:03.182+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:29:03.174+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:29:03.184+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:29:03.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.243 seconds
[2023-03-23T17:29:33.832+0000] {processor.py:153} INFO - Started process (PID=7714) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:29:33.834+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:29:33.834+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:29:33.834+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:29:34.195+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:29:34.183+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:29:34.197+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:29:34.228+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.399 seconds
[2023-03-23T17:30:04.435+0000] {processor.py:153} INFO - Started process (PID=7804) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:30:04.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:30:04.437+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:30:04.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:30:04.786+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:30:04.777+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:30:04.789+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:30:04.822+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.393 seconds
[2023-03-23T17:30:35.004+0000] {processor.py:153} INFO - Started process (PID=7879) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:30:35.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:30:35.006+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:30:35.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:30:35.248+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:30:35.241+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:30:35.251+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:30:35.271+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.270 seconds
[2023-03-23T17:31:05.342+0000] {processor.py:153} INFO - Started process (PID=7949) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:31:05.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:31:05.344+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:31:05.344+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:31:05.534+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:31:05.526+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:31:05.535+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:31:05.557+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.218 seconds
[2023-03-23T17:31:35.830+0000] {processor.py:153} INFO - Started process (PID=8022) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:31:35.831+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:31:35.833+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:31:35.832+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:31:36.044+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:31:36.036+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:31:36.046+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:31:36.070+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.244 seconds
[2023-03-23T17:32:06.896+0000] {processor.py:153} INFO - Started process (PID=8111) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:32:06.898+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:32:06.899+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:32:06.899+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:32:07.130+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:32:07.125+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:32:07.132+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:32:07.150+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.256 seconds
[2023-03-23T17:32:37.984+0000] {processor.py:153} INFO - Started process (PID=8184) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:32:37.985+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:32:37.986+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:32:37.986+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:32:38.189+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:32:38.179+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:32:38.192+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:32:38.222+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.240 seconds
[2023-03-23T17:33:08.586+0000] {processor.py:153} INFO - Started process (PID=8257) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:33:08.587+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:33:08.588+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:33:08.588+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:33:08.936+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:33:08.928+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:33:08.939+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:33:08.966+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.385 seconds
[2023-03-23T17:33:39.064+0000] {processor.py:153} INFO - Started process (PID=8329) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:33:39.065+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:33:39.066+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:33:39.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:33:39.417+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:33:39.406+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:33:39.424+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:33:39.458+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.399 seconds
[2023-03-23T17:34:10.075+0000] {processor.py:153} INFO - Started process (PID=8402) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:34:10.077+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:34:10.078+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:34:10.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:34:10.546+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:34:10.535+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:34:10.548+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:34:10.579+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.509 seconds
[2023-03-23T17:34:40.815+0000] {processor.py:153} INFO - Started process (PID=8475) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:34:40.818+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:34:40.820+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:34:40.820+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:34:41.625+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:34:41.508+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:34:41.646+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:34:41.794+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.988 seconds
[2023-03-23T17:35:11.962+0000] {processor.py:153} INFO - Started process (PID=8550) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:35:11.963+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:35:11.969+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:35:11.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:35:12.337+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:35:12.324+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:35:12.340+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:35:12.380+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.425 seconds
[2023-03-23T17:35:43.031+0000] {processor.py:153} INFO - Started process (PID=8636) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:35:43.032+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:35:43.033+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:35:43.033+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:35:43.447+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:35:43.424+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:35:43.450+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:35:43.498+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.474 seconds
[2023-03-23T17:36:13.883+0000] {processor.py:153} INFO - Started process (PID=8710) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:36:13.885+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:36:13.887+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:36:13.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:36:14.441+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:36:14.429+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:36:14.444+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:36:14.473+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.597 seconds
[2023-03-23T17:36:44.879+0000] {processor.py:153} INFO - Started process (PID=8783) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:36:44.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:36:44.881+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:36:44.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:36:45.215+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:36:45.199+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:36:45.218+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:36:45.314+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.439 seconds
[2023-03-23T17:37:15.402+0000] {processor.py:153} INFO - Started process (PID=8866) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:37:15.403+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:37:15.404+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:37:15.404+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:37:15.713+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:37:15.705+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:37:15.715+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:37:15.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.344 seconds
[2023-03-23T17:37:46.755+0000] {processor.py:153} INFO - Started process (PID=8947) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:37:46.756+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:37:46.757+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:37:46.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:37:46.983+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:37:46.975+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:37:46.985+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:37:47.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.255 seconds
[2023-03-23T17:38:17.279+0000] {processor.py:153} INFO - Started process (PID=9020) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:38:17.280+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:38:17.281+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:38:17.281+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:38:17.591+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:38:17.583+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:38:17.593+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:38:17.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.353 seconds
[2023-03-23T17:38:47.744+0000] {processor.py:153} INFO - Started process (PID=9109) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:38:47.745+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:38:47.746+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:38:47.746+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:38:48.018+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:38:48.009+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:38:48.021+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:38:48.052+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.313 seconds
[2023-03-23T17:39:18.990+0000] {processor.py:153} INFO - Started process (PID=9182) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:39:18.991+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:39:18.993+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:39:18.993+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:39:19.320+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:39:19.308+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:39:19.323+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:39:19.352+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.367 seconds
[2023-03-23T17:39:49.848+0000] {processor.py:153} INFO - Started process (PID=9255) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:39:49.850+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:39:49.854+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:39:49.853+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:39:50.300+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:39:50.290+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:39:50.302+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:39:50.336+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.495 seconds
[2023-03-23T17:40:20.468+0000] {processor.py:153} INFO - Started process (PID=9329) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:40:20.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:40:20.470+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:40:20.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:40:20.664+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:40:20.656+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:40:20.666+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:40:20.684+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.220 seconds
[2023-03-23T17:40:51.086+0000] {processor.py:153} INFO - Started process (PID=9409) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:40:51.088+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:40:51.089+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:40:51.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:40:51.419+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:40:51.394+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:40:51.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:40:51.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.384 seconds
[2023-03-23T17:41:22.050+0000] {processor.py:153} INFO - Started process (PID=9489) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:41:22.051+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:41:22.052+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:41:22.052+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:41:22.325+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:41:22.315+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:41:22.327+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:41:22.354+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.309 seconds
[2023-03-23T17:41:52.725+0000] {processor.py:153} INFO - Started process (PID=9562) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:41:52.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:41:52.728+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:41:52.727+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:41:53.000+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:41:52.993+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:41:53.002+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:41:53.036+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.316 seconds
[2023-03-23T17:42:23.086+0000] {processor.py:153} INFO - Started process (PID=9653) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:42:23.087+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:42:23.088+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:42:23.088+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:42:23.289+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:42:23.279+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:42:23.292+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:42:23.315+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.234 seconds
[2023-03-23T17:42:53.790+0000] {processor.py:153} INFO - Started process (PID=9726) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:42:53.791+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:42:53.793+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:42:53.793+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:42:54.147+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:42:54.138+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:42:54.149+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:42:54.178+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.391 seconds
[2023-03-23T17:43:24.400+0000] {processor.py:153} INFO - Started process (PID=9799) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:43:24.401+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:43:24.403+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:43:24.402+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:43:24.594+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:43:24.588+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:43:24.596+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:43:24.621+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.226 seconds
[2023-03-23T17:43:54.732+0000] {processor.py:153} INFO - Started process (PID=9889) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:43:54.733+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:43:54.734+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:43:54.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:43:54.940+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:43:54.931+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:43:54.941+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:43:54.966+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.237 seconds
[2023-03-23T17:44:25.056+0000] {processor.py:153} INFO - Started process (PID=9961) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:44:25.058+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:44:25.059+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:44:25.059+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:44:25.340+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:44:25.329+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:44:25.343+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:44:25.365+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.313 seconds
[2023-03-23T17:44:56.249+0000] {processor.py:153} INFO - Started process (PID=10050) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:44:56.251+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:44:56.252+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:44:56.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:44:56.567+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:44:56.560+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:44:56.569+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:44:56.596+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.353 seconds
[2023-03-23T17:45:26.659+0000] {processor.py:153} INFO - Started process (PID=10123) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:45:26.660+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:45:26.661+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:45:26.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:45:26.913+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:45:26.905+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:45:26.915+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:45:26.943+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.288 seconds
[2023-03-23T17:45:57.543+0000] {processor.py:153} INFO - Started process (PID=10196) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:45:57.544+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:45:57.546+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:45:57.545+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:45:57.883+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:45:57.874+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:45:57.885+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:45:57.922+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.384 seconds
[2023-03-23T17:46:28.233+0000] {processor.py:153} INFO - Started process (PID=10278) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:46:28.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:46:28.236+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:46:28.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:46:28.570+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:46:28.561+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:46:28.573+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:46:28.603+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.374 seconds
[2023-03-23T17:46:58.801+0000] {processor.py:153} INFO - Started process (PID=10358) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:46:58.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:46:58.803+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:46:58.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:46:59.155+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:46:59.144+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:46:59.159+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:46:59.191+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.395 seconds
[2023-03-23T17:47:29.247+0000] {processor.py:153} INFO - Started process (PID=10433) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:47:29.248+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:47:29.249+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:47:29.249+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:47:29.479+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:47:29.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:47:29.481+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:47:29.503+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.260 seconds
[2023-03-23T17:48:00.120+0000] {processor.py:153} INFO - Started process (PID=10505) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:48:00.121+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:48:00.123+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:48:00.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:48:00.402+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:48:00.393+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:48:00.404+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:48:00.569+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.453 seconds
[2023-03-23T17:48:30.623+0000] {processor.py:153} INFO - Started process (PID=10578) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:48:30.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:48:30.626+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:48:30.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:48:30.850+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:48:30.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:48:30.852+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:48:30.875+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.256 seconds
[2023-03-23T17:49:01.088+0000] {processor.py:153} INFO - Started process (PID=10653) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:49:01.089+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:49:01.090+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:49:01.090+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:49:01.450+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:49:01.438+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:49:01.453+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:49:01.487+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.403 seconds
[2023-03-23T17:49:31.827+0000] {processor.py:153} INFO - Started process (PID=10740) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:49:31.829+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:49:31.830+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:49:31.829+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:49:32.119+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:49:32.109+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:49:32.121+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:49:32.150+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.328 seconds
[2023-03-23T17:50:02.244+0000] {processor.py:153} INFO - Started process (PID=10814) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:50:02.245+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:50:02.247+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:50:02.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:50:02.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:50:02.503+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:50:02.519+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:50:02.546+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.306 seconds
[2023-03-23T17:50:32.761+0000] {processor.py:153} INFO - Started process (PID=10886) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:50:32.763+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:50:32.766+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:50:32.766+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:50:33.107+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:50:33.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:50:33.110+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:50:33.135+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.381 seconds
[2023-03-23T17:51:03.291+0000] {processor.py:153} INFO - Started process (PID=10960) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:51:03.292+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:51:03.293+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:51:03.293+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:51:03.571+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:51:03.562+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:51:03.573+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:51:03.609+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.322 seconds
[2023-03-23T17:51:33.703+0000] {processor.py:153} INFO - Started process (PID=11049) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:51:33.704+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:51:33.706+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:51:33.705+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:51:34.000+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:51:33.988+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:51:34.003+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:51:34.044+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.345 seconds
[2023-03-23T17:52:04.326+0000] {processor.py:153} INFO - Started process (PID=11122) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:52:04.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:52:04.329+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:52:04.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:52:04.640+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:52:04.628+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:52:04.643+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:52:04.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.346 seconds
[2023-03-23T17:52:35.105+0000] {processor.py:153} INFO - Started process (PID=11195) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:52:35.106+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:52:35.107+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:52:35.107+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:52:35.431+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:52:35.421+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:52:35.433+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:52:35.468+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.368 seconds
[2023-03-23T17:53:05.641+0000] {processor.py:153} INFO - Started process (PID=11269) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:53:05.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:53:05.648+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:53:05.647+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:53:06.293+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:53:06.250+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:53:06.299+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:53:06.358+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.734 seconds
[2023-03-23T17:53:36.770+0000] {processor.py:153} INFO - Started process (PID=11356) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:53:36.771+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:53:36.772+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:53:36.772+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:53:37.020+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:53:37.012+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:53:37.022+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:53:37.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.277 seconds
[2023-03-23T17:54:07.351+0000] {processor.py:153} INFO - Started process (PID=11429) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:54:07.352+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:54:07.353+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:54:07.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:54:07.657+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:54:07.649+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:54:07.659+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:54:07.687+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.341 seconds
[2023-03-23T17:54:37.834+0000] {processor.py:153} INFO - Started process (PID=11502) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:54:37.836+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:54:37.837+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:54:37.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:54:38.135+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:54:38.125+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:54:38.138+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:54:38.174+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.344 seconds
[2023-03-23T17:55:08.418+0000] {processor.py:153} INFO - Started process (PID=11575) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:55:08.420+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:55:08.421+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:55:08.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:55:08.768+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:55:08.750+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:55:08.771+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:55:08.818+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.404 seconds
[2023-03-23T17:55:39.208+0000] {processor.py:153} INFO - Started process (PID=11664) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:55:39.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:55:39.212+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:55:39.211+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:55:39.537+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:55:39.528+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:55:39.539+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:55:39.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.364 seconds
[2023-03-23T17:56:09.974+0000] {processor.py:153} INFO - Started process (PID=11737) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:56:09.976+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:56:09.978+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:56:09.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:56:10.442+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:56:10.433+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:56:10.444+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:56:10.499+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.532 seconds
[2023-03-23T17:56:40.939+0000] {processor.py:153} INFO - Started process (PID=11802) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:56:40.941+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:56:40.943+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:56:40.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:56:42.503+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:56:42.396+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:56:42.510+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:56:42.616+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.687 seconds
[2023-03-23T17:57:13.275+0000] {processor.py:153} INFO - Started process (PID=11869) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:57:13.277+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:57:13.279+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:57:13.278+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:57:13.622+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:57:13.615+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:57:13.624+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:57:13.651+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.383 seconds
[2023-03-23T17:57:44.050+0000] {processor.py:153} INFO - Started process (PID=11942) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:57:44.052+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:57:44.053+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:57:44.053+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:57:44.308+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:57:44.300+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:57:44.312+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:57:44.346+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.301 seconds
[2023-03-23T17:58:15.014+0000] {processor.py:153} INFO - Started process (PID=12014) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:58:15.015+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:58:15.016+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:58:15.016+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:58:15.221+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:58:15.212+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:58:15.222+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:58:15.241+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.233 seconds
[2023-03-23T17:58:45.722+0000] {processor.py:153} INFO - Started process (PID=12103) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:58:45.723+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:58:45.725+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:58:45.724+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:58:45.966+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:58:45.956+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:58:45.968+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:58:46.001+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.282 seconds
[2023-03-23T17:59:16.191+0000] {processor.py:153} INFO - Started process (PID=12176) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:59:16.192+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:59:16.193+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:59:16.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:59:16.502+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:59:16.492+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:59:16.504+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:59:16.530+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.344 seconds
[2023-03-23T17:59:46.696+0000] {processor.py:153} INFO - Started process (PID=12249) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:59:46.697+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T17:59:46.698+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:59:46.698+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:59:46.984+0000] {logging_mixin.py:137} INFO - [2023-03-23T17:59:46.974+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T17:59:46.986+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T17:59:47.017+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.325 seconds
[2023-03-23T18:00:17.359+0000] {processor.py:153} INFO - Started process (PID=12321) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:00:17.361+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:00:17.362+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:00:17.362+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:00:17.650+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:00:17.634+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:00:17.652+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:00:17.678+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.325 seconds
[2023-03-23T18:00:47.881+0000] {processor.py:153} INFO - Started process (PID=12403) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:00:47.883+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:00:47.885+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:00:47.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:00:48.391+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:00:48.382+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:00:48.393+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:00:48.426+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.551 seconds
[2023-03-23T18:01:18.752+0000] {processor.py:153} INFO - Started process (PID=12483) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:01:18.753+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:01:18.755+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:01:18.755+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:01:19.213+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:01:19.195+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:01:19.228+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:01:19.301+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.557 seconds
[2023-03-23T18:01:49.396+0000] {processor.py:153} INFO - Started process (PID=12557) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:01:49.398+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:01:49.400+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:01:49.399+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:01:49.698+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:01:49.690+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:01:49.701+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:01:49.726+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.336 seconds
[2023-03-23T18:02:20.053+0000] {processor.py:153} INFO - Started process (PID=12632) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:02:20.055+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:02:20.062+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:02:20.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:02:20.488+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:02:20.479+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:02:20.491+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:02:20.517+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.472 seconds
[2023-03-23T18:02:51.210+0000] {processor.py:153} INFO - Started process (PID=12705) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:02:51.228+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:02:51.244+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:02:51.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:02:52.944+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:02:52.457+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:02:52.947+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:02:53.034+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.868 seconds
[2023-03-23T18:03:23.532+0000] {processor.py:153} INFO - Started process (PID=12778) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:03:23.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:03:23.552+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:03:23.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:03:24.928+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:03:24.786+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:03:24.931+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:03:25.028+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.504 seconds
[2023-03-23T18:03:55.990+0000] {processor.py:153} INFO - Started process (PID=12852) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:03:55.992+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:03:55.994+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:03:55.994+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:03:56.432+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:03:56.413+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:03:56.437+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:03:56.480+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.496 seconds
[2023-03-23T18:04:27.024+0000] {processor.py:153} INFO - Started process (PID=12916) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:04:27.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:04:27.037+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:04:27.028+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:04:27.703+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:04:27.688+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:04:27.706+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:04:27.748+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.734 seconds
[2023-03-23T18:04:58.535+0000] {processor.py:153} INFO - Started process (PID=12983) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:04:58.536+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:04:58.538+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:04:58.538+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:04:58.894+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:04:58.884+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:04:58.898+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:04:58.932+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.402 seconds
[2023-03-23T18:05:29.349+0000] {processor.py:153} INFO - Started process (PID=13056) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:05:29.351+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:05:29.353+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:05:29.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:05:30.071+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:05:30.043+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:05:30.099+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:05:30.377+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.043 seconds
[2023-03-23T18:06:01.367+0000] {processor.py:153} INFO - Started process (PID=13139) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:06:01.369+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:06:01.371+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:06:01.370+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:06:01.798+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:06:01.786+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:06:01.801+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:06:01.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.483 seconds
[2023-03-23T18:06:32.185+0000] {processor.py:153} INFO - Started process (PID=13218) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:06:32.187+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:06:32.189+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:06:32.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:06:32.543+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:06:32.531+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:06:32.546+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:06:32.577+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.403 seconds
[2023-03-23T18:07:02.649+0000] {processor.py:153} INFO - Started process (PID=13291) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:07:02.650+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:07:02.652+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:07:02.652+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:07:02.884+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:07:02.875+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:07:02.886+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:07:02.909+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.263 seconds
[2023-03-23T18:07:33.091+0000] {processor.py:153} INFO - Started process (PID=13364) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:07:33.092+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:07:33.093+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:07:33.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:07:33.329+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:07:33.317+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:07:33.331+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:07:33.361+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.273 seconds
[2023-03-23T18:08:03.430+0000] {processor.py:153} INFO - Started process (PID=13437) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:08:03.431+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:08:03.432+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:08:03.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:08:03.632+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:08:03.626+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:08:03.634+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:08:03.653+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.226 seconds
[2023-03-23T18:08:33.794+0000] {processor.py:153} INFO - Started process (PID=13509) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:08:33.795+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:08:33.796+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:08:33.796+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:08:33.993+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:08:33.982+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:08:33.995+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:08:34.022+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.232 seconds
[2023-03-23T18:09:04.257+0000] {processor.py:153} INFO - Started process (PID=13592) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:09:04.286+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:09:04.304+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:09:04.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:09:05.235+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:09:05.206+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:09:05.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:09:05.340+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.091 seconds
[2023-03-23T18:09:35.903+0000] {processor.py:153} INFO - Started process (PID=13672) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:09:35.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:09:35.916+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:09:35.916+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:09:36.771+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:09:36.745+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:09:36.777+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:09:37.040+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.151 seconds
[2023-03-23T18:10:07.434+0000] {processor.py:153} INFO - Started process (PID=13729) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:10:07.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:10:07.439+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:10:07.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:10:07.747+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:10:07.738+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:10:07.749+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:10:07.778+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.349 seconds
[2023-03-23T18:10:38.455+0000] {processor.py:153} INFO - Started process (PID=13802) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:10:38.458+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:10:38.463+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:10:38.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:10:39.491+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:10:39.431+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:10:39.529+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:10:39.615+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.166 seconds
[2023-03-23T18:11:10.329+0000] {processor.py:153} INFO - Started process (PID=13875) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:11:10.330+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:11:10.331+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:11:10.331+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:11:10.566+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:11:10.557+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:11:10.568+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:11:10.589+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.263 seconds
[2023-03-23T18:11:41.310+0000] {processor.py:153} INFO - Started process (PID=13948) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:11:41.313+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:11:41.315+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:11:41.314+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:11:41.867+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:11:41.855+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:11:41.871+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:11:41.908+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.609 seconds
[2023-03-23T18:12:12.577+0000] {processor.py:153} INFO - Started process (PID=14022) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:12:12.580+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:12:12.584+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:12:12.583+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:12:13.569+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:12:13.530+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:12:13.579+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:12:13.637+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.080 seconds
[2023-03-23T18:12:43.806+0000] {processor.py:153} INFO - Started process (PID=14095) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:12:43.809+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:12:43.810+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:12:43.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:12:44.032+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:12:44.019+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:12:44.034+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:12:44.068+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.265 seconds
[2023-03-23T18:13:14.752+0000] {processor.py:153} INFO - Started process (PID=14168) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:13:14.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:13:14.769+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:13:14.768+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:13:16.075+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:13:16.022+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:13:16.082+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:13:16.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.472 seconds
[2023-03-23T18:13:46.752+0000] {processor.py:153} INFO - Started process (PID=14242) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:13:46.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:13:46.768+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:13:46.767+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:13:47.690+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:13:47.657+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:13:47.721+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:13:47.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.059 seconds
[2023-03-23T18:14:18.308+0000] {processor.py:153} INFO - Started process (PID=14308) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:14:18.311+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:14:18.313+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:14:18.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:14:19.040+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:14:19.022+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:14:19.044+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:14:19.113+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.822 seconds
[2023-03-23T18:14:49.772+0000] {processor.py:153} INFO - Started process (PID=14373) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:14:49.774+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:14:49.774+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:14:49.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:14:50.054+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:14:50.046+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:14:50.056+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:14:50.078+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.309 seconds
[2023-03-23T18:15:20.147+0000] {processor.py:153} INFO - Started process (PID=14447) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:15:20.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:15:20.150+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:15:20.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:15:20.683+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:15:20.559+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:15:20.686+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:15:20.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.612 seconds
[2023-03-23T18:15:50.874+0000] {processor.py:153} INFO - Started process (PID=14528) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:15:50.876+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:15:50.878+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:15:50.877+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:15:51.243+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:15:51.231+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:15:51.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:15:51.279+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.413 seconds
[2023-03-23T18:16:22.150+0000] {processor.py:153} INFO - Started process (PID=14609) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:16:22.151+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:16:22.152+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:16:22.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:16:22.407+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:16:22.396+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:16:22.408+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:16:22.430+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.284 seconds
[2023-03-23T18:16:52.666+0000] {processor.py:153} INFO - Started process (PID=14682) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:16:52.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:16:52.668+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:16:52.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:16:52.940+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:16:52.932+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:16:52.943+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:16:52.975+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.316 seconds
[2023-03-23T18:17:23.131+0000] {processor.py:153} INFO - Started process (PID=14756) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:17:23.133+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:17:23.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:17:23.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:17:23.393+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:17:23.385+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:17:23.396+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:17:23.419+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.293 seconds
[2023-03-23T18:17:53.491+0000] {processor.py:153} INFO - Started process (PID=14829) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:17:53.493+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:17:53.494+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:17:53.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:17:53.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:17:53.810+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:17:53.825+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:17:53.854+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.368 seconds
[2023-03-23T18:18:23.942+0000] {processor.py:153} INFO - Started process (PID=14902) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:18:23.944+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:18:23.946+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:18:23.946+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:18:24.289+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:18:24.276+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:18:24.292+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:18:24.324+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.387 seconds
[2023-03-23T18:18:54.447+0000] {processor.py:153} INFO - Started process (PID=14972) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:18:54.448+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:18:54.450+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:18:54.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:18:54.708+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:18:54.700+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:18:54.710+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:18:54.732+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.291 seconds
[2023-03-23T18:19:25.210+0000] {processor.py:153} INFO - Started process (PID=15045) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:19:25.212+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:19:25.213+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:19:25.213+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:19:25.536+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:19:25.527+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:19:25.538+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:19:25.566+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.361 seconds
[2023-03-23T18:19:55.655+0000] {processor.py:153} INFO - Started process (PID=15118) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:19:55.656+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:19:55.658+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:19:55.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:19:55.998+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:19:55.990+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:19:56.001+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:19:56.039+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.389 seconds
[2023-03-23T18:20:26.523+0000] {processor.py:153} INFO - Started process (PID=15191) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:20:26.525+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:20:26.526+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:20:26.526+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:20:26.818+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:20:26.808+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:20:26.822+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:20:26.853+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.334 seconds
[2023-03-23T18:20:57.774+0000] {processor.py:153} INFO - Started process (PID=15264) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:20:57.778+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:20:57.791+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:20:57.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:20:58.918+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:20:58.825+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:20:58.960+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:20:59.202+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.435 seconds
[2023-03-23T18:21:29.514+0000] {processor.py:153} INFO - Started process (PID=15331) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:21:29.518+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:21:29.520+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:21:29.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:21:30.353+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:21:30.338+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:21:30.363+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:21:30.440+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.933 seconds
[2023-03-23T18:22:01.082+0000] {processor.py:153} INFO - Started process (PID=15403) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:22:01.092+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:22:01.094+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:22:01.094+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:22:01.503+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:22:01.495+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:22:01.506+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:22:01.682+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.608 seconds
[2023-03-23T18:22:31.974+0000] {processor.py:153} INFO - Started process (PID=15476) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:22:31.976+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:22:31.977+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:22:31.977+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:22:32.410+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:22:32.399+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:22:32.412+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:22:32.452+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.479 seconds
[2023-03-23T18:23:03.145+0000] {processor.py:153} INFO - Started process (PID=15551) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:23:03.146+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:23:03.148+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:23:03.147+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:23:03.551+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:23:03.542+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:23:03.554+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:23:03.607+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.467 seconds
[2023-03-23T18:23:33.787+0000] {processor.py:153} INFO - Started process (PID=15631) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:23:33.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:23:33.791+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:23:33.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:23:34.170+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:23:34.160+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:23:34.174+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:23:34.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.426 seconds
[2023-03-23T18:24:04.381+0000] {processor.py:153} INFO - Started process (PID=15704) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:24:04.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:24:04.384+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:24:04.384+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:24:06.857+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:24:06.801+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:24:06.861+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:24:06.909+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.534 seconds
[2023-03-23T18:24:37.024+0000] {processor.py:153} INFO - Started process (PID=15781) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:24:37.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:24:37.028+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:24:37.027+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:24:37.478+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:24:37.467+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:24:37.481+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:24:37.523+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.505 seconds
[2023-03-23T18:25:07.874+0000] {processor.py:153} INFO - Started process (PID=15854) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:25:07.875+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:25:07.876+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:25:07.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:25:08.144+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:25:08.136+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:25:08.146+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:25:08.175+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.305 seconds
[2023-03-23T18:25:38.515+0000] {processor.py:153} INFO - Started process (PID=15927) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:25:38.517+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:25:38.518+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:25:38.517+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:25:38.785+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:25:38.775+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:25:38.788+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:25:38.816+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.305 seconds
[2023-03-23T18:26:09.009+0000] {processor.py:153} INFO - Started process (PID=16001) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:26:09.011+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:26:09.013+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:26:09.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:26:09.399+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:26:09.387+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:26:09.401+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:26:09.431+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.429 seconds
[2023-03-23T18:26:40.298+0000] {processor.py:153} INFO - Started process (PID=16075) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:26:40.299+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:26:40.300+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:26:40.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:26:40.598+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:26:40.589+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:26:40.600+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:26:40.643+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.349 seconds
[2023-03-23T18:27:10.772+0000] {processor.py:153} INFO - Started process (PID=16157) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:27:10.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:27:10.775+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:27:10.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:27:11.377+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:27:11.345+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:27:11.380+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:27:11.463+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.698 seconds
[2023-03-23T18:27:41.541+0000] {processor.py:153} INFO - Started process (PID=16239) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:27:41.543+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:27:41.544+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:27:41.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:27:41.815+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:27:41.804+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:27:41.818+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:27:41.848+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.313 seconds
[2023-03-23T18:28:12.273+0000] {processor.py:153} INFO - Started process (PID=16310) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:28:12.274+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:28:12.276+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:28:12.275+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:28:12.838+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:28:12.814+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:28:12.840+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:28:12.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.604 seconds
[2023-03-23T18:28:43.095+0000] {processor.py:153} INFO - Started process (PID=16385) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:28:43.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:28:43.098+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:28:43.097+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:28:43.349+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:28:43.340+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:28:43.351+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:28:43.377+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.286 seconds
[2023-03-23T18:29:14.396+0000] {processor.py:153} INFO - Started process (PID=16458) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:29:14.398+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:29:14.399+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:29:14.399+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:29:14.680+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:29:14.671+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:29:14.682+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:29:14.716+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.324 seconds
[2023-03-23T18:29:44.982+0000] {processor.py:153} INFO - Started process (PID=16532) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:29:44.985+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:29:44.987+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:29:44.986+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:29:45.335+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:29:45.322+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:29:45.339+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:29:45.592+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.616 seconds
[2023-03-23T18:30:15.781+0000] {processor.py:153} INFO - Started process (PID=16615) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:30:15.785+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:30:15.787+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:30:15.786+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:30:16.113+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:30:16.101+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:30:16.115+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:30:16.142+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.367 seconds
[2023-03-23T18:30:46.904+0000] {processor.py:153} INFO - Started process (PID=16696) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:30:46.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:30:46.906+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:30:46.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:30:47.179+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:30:47.170+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:30:47.181+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:30:47.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.311 seconds
[2023-03-23T18:31:17.743+0000] {processor.py:153} INFO - Started process (PID=16769) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:31:17.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:31:17.745+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:31:17.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:31:17.951+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:31:17.939+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:31:17.953+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:31:17.980+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.239 seconds
[2023-03-23T18:31:48.314+0000] {processor.py:153} INFO - Started process (PID=16842) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:31:48.314+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:31:48.315+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:31:48.315+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:31:48.525+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:31:48.515+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:31:48.528+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:31:48.749+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.438 seconds
[2023-03-23T18:32:19.022+0000] {processor.py:153} INFO - Started process (PID=16924) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:32:19.028+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:32:19.029+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:32:19.029+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:32:19.549+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:32:19.539+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:32:19.551+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:32:19.570+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.556 seconds
[2023-03-23T18:32:50.547+0000] {processor.py:153} INFO - Started process (PID=17004) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:32:50.574+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:32:50.595+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:32:50.594+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:32:51.909+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:32:51.873+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:32:51.994+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:32:52.146+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.606 seconds
[2023-03-23T18:33:22.759+0000] {processor.py:153} INFO - Started process (PID=17077) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:33:22.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:33:22.763+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:33:22.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:33:23.369+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:33:23.352+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:33:23.372+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:33:23.421+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.668 seconds
[2023-03-23T18:33:53.560+0000] {processor.py:153} INFO - Started process (PID=17150) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:33:53.561+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:33:53.563+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:33:53.562+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:33:54.074+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:33:54.045+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:33:54.076+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:33:54.399+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.846 seconds
[2023-03-23T18:34:24.611+0000] {processor.py:153} INFO - Started process (PID=17231) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:34:24.612+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:34:24.614+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:34:24.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:34:25.700+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:34:25.675+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:34:25.714+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:34:25.765+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.161 seconds
[2023-03-23T18:34:56.415+0000] {processor.py:153} INFO - Started process (PID=17306) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:34:56.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:34:56.418+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:34:56.417+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:34:56.961+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:34:56.950+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:34:56.964+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:34:56.996+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.585 seconds
[2023-03-23T18:35:27.469+0000] {processor.py:153} INFO - Started process (PID=17386) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:35:27.471+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:35:27.473+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:35:27.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:35:27.874+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:35:27.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:35:27.877+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:35:27.913+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.454 seconds
[2023-03-23T18:35:58.143+0000] {processor.py:153} INFO - Started process (PID=17460) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:35:58.145+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:35:58.147+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:35:58.146+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:35:58.793+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:35:58.779+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:35:58.796+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:35:58.834+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.702 seconds
[2023-03-23T18:36:29.193+0000] {processor.py:153} INFO - Started process (PID=17534) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:36:29.207+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:36:29.210+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:36:29.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:36:30.476+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:36:30.330+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:36:30.504+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:36:30.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.368 seconds
[2023-03-23T18:37:01.075+0000] {processor.py:153} INFO - Started process (PID=17602) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:37:01.077+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:37:01.078+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:37:01.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:37:01.597+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:37:01.585+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:37:01.600+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:37:01.701+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.632 seconds
[2023-03-23T18:37:31.796+0000] {processor.py:153} INFO - Started process (PID=17682) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:37:31.798+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:37:31.799+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:37:31.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:37:32.172+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:37:32.163+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:37:32.175+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:37:32.225+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.436 seconds
[2023-03-23T18:38:02.759+0000] {processor.py:153} INFO - Started process (PID=17748) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:38:02.760+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:38:02.762+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:38:02.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:38:03.539+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:38:03.529+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:38:03.543+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:38:03.583+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.830 seconds
[2023-03-23T18:38:34.353+0000] {processor.py:153} INFO - Started process (PID=17829) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:38:34.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:38:34.368+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:38:34.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:38:35.190+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:38:35.177+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:38:35.192+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:38:35.233+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.886 seconds
[2023-03-23T18:39:05.657+0000] {processor.py:153} INFO - Started process (PID=17904) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:39:05.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:39:05.663+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:39:05.662+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:39:06.064+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:39:06.053+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:39:06.066+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:39:06.104+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.454 seconds
[2023-03-23T18:39:36.963+0000] {processor.py:153} INFO - Started process (PID=17977) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:39:36.965+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:39:36.966+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:39:36.966+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:39:37.309+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:39:37.296+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:39:37.312+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:39:37.349+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.392 seconds
[2023-03-23T18:40:07.666+0000] {processor.py:153} INFO - Started process (PID=18050) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:40:07.668+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:40:07.669+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:40:07.669+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:40:08.376+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:40:08.367+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:40:08.379+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:40:08.411+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.753 seconds
[2023-03-23T18:40:38.617+0000] {processor.py:153} INFO - Started process (PID=18125) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:40:38.618+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:40:38.620+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:40:38.620+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:40:39.644+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:40:39.627+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:40:39.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:40:39.696+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.089 seconds
[2023-03-23T18:41:09.956+0000] {processor.py:153} INFO - Started process (PID=18198) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:41:09.958+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:41:09.960+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:41:09.960+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:41:10.609+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:41:10.596+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:41:10.612+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:41:10.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.701 seconds
[2023-03-23T18:41:40.940+0000] {processor.py:153} INFO - Started process (PID=18271) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:41:40.941+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:41:40.942+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:41:40.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:41:41.366+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:41:41.356+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:41:41.369+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:41:41.431+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.498 seconds
[2023-03-23T18:42:12.092+0000] {processor.py:153} INFO - Started process (PID=18344) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:42:12.095+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:42:12.101+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:42:12.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:42:13.076+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:42:13.062+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:42:13.083+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:42:13.155+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.071 seconds
[2023-03-23T18:42:43.722+0000] {processor.py:153} INFO - Started process (PID=18420) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:42:43.726+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:42:43.728+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:42:43.728+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:42:44.388+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:42:44.370+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:42:44.391+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:42:44.424+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.710 seconds
[2023-03-23T18:43:15.106+0000] {processor.py:153} INFO - Started process (PID=18495) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:43:15.107+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:43:15.109+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:43:15.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:43:15.887+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:43:15.762+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:43:15.926+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:43:15.988+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.890 seconds
[2023-03-23T18:43:46.478+0000] {processor.py:153} INFO - Started process (PID=18561) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:43:46.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:43:46.484+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:43:46.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:43:46.935+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:43:46.922+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:43:46.938+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:43:46.978+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.511 seconds
[2023-03-23T18:44:17.310+0000] {processor.py:153} INFO - Started process (PID=18634) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:44:17.312+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:44:17.313+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:44:17.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:44:17.953+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:44:17.945+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:44:17.956+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:44:17.980+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.675 seconds
[2023-03-23T18:44:48.148+0000] {processor.py:153} INFO - Started process (PID=18714) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:44:48.150+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:44:48.152+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:44:48.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:44:48.727+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:44:48.715+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:44:48.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:44:48.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.614 seconds
[2023-03-23T18:45:19.505+0000] {processor.py:153} INFO - Started process (PID=18786) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:45:19.507+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:45:19.509+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:45:19.508+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:45:20.196+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:45:20.186+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:45:20.199+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:45:20.229+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.732 seconds
[2023-03-23T18:45:50.387+0000] {processor.py:153} INFO - Started process (PID=18859) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:45:50.389+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:45:50.391+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:45:50.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:45:51.389+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:45:51.283+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:45:51.393+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:45:51.474+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.094 seconds
[2023-03-23T18:46:22.219+0000] {processor.py:153} INFO - Started process (PID=18932) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:46:22.223+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:46:22.232+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:46:22.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:46:23.965+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:46:23.948+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:46:23.970+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:46:24.046+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.833 seconds
[2023-03-23T18:46:54.214+0000] {processor.py:153} INFO - Started process (PID=19007) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:46:54.215+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:46:54.216+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:46:54.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:46:55.165+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:46:55.141+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:46:55.169+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:46:55.247+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.039 seconds
[2023-03-23T18:47:25.693+0000] {processor.py:153} INFO - Started process (PID=19080) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:47:25.695+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:47:25.698+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:47:25.698+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:47:26.457+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:47:26.446+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:47:26.460+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:47:26.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.805 seconds
[2023-03-23T18:47:57.709+0000] {processor.py:153} INFO - Started process (PID=19147) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:47:57.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:47:57.713+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:47:57.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:47:59.584+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:47:59.447+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:47:59.648+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:47:59.777+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.075 seconds
[2023-03-23T18:48:30.533+0000] {processor.py:153} INFO - Started process (PID=19228) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:48:30.546+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:48:30.549+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:48:30.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:48:31.492+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:48:31.455+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:48:31.541+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:48:31.607+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.081 seconds
[2023-03-23T18:49:02.431+0000] {processor.py:153} INFO - Started process (PID=19302) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:49:02.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:49:02.434+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:49:02.434+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:49:03.157+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:49:03.145+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:49:03.160+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:49:03.191+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.766 seconds
[2023-03-23T18:49:33.590+0000] {processor.py:153} INFO - Started process (PID=19377) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:49:33.593+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:49:33.595+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:49:33.594+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:49:34.042+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:49:34.034+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:49:34.044+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:49:34.070+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.487 seconds
[2023-03-23T18:50:04.418+0000] {processor.py:153} INFO - Started process (PID=19449) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:50:04.438+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:50:04.440+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:50:04.440+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:50:04.788+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:50:04.780+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:50:04.790+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:50:04.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.422 seconds
[2023-03-23T18:50:35.006+0000] {processor.py:153} INFO - Started process (PID=19522) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:50:35.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:50:35.009+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:50:35.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:50:35.663+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:50:35.650+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:50:35.666+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:50:35.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.693 seconds
[2023-03-23T18:51:06.162+0000] {processor.py:153} INFO - Started process (PID=19595) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:51:06.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:51:06.166+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:51:06.166+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:51:06.766+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:51:06.757+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:51:06.768+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:51:06.800+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.644 seconds
[2023-03-23T18:51:37.019+0000] {processor.py:153} INFO - Started process (PID=19670) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:51:37.021+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:51:37.022+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:51:37.022+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:51:37.321+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:51:37.312+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:51:37.323+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:51:37.375+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.361 seconds
[2023-03-23T18:52:07.584+0000] {processor.py:153} INFO - Started process (PID=19748) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:52:07.586+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:52:07.587+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:52:07.587+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:52:07.951+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:52:07.942+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:52:07.954+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:52:08.001+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.423 seconds
[2023-03-23T18:52:38.072+0000] {processor.py:153} INFO - Started process (PID=19812) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:52:38.074+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:52:38.075+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:52:38.074+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:52:38.561+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:52:38.550+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:52:38.564+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:52:38.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.526 seconds
[2023-03-23T18:53:08.995+0000] {processor.py:153} INFO - Started process (PID=19885) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:53:08.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:53:09.000+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:53:08.999+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:53:09.717+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:53:09.703+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:53:09.720+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:53:09.787+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.799 seconds
[2023-03-23T18:53:39.914+0000] {processor.py:153} INFO - Started process (PID=19960) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:53:39.920+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:53:39.925+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:53:39.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:53:40.391+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:53:40.374+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:53:40.394+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:53:40.431+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.524 seconds
[2023-03-23T18:54:11.430+0000] {processor.py:153} INFO - Started process (PID=20033) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:54:11.431+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:54:11.433+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:54:11.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:54:11.762+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:54:11.749+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:54:11.764+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:54:11.976+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.551 seconds
[2023-03-23T18:54:42.118+0000] {processor.py:153} INFO - Started process (PID=20116) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:54:42.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:54:42.121+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:54:42.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:54:42.804+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:54:42.796+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:54:42.806+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:54:42.834+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.722 seconds
[2023-03-23T18:55:13.645+0000] {processor.py:153} INFO - Started process (PID=20196) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:55:13.647+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:55:13.649+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:55:13.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:55:14.506+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:55:14.489+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:55:14.509+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:55:14.549+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.910 seconds
[2023-03-23T18:55:44.710+0000] {processor.py:153} INFO - Started process (PID=20271) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:55:44.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:55:44.713+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:55:44.712+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:55:45.059+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:55:45.046+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:55:45.061+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:55:45.090+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.384 seconds
[2023-03-23T18:56:15.527+0000] {processor.py:153} INFO - Started process (PID=20343) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:56:15.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:56:15.561+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:56:15.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:56:16.505+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:56:16.494+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:56:16.508+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:56:16.730+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.210 seconds
[2023-03-23T18:56:46.806+0000] {processor.py:153} INFO - Started process (PID=20417) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:56:46.808+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:56:46.812+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:56:46.812+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:56:47.832+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:56:47.814+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:56:47.839+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:56:47.882+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.083 seconds
[2023-03-23T18:57:18.195+0000] {processor.py:153} INFO - Started process (PID=20484) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:57:18.197+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:57:18.199+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:57:18.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:57:19.319+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:57:19.308+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:57:19.322+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:57:19.365+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.176 seconds
[2023-03-23T18:57:50.182+0000] {processor.py:153} INFO - Started process (PID=20564) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:57:50.185+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:57:50.186+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:57:50.186+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:57:50.740+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:57:50.723+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:57:50.743+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:57:50.794+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.618 seconds
[2023-03-23T18:58:21.656+0000] {processor.py:153} INFO - Started process (PID=20637) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:58:21.658+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:58:21.659+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:58:21.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:58:22.079+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:58:22.058+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:58:22.083+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:58:22.356+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.707 seconds
[2023-03-23T18:58:52.618+0000] {processor.py:153} INFO - Started process (PID=20712) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:58:52.620+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:58:52.621+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:58:52.621+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:58:53.374+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:58:53.344+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:58:53.377+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:58:53.414+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.802 seconds
[2023-03-23T18:59:24.007+0000] {processor.py:153} INFO - Started process (PID=20786) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:59:24.009+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:59:24.010+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:59:24.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:59:24.724+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:59:24.715+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:59:24.727+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:59:24.752+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.752 seconds
[2023-03-23T18:59:54.947+0000] {processor.py:153} INFO - Started process (PID=20853) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:59:54.952+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T18:59:54.962+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:59:54.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:59:55.625+0000] {logging_mixin.py:137} INFO - [2023-03-23T18:59:55.585+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T18:59:55.629+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T18:59:55.681+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.741 seconds
[2023-03-23T19:00:26.000+0000] {processor.py:153} INFO - Started process (PID=20924) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:00:26.002+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:00:26.004+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:00:26.004+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:00:27.175+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:00:27.165+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:00:27.179+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:00:27.217+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.225 seconds
[2023-03-23T19:00:57.324+0000] {processor.py:153} INFO - Started process (PID=20998) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:00:57.326+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:00:57.328+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:00:57.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:00:58.023+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:00:58.016+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:00:58.025+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:00:58.059+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.742 seconds
[2023-03-23T19:01:28.302+0000] {processor.py:153} INFO - Started process (PID=21063) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:01:28.304+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:01:28.305+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:01:28.305+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:01:28.809+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:01:28.797+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:01:28.812+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:01:28.839+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.542 seconds
[2023-03-23T19:01:59.732+0000] {processor.py:153} INFO - Started process (PID=21136) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:01:59.733+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:01:59.734+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:01:59.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:02:00.133+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:02:00.115+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:02:00.136+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:02:00.186+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.463 seconds
[2023-03-23T19:02:30.436+0000] {processor.py:153} INFO - Started process (PID=21209) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:02:30.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:02:30.446+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:02:30.445+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:02:31.082+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:02:31.074+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:02:31.084+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:02:31.116+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.687 seconds
[2023-03-23T19:03:01.460+0000] {processor.py:153} INFO - Started process (PID=21282) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:03:01.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:03:01.463+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:03:01.463+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:03:01.955+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:03:01.947+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:03:01.957+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:03:01.979+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.525 seconds
[2023-03-23T19:03:32.037+0000] {processor.py:153} INFO - Started process (PID=21357) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:03:32.039+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:03:32.040+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:03:32.040+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:03:32.607+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:03:32.597+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:03:32.610+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:03:32.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.608 seconds
[2023-03-23T19:04:02.877+0000] {processor.py:153} INFO - Started process (PID=21431) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:04:02.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:04:02.879+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:04:02.879+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:04:03.205+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:04:03.195+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:04:03.208+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:04:03.415+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.544 seconds
[2023-03-23T19:04:33.471+0000] {processor.py:153} INFO - Started process (PID=21505) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:04:33.472+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:04:33.474+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:04:33.473+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:04:33.925+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:04:33.918+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:04:33.927+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:04:33.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.487 seconds
[2023-03-23T19:05:04.180+0000] {processor.py:153} INFO - Started process (PID=21579) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:05:04.181+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:05:04.183+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:05:04.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:05:04.657+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:05:04.648+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:05:04.660+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:05:04.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.523 seconds
[2023-03-23T19:05:35.210+0000] {processor.py:153} INFO - Started process (PID=21652) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:05:35.212+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:05:35.214+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:05:35.214+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:05:35.897+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:05:35.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:05:35.901+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:05:35.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.721 seconds
[2023-03-23T19:06:06.633+0000] {processor.py:153} INFO - Started process (PID=21725) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:06:06.635+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:06:06.635+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:06:06.635+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:06:07.107+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:06:07.094+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:06:07.109+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:06:07.137+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.509 seconds
[2023-03-23T19:06:37.454+0000] {processor.py:153} INFO - Started process (PID=21798) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:06:37.455+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:06:37.457+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:06:37.456+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:06:38.025+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:06:38.007+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:06:38.030+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:06:38.063+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.615 seconds
[2023-03-23T19:07:08.332+0000] {processor.py:153} INFO - Started process (PID=21871) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:07:08.334+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:07:08.335+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:07:08.335+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:07:08.873+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:07:08.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:07:08.875+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:07:08.901+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.574 seconds
[2023-03-23T19:07:39.383+0000] {processor.py:153} INFO - Started process (PID=21944) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:07:39.391+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:07:39.395+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:07:39.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:07:41.765+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:07:41.699+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:07:41.769+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:07:41.864+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.488 seconds
[2023-03-23T19:08:12.785+0000] {processor.py:153} INFO - Started process (PID=22012) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:08:12.790+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:08:12.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:08:12.822+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:08:15.210+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:08:15.096+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:08:15.264+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:08:15.413+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.635 seconds
[2023-03-23T19:08:45.632+0000] {processor.py:153} INFO - Started process (PID=22083) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:08:45.635+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:08:45.643+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:08:45.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:08:46.392+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:08:46.380+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:08:46.395+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:08:46.422+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.796 seconds
[2023-03-23T19:09:17.342+0000] {processor.py:153} INFO - Started process (PID=22161) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:09:17.344+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:09:17.347+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:09:17.347+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:09:18.098+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:09:18.086+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:09:18.102+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:09:18.134+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.797 seconds
[2023-03-23T19:09:48.232+0000] {processor.py:153} INFO - Started process (PID=22236) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:09:48.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:09:48.236+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:09:48.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:09:48.950+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:09:48.884+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:09:48.969+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:09:49.035+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.813 seconds
[2023-03-23T19:10:19.636+0000] {processor.py:153} INFO - Started process (PID=22309) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:10:19.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:10:19.639+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:10:19.639+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:10:20.357+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:10:20.332+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:10:20.362+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:10:20.408+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.792 seconds
[2023-03-23T19:10:50.691+0000] {processor.py:153} INFO - Started process (PID=22373) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:10:50.692+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:10:50.693+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:10:50.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:10:51.296+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:10:51.284+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:10:51.299+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:10:51.373+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.688 seconds
[2023-03-23T19:11:21.638+0000] {processor.py:153} INFO - Started process (PID=22446) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:11:21.640+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:11:21.642+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:11:21.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:11:22.330+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:11:22.314+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:11:22.333+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:11:22.390+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.759 seconds
[2023-03-23T19:11:52.960+0000] {processor.py:153} INFO - Started process (PID=22519) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:11:52.962+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:11:52.963+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:11:52.963+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:11:53.420+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:11:53.412+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:11:53.423+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:11:53.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.490 seconds
[2023-03-23T19:12:23.612+0000] {processor.py:153} INFO - Started process (PID=22591) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:12:23.614+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:12:23.615+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:12:23.615+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:12:24.234+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:12:24.222+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:12:24.238+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:12:24.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.664 seconds
[2023-03-23T19:12:54.730+0000] {processor.py:153} INFO - Started process (PID=22666) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:12:54.732+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:12:54.734+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:12:54.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:12:55.922+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:12:55.886+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:12:55.937+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:12:55.979+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.256 seconds
[2023-03-23T19:13:26.348+0000] {processor.py:153} INFO - Started process (PID=22739) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:13:26.355+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:13:26.356+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:13:26.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:13:27.717+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:13:27.655+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:13:27.732+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:13:27.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.469 seconds
[2023-03-23T19:13:58.878+0000] {processor.py:153} INFO - Started process (PID=22812) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:13:58.879+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:13:58.881+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:13:58.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:13:59.290+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:13:59.278+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:13:59.293+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:13:59.319+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.446 seconds
[2023-03-23T19:14:29.504+0000] {processor.py:153} INFO - Started process (PID=22887) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:14:29.505+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:14:29.506+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:14:29.505+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:14:29.809+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:14:29.798+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:14:29.812+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:14:29.835+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.334 seconds
[2023-03-23T19:15:00.832+0000] {processor.py:153} INFO - Started process (PID=22960) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:15:00.833+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:15:00.835+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:15:00.834+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:15:01.206+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:15:01.197+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:15:01.207+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:15:01.312+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.485 seconds
[2023-03-23T19:15:31.479+0000] {processor.py:153} INFO - Started process (PID=23043) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:15:31.482+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:15:31.486+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:15:31.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:15:32.550+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:15:32.449+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:15:32.554+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:15:32.611+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.139 seconds
[2023-03-23T19:16:03.332+0000] {processor.py:153} INFO - Started process (PID=23125) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:16:03.336+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:16:03.339+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:16:03.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:16:04.203+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:16:04.176+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:16:04.206+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:16:04.240+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.914 seconds
[2023-03-23T19:16:34.808+0000] {processor.py:153} INFO - Started process (PID=23199) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:16:34.810+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:16:34.811+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:16:34.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:16:35.090+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:16:35.077+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:16:35.093+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:16:35.337+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.533 seconds
[2023-03-23T19:17:05.475+0000] {processor.py:153} INFO - Started process (PID=23272) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:17:05.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:17:05.478+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:17:05.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:17:05.808+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:17:05.800+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:17:05.810+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:17:05.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.353 seconds
[2023-03-23T19:17:36.083+0000] {processor.py:153} INFO - Started process (PID=23345) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:17:36.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:17:36.086+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:17:36.086+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:17:36.643+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:17:36.632+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:17:36.646+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:17:36.675+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.615 seconds
[2023-03-23T19:18:06.761+0000] {processor.py:153} INFO - Started process (PID=23419) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:18:06.762+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:18:06.763+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:18:06.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:18:07.079+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:18:07.067+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:18:07.084+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:18:07.109+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.353 seconds
[2023-03-23T19:18:37.361+0000] {processor.py:153} INFO - Started process (PID=23511) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:18:37.363+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:18:37.373+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:18:37.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:18:38.108+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:18:38.092+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:18:38.113+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:18:38.457+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.103 seconds
[2023-03-23T19:19:08.767+0000] {processor.py:153} INFO - Started process (PID=23584) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:19:08.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:19:08.770+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:19:08.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:19:09.098+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:19:09.090+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:19:09.100+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:19:09.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.355 seconds
[2023-03-23T19:19:39.480+0000] {processor.py:153} INFO - Started process (PID=23657) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:19:39.483+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:19:39.484+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:19:39.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:19:40.271+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:19:40.258+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:19:40.274+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:19:40.316+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.850 seconds
[2023-03-23T19:20:11.233+0000] {processor.py:153} INFO - Started process (PID=23732) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:20:11.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:20:11.235+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:20:11.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:20:11.542+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:20:11.532+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:20:11.545+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:20:11.563+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.333 seconds
[2023-03-23T19:20:41.938+0000] {processor.py:153} INFO - Started process (PID=23815) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:20:41.941+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:20:41.942+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:20:41.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:20:42.646+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:20:42.630+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:20:42.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:20:42.699+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.769 seconds
[2023-03-23T19:21:13.088+0000] {processor.py:153} INFO - Started process (PID=23895) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:21:13.091+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:21:13.094+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:21:13.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:21:13.662+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:21:13.652+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:21:13.665+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:21:13.688+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.608 seconds
[2023-03-23T19:21:44.638+0000] {processor.py:153} INFO - Started process (PID=23968) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:21:44.639+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:21:44.641+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:21:44.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:21:45.419+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:21:45.384+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:21:45.429+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:21:45.476+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.847 seconds
[2023-03-23T19:22:15.558+0000] {processor.py:153} INFO - Started process (PID=24043) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:22:15.559+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:22:15.560+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:22:15.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:22:15.852+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:22:15.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:22:15.855+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:22:15.876+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.323 seconds
[2023-03-23T19:22:46.129+0000] {processor.py:153} INFO - Started process (PID=24126) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:22:46.132+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:22:46.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:22:46.133+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:22:47.044+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:22:47.031+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:22:47.047+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:22:47.082+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.961 seconds
[2023-03-23T19:23:17.638+0000] {processor.py:153} INFO - Started process (PID=24208) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:23:17.639+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:23:17.640+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:23:17.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:23:18.114+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:23:18.106+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:23:18.117+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:23:18.142+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.508 seconds
[2023-03-23T19:23:48.251+0000] {processor.py:153} INFO - Started process (PID=24283) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:23:48.253+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:23:48.254+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:23:48.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:23:48.668+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:23:48.656+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:23:48.671+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:23:48.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.448 seconds
[2023-03-23T19:24:18.800+0000] {processor.py:153} INFO - Started process (PID=24353) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:24:18.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:24:18.802+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:24:18.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:24:19.114+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:24:19.108+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:24:19.116+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:24:19.132+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.337 seconds
[2023-03-23T19:24:49.452+0000] {processor.py:153} INFO - Started process (PID=24427) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:24:49.454+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:24:49.456+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:24:49.455+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:24:49.966+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:24:49.959+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:24:49.969+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:24:49.986+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.539 seconds
[2023-03-23T19:25:20.115+0000] {processor.py:153} INFO - Started process (PID=24509) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:25:20.116+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:25:20.117+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:25:20.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:25:20.577+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:25:20.560+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:25:20.584+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:25:20.671+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.563 seconds
[2023-03-23T19:25:50.766+0000] {processor.py:153} INFO - Started process (PID=24589) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:25:50.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:25:50.769+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:25:50.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:25:51.258+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:25:51.251+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:25:51.260+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:25:51.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.522 seconds
[2023-03-23T19:26:21.570+0000] {processor.py:153} INFO - Started process (PID=24662) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:26:21.576+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:26:21.582+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:26:21.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:26:22.159+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:26:22.153+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:26:22.161+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:26:22.187+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.622 seconds
[2023-03-23T19:26:52.285+0000] {processor.py:153} INFO - Started process (PID=24752) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:26:52.287+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:26:52.291+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:26:52.290+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:26:53.053+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:26:53.042+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:26:53.055+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:26:53.083+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.812 seconds
[2023-03-23T19:27:23.405+0000] {processor.py:153} INFO - Started process (PID=24827) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:27:23.407+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:27:23.409+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:27:23.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:27:24.194+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:27:24.183+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:27:24.197+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:27:24.232+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.833 seconds
[2023-03-23T19:27:54.563+0000] {processor.py:153} INFO - Started process (PID=24900) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:27:54.565+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:27:54.566+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:27:54.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:27:54.938+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:27:54.926+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:27:54.941+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:27:54.960+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.400 seconds
[2023-03-23T19:28:25.093+0000] {processor.py:153} INFO - Started process (PID=24973) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:28:25.095+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:28:25.097+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:28:25.097+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:28:25.428+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:28:25.420+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:28:25.431+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:28:25.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.360 seconds
[2023-03-23T19:28:56.068+0000] {processor.py:153} INFO - Started process (PID=25062) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:28:56.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:28:56.071+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:28:56.071+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:28:56.403+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:28:56.397+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:28:56.405+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:28:56.438+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.375 seconds
[2023-03-23T19:29:26.726+0000] {processor.py:153} INFO - Started process (PID=25135) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:29:26.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:29:26.729+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:29:26.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:29:27.123+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:29:27.110+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:29:27.126+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:29:27.145+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.425 seconds
[2023-03-23T19:29:57.194+0000] {processor.py:153} INFO - Started process (PID=25216) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:29:57.196+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:29:57.197+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:29:57.197+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:29:57.554+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:29:57.541+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:29:57.557+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:29:57.577+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.386 seconds
[2023-03-23T19:30:28.313+0000] {processor.py:153} INFO - Started process (PID=25296) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:30:28.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:30:28.320+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:30:28.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:30:28.795+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:30:28.786+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:30:28.798+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:30:28.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.518 seconds
[2023-03-23T19:30:59.125+0000] {processor.py:153} INFO - Started process (PID=25369) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:30:59.127+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:30:59.128+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:30:59.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:30:59.534+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:30:59.525+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:30:59.536+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:30:59.564+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.442 seconds
[2023-03-23T19:31:29.931+0000] {processor.py:153} INFO - Started process (PID=25459) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:31:29.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:31:29.934+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:31:29.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:31:30.248+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:31:30.237+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:31:30.250+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:31:30.269+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.341 seconds
[2023-03-23T19:32:01.007+0000] {processor.py:153} INFO - Started process (PID=25532) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:32:01.008+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:32:01.009+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:32:01.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:32:01.364+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:32:01.354+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:32:01.367+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:32:01.386+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.382 seconds
[2023-03-23T19:32:31.665+0000] {processor.py:153} INFO - Started process (PID=25615) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:32:31.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:32:31.668+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:32:31.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:32:32.210+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:32:32.204+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:32:32.212+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:32:32.231+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.569 seconds
[2023-03-23T19:33:03.016+0000] {processor.py:153} INFO - Started process (PID=25695) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:33:03.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:33:03.018+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:33:03.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:33:03.334+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:33:03.327+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:33:03.336+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:33:03.356+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.344 seconds
[2023-03-23T19:33:33.486+0000] {processor.py:153} INFO - Started process (PID=25768) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:33:33.488+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:33:33.490+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:33:33.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:33:33.996+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:33:33.983+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:33:33.998+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:33:34.027+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.544 seconds
[2023-03-23T19:34:04.172+0000] {processor.py:153} INFO - Started process (PID=25855) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:34:04.174+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:34:04.175+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:34:04.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:34:04.596+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:34:04.582+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:34:04.599+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:34:04.621+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.453 seconds
[2023-03-23T19:34:35.072+0000] {processor.py:153} INFO - Started process (PID=25928) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:34:35.073+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:34:35.074+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:34:35.074+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:34:35.383+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:34:35.377+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:34:35.385+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:34:35.400+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.331 seconds
[2023-03-23T19:35:05.458+0000] {processor.py:153} INFO - Started process (PID=26002) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:35:05.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:35:05.463+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:35:05.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:35:05.909+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:35:05.897+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:35:05.912+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:35:05.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.480 seconds
[2023-03-23T19:35:36.149+0000] {processor.py:153} INFO - Started process (PID=26091) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:35:36.150+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:35:36.151+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:35:36.151+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:35:36.450+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:35:36.440+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:35:36.453+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:35:36.471+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.325 seconds
[2023-03-23T19:36:06.517+0000] {processor.py:153} INFO - Started process (PID=26164) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:36:06.517+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:36:06.518+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:36:06.518+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:36:06.857+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:36:06.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:36:06.862+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:36:06.881+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.367 seconds
[2023-03-23T19:36:37.175+0000] {processor.py:153} INFO - Started process (PID=26237) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:36:37.177+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:36:37.178+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:36:37.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:36:37.650+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:36:37.640+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:36:37.652+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:36:37.676+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.507 seconds
[2023-03-23T19:37:08.304+0000] {processor.py:153} INFO - Started process (PID=26326) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:37:08.305+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:37:08.306+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:37:08.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:37:08.763+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:37:08.755+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:37:08.764+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:37:08.786+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.487 seconds
[2023-03-23T19:37:38.856+0000] {processor.py:153} INFO - Started process (PID=26399) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:37:38.857+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:37:38.859+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:37:38.858+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:37:39.385+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:37:39.372+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:37:39.386+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:37:39.409+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.556 seconds
[2023-03-23T19:38:09.490+0000] {processor.py:153} INFO - Started process (PID=26473) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:38:09.491+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:38:09.492+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:38:09.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:38:09.811+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:38:09.804+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:38:09.812+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:38:09.827+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.340 seconds
[2023-03-23T19:38:39.990+0000] {processor.py:153} INFO - Started process (PID=26563) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:38:39.991+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:38:39.992+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:38:39.992+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:38:40.289+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:38:40.277+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:38:40.291+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:38:40.308+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.321 seconds
[2023-03-23T19:39:10.394+0000] {processor.py:153} INFO - Started process (PID=26636) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:39:10.396+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:39:10.397+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:39:10.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:39:10.941+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:39:10.931+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:39:10.944+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:39:10.968+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.579 seconds
[2023-03-23T19:39:41.596+0000] {processor.py:153} INFO - Started process (PID=26725) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:39:41.597+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:39:41.598+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:39:41.597+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:39:41.978+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:39:41.967+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:39:41.981+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:39:41.998+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.406 seconds
[2023-03-23T19:40:12.663+0000] {processor.py:153} INFO - Started process (PID=26798) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:40:12.664+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:40:12.665+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:40:12.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:40:13.049+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:40:13.037+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:40:13.051+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:40:13.068+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.408 seconds
[2023-03-23T19:40:43.354+0000] {processor.py:153} INFO - Started process (PID=26880) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:40:43.356+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:40:43.357+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:40:43.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:40:43.764+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:40:43.751+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:40:43.765+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:40:43.791+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.441 seconds
[2023-03-23T19:41:14.604+0000] {processor.py:153} INFO - Started process (PID=26960) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:41:14.606+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:41:14.607+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:41:14.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:41:14.981+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:41:14.969+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:41:14.984+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:41:15.002+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.403 seconds
[2023-03-23T19:41:45.123+0000] {processor.py:153} INFO - Started process (PID=27033) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:41:45.125+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:41:45.129+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:41:45.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:41:46.238+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:41:46.227+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:41:46.241+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:41:46.267+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.151 seconds
[2023-03-23T19:42:16.799+0000] {processor.py:153} INFO - Started process (PID=27122) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:42:16.800+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:42:16.801+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:42:16.800+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:42:17.191+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:42:17.177+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:42:17.194+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:42:17.214+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.420 seconds
[2023-03-23T19:42:47.492+0000] {processor.py:153} INFO - Started process (PID=27195) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:42:47.493+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:42:47.494+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:42:47.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:42:47.806+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:42:47.800+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:42:47.808+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:42:47.824+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.335 seconds
[2023-03-23T19:43:17.916+0000] {processor.py:153} INFO - Started process (PID=27269) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:43:17.917+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:43:17.919+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:43:17.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:43:18.696+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:43:18.683+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:43:18.699+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:43:18.726+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.815 seconds
[2023-03-23T19:43:49.636+0000] {processor.py:153} INFO - Started process (PID=27359) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:43:49.637+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:43:49.638+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:43:49.637+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:43:50.014+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:43:50.007+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:43:50.017+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:43:50.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.404 seconds
[2023-03-23T19:44:20.224+0000] {processor.py:153} INFO - Started process (PID=27434) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:44:20.225+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:44:20.226+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:44:20.226+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:44:20.552+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:44:20.547+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:44:20.554+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:44:20.571+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.350 seconds
[2023-03-23T19:44:50.759+0000] {processor.py:153} INFO - Started process (PID=27508) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:44:50.760+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:44:50.761+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:44:50.761+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:44:51.110+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:44:51.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:44:51.113+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:44:51.180+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.425 seconds
[2023-03-23T19:45:21.578+0000] {processor.py:153} INFO - Started process (PID=27588) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:45:21.581+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:45:21.583+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:45:21.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:45:22.106+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:45:22.097+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:45:22.109+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:45:22.134+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.563 seconds
[2023-03-23T19:45:52.847+0000] {processor.py:153} INFO - Started process (PID=27668) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:45:52.848+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:45:52.849+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:45:52.849+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:45:53.152+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:45:53.146+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:45:53.154+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:45:53.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.330 seconds
[2023-03-23T19:46:23.563+0000] {processor.py:153} INFO - Started process (PID=27741) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:46:23.565+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:46:23.566+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:46:23.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:46:23.970+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:46:23.963+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:46:23.973+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:46:23.992+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.434 seconds
[2023-03-23T19:46:54.126+0000] {processor.py:153} INFO - Started process (PID=27815) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:46:54.127+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:46:54.128+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:46:54.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:46:54.603+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:46:54.539+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:46:54.606+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:46:54.674+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.552 seconds
[2023-03-23T19:47:24.906+0000] {processor.py:153} INFO - Started process (PID=27906) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:47:24.907+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:47:24.909+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:47:24.909+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:47:25.392+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:47:25.381+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:47:25.395+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:47:25.504+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.603 seconds
[2023-03-23T19:47:55.797+0000] {processor.py:153} INFO - Started process (PID=27978) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:47:55.798+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:47:55.799+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:47:55.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:47:56.099+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:47:56.091+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:47:56.101+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:47:56.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.325 seconds
[2023-03-23T19:48:26.293+0000] {processor.py:153} INFO - Started process (PID=28062) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:48:26.294+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:48:26.296+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:48:26.295+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:48:26.840+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:48:26.830+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:48:26.842+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:48:26.869+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.582 seconds
[2023-03-23T19:48:56.962+0000] {processor.py:153} INFO - Started process (PID=28144) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:48:56.964+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:48:56.965+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:48:56.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:48:57.314+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:48:57.302+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:48:57.316+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:48:57.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.477 seconds
[2023-03-23T19:49:28.059+0000] {processor.py:153} INFO - Started process (PID=28217) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:49:28.061+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:49:28.062+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:49:28.062+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:49:28.466+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:49:28.457+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:49:28.468+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:49:28.490+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.435 seconds
[2023-03-23T19:49:58.657+0000] {processor.py:153} INFO - Started process (PID=28301) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:49:58.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:49:58.660+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:49:58.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:49:59.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:49:59.125+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:49:59.136+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:49:59.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.507 seconds
[2023-03-23T19:50:29.220+0000] {processor.py:153} INFO - Started process (PID=28383) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:50:29.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:50:29.223+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:50:29.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:50:29.643+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:50:29.634+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:50:29.646+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:50:29.670+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.455 seconds
[2023-03-23T19:51:00.396+0000] {processor.py:153} INFO - Started process (PID=28456) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:51:00.397+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:51:00.399+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:51:00.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:51:00.705+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:51:00.695+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:51:00.707+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:51:00.724+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.332 seconds
[2023-03-23T19:51:30.865+0000] {processor.py:153} INFO - Started process (PID=28546) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:51:30.867+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:51:30.868+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:51:30.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:51:31.262+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:51:31.247+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:51:31.265+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:51:31.285+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.424 seconds
[2023-03-23T19:52:01.414+0000] {processor.py:153} INFO - Started process (PID=28619) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:52:01.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:52:01.418+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:52:01.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:52:01.790+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:52:01.778+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:52:01.793+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:52:02.012+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.601 seconds
[2023-03-23T19:52:34.902+0000] {processor.py:153} INFO - Started process (PID=28691) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:52:34.914+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:52:34.920+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:52:34.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:52:36.969+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:52:36.907+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:52:36.989+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:52:37.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.161 seconds
[2023-03-23T19:53:07.555+0000] {processor.py:153} INFO - Started process (PID=28766) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:53:07.567+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:53:07.571+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:53:07.571+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:53:08.729+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:53:08.684+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:53:08.733+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:53:08.773+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.225 seconds
[2023-03-23T19:53:39.739+0000] {processor.py:153} INFO - Started process (PID=28839) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:53:39.741+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:53:39.742+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:53:39.742+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:53:40.278+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:53:40.271+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:53:40.280+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:53:40.297+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.562 seconds
[2023-03-23T19:54:10.996+0000] {processor.py:153} INFO - Started process (PID=28912) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:54:10.998+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:54:10.999+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:54:10.998+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:54:11.349+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:54:11.344+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:54:11.351+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:54:11.512+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.520 seconds
[2023-03-23T19:54:42.178+0000] {processor.py:153} INFO - Started process (PID=29001) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:54:42.180+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:54:42.181+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:54:42.181+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:54:42.517+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:54:42.505+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:54:42.519+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:54:42.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.365 seconds
[2023-03-23T19:55:13.243+0000] {processor.py:153} INFO - Started process (PID=29074) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:55:13.245+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:55:13.248+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:55:13.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:55:13.841+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:55:13.828+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:55:13.844+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:55:13.875+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.640 seconds
[2023-03-23T19:55:44.091+0000] {processor.py:153} INFO - Started process (PID=29147) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:55:44.095+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:55:44.097+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:55:44.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:55:44.840+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:55:44.821+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:55:44.850+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:55:44.890+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.807 seconds
[2023-03-23T19:56:15.193+0000] {processor.py:153} INFO - Started process (PID=29229) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:56:15.194+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:56:15.195+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:56:15.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:56:15.891+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:56:15.868+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:56:15.895+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:56:15.935+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.749 seconds
[2023-03-23T19:56:46.297+0000] {processor.py:153} INFO - Started process (PID=29303) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:56:46.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:56:46.303+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:56:46.303+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:56:47.264+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:56:47.231+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:56:47.302+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:56:47.389+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.130 seconds
[2023-03-23T19:57:17.665+0000] {processor.py:153} INFO - Started process (PID=29367) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:57:17.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:57:17.670+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:57:17.670+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:57:18.296+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:57:18.285+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:57:18.300+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:57:18.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.683 seconds
[2023-03-23T19:57:49.266+0000] {processor.py:153} INFO - Started process (PID=29440) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:57:49.267+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:57:49.268+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:57:49.268+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:57:49.615+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:57:49.607+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:57:49.618+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:57:49.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.387 seconds
[2023-03-23T19:58:19.900+0000] {processor.py:153} INFO - Started process (PID=29513) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:58:19.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:58:19.904+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:58:19.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:58:20.567+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:58:20.556+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:58:20.570+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:58:20.618+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.727 seconds
[2023-03-23T19:58:51.465+0000] {processor.py:153} INFO - Started process (PID=29587) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:58:51.467+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:58:51.468+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:58:51.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:58:51.878+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:58:51.870+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:58:51.881+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:58:51.914+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.453 seconds
[2023-03-23T19:59:22.364+0000] {processor.py:153} INFO - Started process (PID=29660) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:59:22.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:59:22.367+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:59:22.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:59:22.735+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:59:22.730+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:59:22.737+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:59:22.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.402 seconds
[2023-03-23T19:59:53.169+0000] {processor.py:153} INFO - Started process (PID=29734) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:59:53.171+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T19:59:53.173+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:59:53.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:59:54.100+0000] {logging_mixin.py:137} INFO - [2023-03-23T19:59:54.089+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T19:59:54.107+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T19:59:54.139+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.979 seconds
[2023-03-23T20:00:24.878+0000] {processor.py:153} INFO - Started process (PID=29823) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:00:24.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:00:24.881+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:00:24.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:00:25.356+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:00:25.341+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:00:25.362+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:00:25.388+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.514 seconds
[2023-03-23T20:00:55.573+0000] {processor.py:153} INFO - Started process (PID=29897) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:00:55.574+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:00:55.574+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:00:55.574+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:00:55.937+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:00:55.931+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:00:55.939+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:00:55.963+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.394 seconds
[2023-03-23T20:01:26.552+0000] {processor.py:153} INFO - Started process (PID=29970) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:01:26.554+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:01:26.556+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:01:26.555+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:01:27.123+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:01:27.116+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:01:27.128+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:01:27.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.638 seconds
[2023-03-23T20:01:57.346+0000] {processor.py:153} INFO - Started process (PID=30045) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:01:57.348+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:01:57.350+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:01:57.349+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:01:57.762+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:01:57.751+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:01:57.764+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:01:57.786+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.444 seconds
[2023-03-23T20:02:28.562+0000] {processor.py:153} INFO - Started process (PID=30134) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:02:28.564+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:02:28.565+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:02:28.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:02:28.880+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:02:28.873+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:02:28.882+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:02:28.899+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.340 seconds
[2023-03-23T20:02:59.252+0000] {processor.py:153} INFO - Started process (PID=30207) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:02:59.253+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:02:59.254+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:02:59.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:02:59.593+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:02:59.584+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:02:59.595+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:02:59.616+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.367 seconds
[2023-03-23T20:03:30.076+0000] {processor.py:153} INFO - Started process (PID=30280) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:03:30.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:03:30.079+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:03:30.079+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:03:30.574+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:03:30.564+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:03:30.578+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:03:30.608+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.535 seconds
[2023-03-23T20:04:01.304+0000] {processor.py:153} INFO - Started process (PID=30355) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:04:01.311+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:04:01.313+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:04:01.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:04:02.813+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:04:02.772+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:04:02.829+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:04:02.915+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.620 seconds
[2023-03-23T20:04:33.420+0000] {processor.py:153} INFO - Started process (PID=30427) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:04:33.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:04:33.422+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:04:33.422+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:04:33.943+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:04:33.929+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:04:33.946+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:04:34.015+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.602 seconds
[2023-03-23T20:05:04.300+0000] {processor.py:153} INFO - Started process (PID=30502) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:05:04.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:05:04.304+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:05:04.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:05:04.852+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:05:04.843+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:05:04.854+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:05:04.884+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.590 seconds
[2023-03-23T20:05:34.975+0000] {processor.py:153} INFO - Started process (PID=30575) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:05:34.976+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:05:34.978+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:05:34.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:05:35.516+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:05:35.502+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:05:35.519+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:05:35.544+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.577 seconds
[2023-03-23T20:06:05.682+0000] {processor.py:153} INFO - Started process (PID=30649) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:06:05.685+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:06:05.687+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:06:05.687+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:06:06.390+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:06:06.373+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:06:06.401+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:06:06.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.759 seconds
[2023-03-23T20:06:36.799+0000] {processor.py:153} INFO - Started process (PID=30724) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:06:36.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:06:36.803+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:06:36.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:06:37.523+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:06:37.512+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:06:37.527+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:06:37.559+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.771 seconds
[2023-03-23T20:07:07.872+0000] {processor.py:153} INFO - Started process (PID=30799) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:07:07.873+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:07:07.875+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:07:07.875+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:07:08.455+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:07:08.444+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:07:08.457+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:07:08.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.619 seconds
[2023-03-23T20:07:39.611+0000] {processor.py:153} INFO - Started process (PID=30872) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:07:39.616+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:07:39.619+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:07:39.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:07:40.378+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:07:40.367+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:07:40.381+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:07:40.414+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.813 seconds
[2023-03-23T20:08:10.738+0000] {processor.py:153} INFO - Started process (PID=30946) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:08:10.739+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:08:10.741+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:08:10.740+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:08:11.430+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:08:11.421+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:08:11.433+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:08:11.459+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.728 seconds
[2023-03-23T20:08:42.201+0000] {processor.py:153} INFO - Started process (PID=31020) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:08:42.202+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:08:42.203+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:08:42.203+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:08:42.673+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:08:42.664+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:08:42.677+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:08:42.736+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.552 seconds
[2023-03-23T20:09:13.172+0000] {processor.py:153} INFO - Started process (PID=31093) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:09:13.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:09:13.175+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:09:13.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:09:13.623+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:09:13.616+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:09:13.626+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:09:13.652+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.484 seconds
[2023-03-23T20:09:43.801+0000] {processor.py:153} INFO - Started process (PID=31166) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:09:43.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:09:43.803+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:09:43.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:09:44.282+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:09:44.272+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:09:44.286+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:09:44.312+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.518 seconds
[2023-03-23T20:10:14.693+0000] {processor.py:153} INFO - Started process (PID=31239) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:10:14.695+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:10:14.697+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:10:14.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:10:15.888+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:10:15.876+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:10:15.890+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:10:15.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.240 seconds
[2023-03-23T20:10:46.131+0000] {processor.py:153} INFO - Started process (PID=31312) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:10:46.134+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:10:46.137+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:10:46.136+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:10:47.661+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:10:47.532+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:10:47.672+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:10:47.746+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.632 seconds
[2023-03-23T20:11:18.325+0000] {processor.py:153} INFO - Started process (PID=31384) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:11:18.335+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:11:18.338+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:11:18.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:11:19.429+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:11:19.413+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:11:19.433+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:11:19.483+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.169 seconds
[2023-03-23T20:11:52.094+0000] {processor.py:153} INFO - Started process (PID=31450) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:11:52.104+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:11:52.116+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:11:52.116+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:11:56.797+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:11:55.870+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:11:56.878+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:11:56.938+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 4.853 seconds
[2023-03-23T20:12:27.469+0000] {processor.py:153} INFO - Started process (PID=31518) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:12:27.471+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:12:27.472+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:12:27.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:12:28.119+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:12:28.106+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:12:28.124+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:12:28.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.694 seconds
[2023-03-23T20:13:06.272+0000] {processor.py:153} INFO - Started process (PID=31587) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:13:06.276+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:13:06.308+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:13:06.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:13:09.791+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:13:09.397+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:13:09.871+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:13:09.961+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 3.705 seconds
[2023-03-23T20:13:40.992+0000] {processor.py:153} INFO - Started process (PID=31661) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:13:41.004+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:13:41.009+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:13:41.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:13:44.182+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:13:44.136+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:13:44.191+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:13:44.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 3.318 seconds
[2023-03-23T20:14:15.048+0000] {processor.py:153} INFO - Started process (PID=31737) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:14:15.052+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:14:15.054+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:14:15.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:14:16.401+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:14:16.384+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:14:16.404+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:14:16.449+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.409 seconds
[2023-03-23T20:14:46.799+0000] {processor.py:153} INFO - Started process (PID=31811) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:14:46.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:14:46.804+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:14:46.804+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:14:47.818+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:14:47.763+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:14:47.821+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:14:48.095+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.302 seconds
[2023-03-23T20:15:18.509+0000] {processor.py:153} INFO - Started process (PID=31876) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:15:18.522+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:15:18.525+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:15:18.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:15:20.499+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:15:20.447+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:15:20.514+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:15:20.690+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.198 seconds
[2023-03-23T20:15:50.883+0000] {processor.py:153} INFO - Started process (PID=31943) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:15:50.886+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:15:50.891+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:15:50.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:15:52.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:15:52.116+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:15:52.138+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:15:52.204+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.328 seconds
[2023-03-23T20:16:22.815+0000] {processor.py:153} INFO - Started process (PID=32020) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:16:22.817+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:16:22.819+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:16:22.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:16:23.653+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:16:23.636+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:16:23.656+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:16:23.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.888 seconds
[2023-03-23T20:16:54.414+0000] {processor.py:153} INFO - Started process (PID=32093) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:16:54.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:16:54.427+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:16:54.427+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:16:56.296+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:16:56.158+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:16:56.300+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:16:56.452+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.045 seconds
[2023-03-23T20:17:26.867+0000] {processor.py:153} INFO - Started process (PID=32167) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:17:26.869+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:17:26.871+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:17:26.870+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:17:27.647+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:17:27.611+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:17:27.651+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:17:27.712+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.850 seconds
[2023-03-23T20:17:58.355+0000] {processor.py:153} INFO - Started process (PID=32240) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:17:58.357+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:17:58.361+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:17:58.361+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:17:59.189+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:17:59.174+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:17:59.193+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:17:59.240+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.896 seconds
[2023-03-23T20:18:30.282+0000] {processor.py:153} INFO - Started process (PID=32298) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:18:30.284+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:18:30.286+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:18:30.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:18:30.822+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:18:30.815+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:18:30.824+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:18:30.848+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.573 seconds
[2023-03-23T20:19:01.699+0000] {processor.py:153} INFO - Started process (PID=32372) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:19:01.700+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:19:01.701+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:19:01.701+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:19:02.276+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:19:02.266+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:19:02.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:19:02.312+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.617 seconds
[2023-03-23T20:19:32.596+0000] {processor.py:153} INFO - Started process (PID=32445) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:19:32.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:19:32.600+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:19:32.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:19:33.203+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:19:33.195+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:19:33.205+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:19:33.237+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.649 seconds
[2023-03-23T20:20:03.683+0000] {processor.py:153} INFO - Started process (PID=32518) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:20:03.685+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:20:03.691+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:20:03.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:20:04.425+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:20:04.410+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:20:04.430+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:20:04.474+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.797 seconds
[2023-03-23T20:20:35.180+0000] {processor.py:153} INFO - Started process (PID=32591) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:20:35.182+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:20:35.184+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:20:35.184+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:20:36.427+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:20:36.411+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:20:36.431+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:20:36.489+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.315 seconds
[2023-03-23T20:21:06.817+0000] {processor.py:153} INFO - Started process (PID=32665) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:21:06.818+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:21:06.820+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:21:06.820+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:21:07.458+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:21:07.447+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:21:07.461+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:21:07.495+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.684 seconds
[2023-03-23T20:21:37.768+0000] {processor.py:153} INFO - Started process (PID=32739) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:21:37.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:21:37.776+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:21:37.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:21:38.637+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:21:38.627+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:21:38.639+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:21:38.673+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.913 seconds
[2023-03-23T20:22:09.069+0000] {processor.py:153} INFO - Started process (PID=338) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:22:09.071+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:22:09.072+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:22:09.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:22:09.870+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:22:09.859+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:22:09.873+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:22:09.901+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.840 seconds
[2023-03-23T20:22:40.695+0000] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:22:40.707+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:22:40.712+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:22:40.712+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:22:42.305+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:22:42.268+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:22:42.324+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:22:42.402+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.719 seconds
[2023-03-23T20:23:12.644+0000] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:23:12.645+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:23:12.647+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:23:12.647+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:23:13.503+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:23:13.451+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:23:13.506+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:23:13.575+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.937 seconds
[2023-03-23T20:23:43.748+0000] {processor.py:153} INFO - Started process (PID=549) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:23:43.749+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:23:43.752+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:23:43.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:23:44.221+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:23:44.157+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:23:44.224+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:23:44.266+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.547 seconds
[2023-03-23T20:24:14.335+0000] {processor.py:153} INFO - Started process (PID=622) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:24:14.336+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:24:14.337+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:24:14.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:24:14.776+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:24:14.769+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:24:14.778+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:24:14.804+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.474 seconds
[2023-03-23T20:24:45.539+0000] {processor.py:153} INFO - Started process (PID=695) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:24:45.540+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:24:45.542+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:24:45.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:24:46.243+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:24:46.173+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:24:46.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:24:46.281+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.748 seconds
[2023-03-23T20:25:17.084+0000] {processor.py:153} INFO - Started process (PID=769) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:25:17.086+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:25:17.087+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:25:17.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:25:17.579+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:25:17.566+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:25:17.582+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:25:17.617+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.538 seconds
[2023-03-23T20:25:47.693+0000] {processor.py:153} INFO - Started process (PID=843) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:25:47.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:25:47.696+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:25:47.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:25:48.254+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:25:48.244+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:25:48.259+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:25:48.287+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.600 seconds
[2023-03-23T20:26:18.814+0000] {processor.py:153} INFO - Started process (PID=916) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:26:18.816+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:26:18.817+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:26:18.817+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:26:19.346+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:26:19.337+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:26:19.354+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:26:19.391+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.587 seconds
[2023-03-23T20:26:49.704+0000] {processor.py:153} INFO - Started process (PID=989) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:26:49.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:26:49.707+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:26:49.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:26:50.151+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:26:50.144+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:26:50.154+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:26:50.200+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.501 seconds
[2023-03-23T20:27:20.505+0000] {processor.py:153} INFO - Started process (PID=1062) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:27:20.510+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:27:20.515+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:27:20.514+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:27:21.738+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:27:21.700+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:27:21.745+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:27:21.832+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.336 seconds
[2023-03-23T20:27:52.130+0000] {processor.py:153} INFO - Started process (PID=1136) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:27:52.132+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:27:52.134+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:27:52.133+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:27:52.770+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:27:52.756+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:27:52.773+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:27:52.805+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.682 seconds
[2023-03-23T20:28:23.160+0000] {processor.py:153} INFO - Started process (PID=1209) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:28:23.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:28:23.163+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:28:23.163+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:28:23.665+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:28:23.655+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:28:23.668+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:28:23.695+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.539 seconds
[2023-03-23T20:28:54.259+0000] {processor.py:153} INFO - Started process (PID=1282) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:28:54.261+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:28:54.262+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:28:54.262+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:28:54.710+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:28:54.701+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:28:54.712+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:28:54.736+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.482 seconds
[2023-03-23T20:29:24.891+0000] {processor.py:153} INFO - Started process (PID=1357) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:29:24.892+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:29:24.893+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:29:24.893+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:29:25.318+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:29:25.311+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:29:25.319+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:29:25.339+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.452 seconds
[2023-03-23T20:29:55.630+0000] {processor.py:153} INFO - Started process (PID=1431) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:29:55.632+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:29:55.633+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:29:55.633+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:29:56.120+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:29:56.108+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:29:56.124+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:29:56.158+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.532 seconds
[2023-03-23T20:30:26.390+0000] {processor.py:153} INFO - Started process (PID=1504) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:30:26.392+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:30:26.393+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:30:26.393+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:30:26.900+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:30:26.890+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:30:26.903+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:30:26.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.541 seconds
[2023-03-23T20:30:57.140+0000] {processor.py:153} INFO - Started process (PID=1577) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:30:57.141+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:30:57.143+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:30:57.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:30:57.685+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:30:57.675+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:30:57.689+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:30:57.722+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.587 seconds
[2023-03-23T20:31:28.412+0000] {processor.py:153} INFO - Started process (PID=1650) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:31:28.414+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:31:28.416+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:31:28.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:31:29.055+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:31:29.045+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:31:29.057+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:31:29.087+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.680 seconds
[2023-03-23T20:31:59.169+0000] {processor.py:153} INFO - Started process (PID=1722) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:31:59.171+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:31:59.172+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:31:59.172+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:31:59.726+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:31:59.717+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:31:59.729+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:31:59.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.596 seconds
[2023-03-23T20:32:30.330+0000] {processor.py:153} INFO - Started process (PID=1794) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:32:30.333+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:32:30.336+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:32:30.335+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:32:30.830+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:32:30.823+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:32:30.832+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:32:30.855+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.533 seconds
[2023-03-23T20:33:00.944+0000] {processor.py:153} INFO - Started process (PID=1867) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:33:00.946+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:33:00.948+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:33:00.948+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:33:01.760+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:33:01.748+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:33:01.763+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:33:01.797+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.861 seconds
[2023-03-23T20:33:32.122+0000] {processor.py:153} INFO - Started process (PID=1939) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:33:32.123+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:33:32.125+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:33:32.125+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:33:32.811+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:33:32.798+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:33:32.817+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:33:32.854+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.739 seconds
[2023-03-23T20:34:03.203+0000] {processor.py:153} INFO - Started process (PID=2014) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:34:03.205+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:34:03.206+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:34:03.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:34:03.891+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:34:03.880+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:34:03.894+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:34:03.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.726 seconds
[2023-03-23T20:34:34.386+0000] {processor.py:153} INFO - Started process (PID=2089) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:34:34.388+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:34:34.397+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:34:34.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:34:35.428+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:34:35.415+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:34:35.431+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:34:35.489+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.110 seconds
[2023-03-23T20:35:05.649+0000] {processor.py:153} INFO - Started process (PID=2146) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:35:05.650+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:35:05.652+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:35:05.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:35:06.377+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:35:06.365+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:35:06.380+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:35:06.561+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.918 seconds
[2023-03-23T20:35:37.220+0000] {processor.py:153} INFO - Started process (PID=2219) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:35:37.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:35:37.224+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:35:37.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:35:37.921+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:35:37.906+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:35:37.928+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:35:37.963+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.749 seconds
[2023-03-23T20:36:08.133+0000] {processor.py:153} INFO - Started process (PID=2292) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:36:08.135+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:36:08.136+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:36:08.136+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:36:08.713+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:36:08.703+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:36:08.716+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:36:08.745+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.618 seconds
[2023-03-23T20:36:40.117+0000] {processor.py:153} INFO - Started process (PID=2358) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:36:40.126+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:36:40.143+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:36:40.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:36:42.408+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:36:42.355+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:36:42.420+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:36:42.500+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.390 seconds
[2023-03-23T20:37:13.409+0000] {processor.py:153} INFO - Started process (PID=2423) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:37:13.411+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:37:13.413+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:37:13.412+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:37:14.763+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:37:14.749+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:37:14.766+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:37:14.834+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.438 seconds
[2023-03-23T20:37:45.181+0000] {processor.py:153} INFO - Started process (PID=2499) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:37:45.183+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:37:45.185+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:37:45.185+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:37:45.933+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:37:45.923+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:37:45.935+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:37:45.967+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.795 seconds
[2023-03-23T20:38:16.196+0000] {processor.py:153} INFO - Started process (PID=2570) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:38:16.199+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:38:16.204+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:38:16.204+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:38:17.330+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:38:17.313+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:38:17.336+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:38:17.388+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.199 seconds
[2023-03-23T20:38:47.746+0000] {processor.py:153} INFO - Started process (PID=2636) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:38:47.750+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:38:47.752+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:38:47.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:38:48.842+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:38:48.736+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:38:48.850+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:38:48.916+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.178 seconds
[2023-03-23T20:39:19.744+0000] {processor.py:153} INFO - Started process (PID=2700) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:39:19.750+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:39:19.762+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:39:19.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:39:21.003+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:39:20.975+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:39:21.023+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:39:21.099+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.362 seconds
[2023-03-23T20:39:51.555+0000] {processor.py:153} INFO - Started process (PID=2774) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:39:51.557+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:39:51.559+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:39:51.559+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:39:52.469+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:39:52.456+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:39:52.472+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:39:52.535+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.988 seconds
[2023-03-23T20:40:23.348+0000] {processor.py:153} INFO - Started process (PID=2847) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:40:23.350+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:40:23.352+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:40:23.351+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:40:24.013+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:40:24.001+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:40:24.016+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:40:24.044+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.705 seconds
[2023-03-23T20:40:55.176+0000] {processor.py:153} INFO - Started process (PID=2915) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:40:55.179+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:40:55.191+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:40:55.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:40:57.383+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:40:57.175+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:40:57.408+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:40:57.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.300 seconds
[2023-03-23T20:41:27.755+0000] {processor.py:153} INFO - Started process (PID=2987) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:41:27.757+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:41:27.759+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:41:27.759+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:41:28.780+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:41:28.764+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:41:28.785+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:41:28.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.210 seconds
[2023-03-23T20:41:59.138+0000] {processor.py:153} INFO - Started process (PID=3053) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:41:59.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:41:59.144+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:41:59.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:42:00.555+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:42:00.526+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:42:00.561+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:42:00.623+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.508 seconds
[2023-03-23T20:42:31.059+0000] {processor.py:153} INFO - Started process (PID=3128) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:42:31.063+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:42:31.067+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:42:31.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:42:32.716+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:42:32.700+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:42:32.718+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:42:32.830+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.789 seconds
[2023-03-23T20:43:03.076+0000] {processor.py:153} INFO - Started process (PID=3186) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:43:03.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:43:03.088+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:43:03.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:43:04.169+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:43:04.153+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:43:04.172+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:43:04.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.277 seconds
[2023-03-23T20:43:34.606+0000] {processor.py:153} INFO - Started process (PID=3260) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:43:34.612+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:43:34.618+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:43:34.614+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:43:36.238+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:43:36.220+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:43:36.242+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:43:36.457+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.860 seconds
[2023-03-23T20:44:06.874+0000] {processor.py:153} INFO - Started process (PID=3328) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:44:06.882+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:44:06.884+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:44:06.884+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:44:10.156+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:44:09.841+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:44:10.160+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:44:10.304+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 3.441 seconds
[2023-03-23T20:44:41.080+0000] {processor.py:153} INFO - Started process (PID=3394) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:44:41.081+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:44:41.083+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:44:41.083+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:44:41.832+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:44:41.815+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:44:41.835+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:44:41.872+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.800 seconds
[2023-03-23T20:45:12.385+0000] {processor.py:153} INFO - Started process (PID=3469) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:45:12.399+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:45:12.404+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:45:12.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:45:14.163+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:45:14.150+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:45:14.166+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:45:14.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.837 seconds
[2023-03-23T20:45:44.485+0000] {processor.py:153} INFO - Started process (PID=3543) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:45:44.487+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:45:44.489+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:45:44.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:45:45.419+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:45:45.380+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:45:45.427+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:45:45.486+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.016 seconds
[2023-03-23T20:46:16.372+0000] {processor.py:153} INFO - Started process (PID=3617) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:46:16.374+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:46:16.376+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:46:16.376+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:46:17.108+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:46:17.096+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:46:17.111+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:46:17.161+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.796 seconds
[2023-03-23T20:46:48.455+0000] {processor.py:153} INFO - Started process (PID=3691) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:46:48.472+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:46:48.476+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:46:48.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:46:50.522+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:46:50.509+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:46:50.524+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:46:50.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 2.167 seconds
[2023-03-23T20:47:20.838+0000] {processor.py:153} INFO - Started process (PID=3766) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:47:20.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:47:20.842+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:47:20.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:47:21.809+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:47:21.687+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:47:21.813+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:47:21.880+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.055 seconds
[2023-03-23T20:47:52.852+0000] {processor.py:153} INFO - Started process (PID=3832) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:47:52.856+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:47:52.858+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:47:52.858+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:47:53.691+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:47:53.680+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:47:53.694+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:47:53.727+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.884 seconds
[2023-03-23T20:48:23.993+0000] {processor.py:153} INFO - Started process (PID=3914) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:48:23.995+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:48:23.997+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:48:23.996+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:48:24.937+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:48:24.883+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:48:24.942+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:48:25.014+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.029 seconds
[2023-03-23T20:48:55.583+0000] {processor.py:153} INFO - Started process (PID=3987) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:48:55.586+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:48:55.588+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:48:55.587+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:48:56.261+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:48:56.250+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:48:56.263+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:48:56.293+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.718 seconds
[2023-03-23T20:49:26.775+0000] {processor.py:153} INFO - Started process (PID=4060) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:49:26.776+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:49:26.779+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:49:26.778+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:49:27.480+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:49:27.463+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:49:27.483+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:49:27.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.745 seconds
[2023-03-23T20:49:58.426+0000] {processor.py:153} INFO - Started process (PID=4136) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:49:58.429+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:49:58.447+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:49:58.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:49:59.981+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:49:59.959+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:49:59.984+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:50:00.064+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 1.655 seconds
[2023-03-23T20:50:30.461+0000] {processor.py:153} INFO - Started process (PID=4194) to work on /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:50:30.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/gcs_to_bq.py for tasks to queue
[2023-03-23T20:50:30.472+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:50:30.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:50:31.266+0000] {logging_mixin.py:137} INFO - [2023-03-23T20:50:31.253+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/gcs_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/gcs_to_bq.py", line 15, in <module>
    from airflow.providers.google.cloud.operators.gcs import GoogleCloudStorageCreateBucketOperator, GCSSynchronizeBucketsOperator, GCSListObjectsOperator, GCSDeleteBucketOperator,GoogleCloudStorageCopyOperator
ImportError: cannot import name 'GoogleCloudStorageCreateBucketOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2023-03-23T20:50:31.269+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/gcs_to_bq.py
[2023-03-23T20:50:31.317+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/gcs_to_bq.py took 0.864 seconds
